{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"nb033.ipynb","provenance":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["### reference https://github.com/abhishekkrthakur/long-text-token-classification/tree/8f636ea23b7e1842583581d9cbdbe9f0f54d3191 "],"metadata":{"id":"5_2g37QvKzWg"}},{"cell_type":"markdown","source":["MyDrive/kaggle/feedback のディレクトリを作ってその中に入れると動くと思います"],"metadata":{"id":"QAZK6ncQTXsf"}},{"cell_type":"code","source":["class Config:\n","    name = \"nb033\" # 実験のたびにコピーしてここの名前を変えて実行するとoutputが別のファイルに保存される\n","    debug = False # debug用の小さいデータになる\n","\n","    # Colab Env\n","    upload_from_colab = False\n","    drive_path = '/content/drive/MyDrive/Kaggle_Feedback-Prize-Evaluating-Student-Writing/'\n","    \n","    # Kaggle Env\n","    kaggle_dataset_path = None"],"metadata":{"id":"z7YNmSGL1p_5","executionInfo":{"status":"ok","timestamp":1646631171455,"user_tz":-540,"elapsed":11,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"}},"execution":{"iopub.status.busy":"2022-03-05T17:24:57.951047Z","iopub.execute_input":"2022-03-05T17:24:57.951495Z","iopub.status.idle":"2022-03-05T17:24:57.980082Z","shell.execute_reply.started":"2022-03-05T17:24:57.951387Z","shell.execute_reply":"2022-03-05T17:24:57.979441Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["import os\n","import json\n","import warnings\n","import shutil\n","import logging\n","import joblib\n","import random\n","import datetime\n","import sys\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from tqdm.auto import tqdm\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import mean_squared_error\n","\n","import lightgbm\n","import pickle\n","from datetime import datetime\n","from matplotlib import pyplot as plt\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.model_selection import GroupKFold\n","from sklearn.preprocessing import StandardScaler\n","import dateutil.easter as easter\n","import random\n","seed = 334"],"metadata":{"id":"VbXtfty816RE","executionInfo":{"status":"ok","timestamp":1646631171457,"user_tz":-540,"elapsed":12,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"}},"execution":{"iopub.status.busy":"2022-03-05T17:24:57.981343Z","iopub.execute_input":"2022-03-05T17:24:57.982091Z","iopub.status.idle":"2022-03-05T17:25:05.958789Z","shell.execute_reply.started":"2022-03-05T17:24:57.982051Z","shell.execute_reply":"2022-03-05T17:25:05.958075Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["COLAB = \"google.colab\" in sys.modules"],"metadata":{"id":"LhXvf-UB16Ol","executionInfo":{"status":"ok","timestamp":1646631174484,"user_tz":-540,"elapsed":432,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"}},"execution":{"iopub.status.busy":"2022-03-05T17:25:05.961306Z","iopub.execute_input":"2022-03-05T17:25:05.961734Z","iopub.status.idle":"2022-03-05T17:25:05.965906Z","shell.execute_reply.started":"2022-03-05T17:25:05.961697Z","shell.execute_reply":"2022-03-05T17:25:05.965309Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["!pip install --upgrade --force-reinstall --no-deps kaggle\n","! pip install -qq transformers sentencepiece iterative-stratification tez"],"metadata":{"id":"Ea4nxNzi16LE","executionInfo":{"status":"ok","timestamp":1646631179426,"user_tz":-540,"elapsed":4194,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"}},"outputId":"0215c23f-7e3d-4941-ad1e-e687291df39e","execution":{"iopub.status.busy":"2022-03-05T17:25:05.967513Z","iopub.execute_input":"2022-03-05T17:25:05.967886Z","iopub.status.idle":"2022-03-05T17:25:10.736937Z","shell.execute_reply.started":"2022-03-05T17:25:05.967851Z","shell.execute_reply":"2022-03-05T17:25:10.736148Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting kaggle\n","  Using cached kaggle-1.5.12-py3-none-any.whl\n","Installing collected packages: kaggle\n","  Attempting uninstall: kaggle\n","    Found existing installation: kaggle 1.5.12\n","    Uninstalling kaggle-1.5.12:\n","      Successfully uninstalled kaggle-1.5.12\n","Successfully installed kaggle-1.5.12\n"]}]},{"cell_type":"code","source":["if COLAB:\n","    print(\"This environment is Google Colab\")\n","    %cd drive/MyDrive/Kaggle_Feedback-Prize-Evaluating-Student-Writing/main/\n","    \n","    # mount\n","    from google.colab import drive\n","    if not os.path.isdir(\"/content/drive\"):\n","        drive.mount('/content/drive') \n","\t\n","    \n","    # # use kaggle api (need kaggle token)\n","    # f = open(Config.api_path, 'r')\n","    # json_data = json.load(f) \n","    # os.environ[\"KAGGLE_USERNAME\"] = json_data[\"username\"]\n","    # os.environ[\"KAGGLE_KEY\"] = json_data[\"key\"]\n","    \n","    # set dirs\n","    DRIVE = Config.drive_path\n","    EXP = Config.name\n","    INPUT = os.path.join(DRIVE, \"input\")\n","    OUTPUT = os.path.join(DRIVE, f'output/{Config.name}')\n","    SCRIPT = os.path.join(DRIVE, \"script\")\n","    OUTPUT_EXP = os.path.join(OUTPUT, EXP) \n","    # EXP_MODEL = os.path.join(OUTPUT_EXP, \"model\")\n","    # EXP_FIG = os.path.join(OUTPUT_EXP, \"fig\")\n","    # EXP_PREDS = os.path.join(OUTPUT_EXP, \"preds\")\n","    INPUT = os.path.join(INPUT, 'feedback-prize-2021')\n","    \n","    # make dirs\n","    for d in [INPUT, SCRIPT, OUTPUT, OUTPUT_EXP]:\n","        os.makedirs(d, exist_ok=True)\n","    \n","    # if not os.path.isfile(os.path.join(INPUT, \"train.csv\")):\n","    #     # load dataset\n","    #     ! kaggle competitions download -c feedback-prize-2021 -p $INPUT \n","    #     unzip_file = os.path.join(INPUT, 'feedback-prize-2021.zip')\n","    #     ! unzip $unzip_file -d $INPUT\n","    \n","\n","else:\n","    print(\"This environment is Kaggle Kernel\")\n","    \n","    # set dirs\n","    INPUT = \"../input/feedback-prize-2021\"\n","#     EXP, OUTPUT, SUBMISSION = \"./\", \"./\", \"./\"\n","#     EXP_MODEL = os.path.join(EXP, \"model\")\n","#     EXP_FIG = os.path.join(EXP, \"fig\")\n","#     EXP_PREDS = os.path.join(EXP, \"preds\")\n","    \n","#     # copy dirs\n","#     if Config.kaggle_dataset_path is not None:\n","#         KD_MODEL = os.path.join(Config.kaggle_dataset_path, \"model\")\n","#         KD_EXP_PREDS = os.path.join(Config.kaggle_dataset_path, \"preds\")\n","#         shutil.copytree(KD_MODEL, EXP_MODEL)\n","#         shutil.copytree(KD_EXP_PREDS, EXP_PREDS)\n","\n","#     # make dirs\n","#     for d in [EXP_MODEL, EXP_FIG, EXP_PREDS]:\n","#         os.makedirs(d, exist_ok=True)\n","    OUTPUT_EXP = './'\n","        \n","    "],"metadata":{"id":"1YQXcS4z16IF","executionInfo":{"status":"ok","timestamp":1646631179838,"user_tz":-540,"elapsed":430,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"}},"outputId":"c5e18bf3-a827-43fe-b95f-df65119a60e6","execution":{"iopub.status.busy":"2022-03-05T17:25:10.738790Z","iopub.execute_input":"2022-03-05T17:25:10.739042Z","iopub.status.idle":"2022-03-05T17:25:10.759397Z","shell.execute_reply.started":"2022-03-05T17:25:10.739008Z","shell.execute_reply":"2022-03-05T17:25:10.758727Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["This environment is Google Colab\n","[Errno 2] No such file or directory: 'drive/MyDrive/Kaggle_Feedback-Prize-Evaluating-Student-Writing/main/'\n","/content/drive/MyDrive/Kaggle_Feedback-Prize-Evaluating-Student-Writing/main\n"]}]},{"cell_type":"code","source":["import copy\n","import os\n","\n","import numpy as np\n","import pandas as pd\n","import torch\n","from joblib import Parallel, delayed\n","from tez import enums\n","from tez.callbacks import Callback\n","from tqdm import tqdm\n","\n","target_id_map = {\n","    \"B-Lead\": 0,\n","    \"I-Lead\": 1,\n","    \"B-Position\": 2,\n","    \"I-Position\": 3,\n","    \"B-Evidence\": 4,\n","    \"I-Evidence\": 5,\n","    \"B-Claim\": 6,\n","    \"I-Claim\": 7,\n","    \"B-Concluding Statement\": 8,\n","    \"I-Concluding Statement\": 9,\n","    \"B-Counterclaim\": 10,\n","    \"I-Counterclaim\": 11,\n","    \"B-Rebuttal\": 12,\n","    \"I-Rebuttal\": 13,\n","    \"O\": 14,\n","    \"PAD\": -100,\n","}\n","\n","\n","id_target_map = {v: k for k, v in target_id_map.items()}\n","\n","\n","def _prepare_training_data_helper(args, tokenizer, df, train_ids):\n","    training_samples = []\n","    for idx in tqdm(train_ids):\n","        filename = os.path.join(args.input, \"train\", idx + \".txt\")\n","        with open(filename, \"r\") as f:\n","            text = f.read()\n","\n","        encoded_text = tokenizer.encode_plus(\n","            text,\n","            add_special_tokens=False,\n","            return_offsets_mapping=True,\n","        )\n","        input_ids = encoded_text[\"input_ids\"] # トークンごとに固有の数がふられる\n","        input_labels = copy.deepcopy(input_ids)\n","        offset_mapping = encoded_text[\"offset_mapping\"] # トークンの始まりと終わりの文字数\n","\n","        for k in range(len(input_labels)):\n","            input_labels[k] = \"O\"\n","\n","        sample = {\n","            \"id\": idx,\n","            \"input_ids\": input_ids,\n","            \"text\": text,\n","            \"offset_mapping\": offset_mapping,\n","        }\n","\n","        temp_df = df[df[\"id\"] == idx]\n","        for _, row in temp_df.iterrows():\n","            text_labels = [0] * len(text)\n","            discourse_start = int(row[\"discourse_start\"])\n","            discourse_end = int(row[\"discourse_end\"])\n","            prediction_label = row[\"discourse_type\"]\n","            text_labels[discourse_start:discourse_end] = [1] * (discourse_end - discourse_start)\n","            target_idx = []\n","            for map_idx, (offset1, offset2) in enumerate(encoded_text[\"offset_mapping\"]):\n","                if sum(text_labels[offset1:offset2]) > 0:\n","                    if len(text[offset1:offset2].split()) > 0:\n","                        target_idx.append(map_idx)\n","\n","            targets_start = target_idx[0]\n","            targets_end = target_idx[-1]\n","            pred_start = \"B-\" + prediction_label\n","            pred_end = \"I-\" + prediction_label\n","            input_labels[targets_start] = pred_start\n","            input_labels[targets_start + 1 : targets_end + 1] = [pred_end] * (targets_end - targets_start)\n","\n","        sample[\"input_ids\"] = input_ids\n","        sample[\"input_labels\"] = input_labels\n","        training_samples.append(sample)\n","    return training_samples\n","\n","\n","def prepare_training_data(df, tokenizer, args, num_jobs):\n","    training_samples = []\n","    train_ids = df[\"id\"].unique()\n","\n","    train_ids_splits = np.array_split(train_ids, num_jobs)\n","\n","    results = Parallel(n_jobs=num_jobs,)( \n","        delayed(_prepare_training_data_helper)(args, tokenizer, df, idx) for idx in train_ids_splits\n","    )\n","    for result in results:\n","        training_samples.extend(result)\n","\n","    return training_samples\n","\n","\n","def calc_overlap(row):\n","    \"\"\"\n","    Calculates the overlap between prediction and\n","    ground truth and overlap percentages used for determining\n","    true positives.\n","    \"\"\"\n","    set_pred = set(row.predictionstring_pred.split(\" \"))\n","    set_gt = set(row.predictionstring_gt.split(\" \"))\n","    # Length of each and intersection\n","    len_gt = len(set_gt)\n","    len_pred = len(set_pred)\n","    inter = len(set_gt.intersection(set_pred))\n","    overlap_1 = inter / len_gt\n","    overlap_2 = inter / len_pred\n","    return [overlap_1, overlap_2]\n","\n","\n","def score_feedback_comp_micro(pred_df, gt_df):\n","    \"\"\"\n","    A function that scores for the kaggle\n","        Student Writing Competition\n","\n","    Uses the steps in the evaluation page here:\n","        https://www.kaggle.com/c/feedback-prize-2021/overview/evaluation\n","    This code is from Rob Mulla's Kaggle kernel.\n","    \"\"\"\n","    gt_df = gt_df[[\"id\", \"discourse_type\", \"predictionstring\"]].reset_index(drop=True).copy()\n","    pred_df = pred_df[[\"id\", \"class\", \"predictionstring\"]].reset_index(drop=True).copy()\n","    pred_df[\"pred_id\"] = pred_df.index\n","    gt_df[\"gt_id\"] = gt_df.index\n","    # Step 1. all ground truths and predictions for a given class are compared.\n","    joined = pred_df.merge(\n","        gt_df,\n","        left_on=[\"id\", \"class\"],\n","        right_on=[\"id\", \"discourse_type\"],\n","        how=\"outer\",\n","        suffixes=(\"_pred\", \"_gt\"),\n","    )\n","    joined[\"predictionstring_gt\"] = joined[\"predictionstring_gt\"].fillna(\" \")\n","    joined[\"predictionstring_pred\"] = joined[\"predictionstring_pred\"].fillna(\" \")\n","\n","    joined[\"overlaps\"] = joined.apply(calc_overlap, axis=1)\n","\n","    # 2. If the overlap between the ground truth and prediction is >= 0.5,\n","    # and the overlap between the prediction and the ground truth >= 0.5,\n","    # the prediction is a match and considered a true positive.\n","    # If multiple matches exist, the match with the highest pair of overlaps is taken.\n","    joined[\"overlap1\"] = joined[\"overlaps\"].apply(lambda x: eval(str(x))[0])\n","    joined[\"overlap2\"] = joined[\"overlaps\"].apply(lambda x: eval(str(x))[1])\n","\n","    joined[\"potential_TP\"] = (joined[\"overlap1\"] >= 0.5) & (joined[\"overlap2\"] >= 0.5)\n","    joined[\"max_overlap\"] = joined[[\"overlap1\", \"overlap2\"]].max(axis=1)\n","    tp_pred_ids = (\n","        joined.query(\"potential_TP\")\n","        .sort_values(\"max_overlap\", ascending=False)\n","        .groupby([\"id\", \"predictionstring_gt\"])\n","        .first()[\"pred_id\"]\n","        .values\n","    )\n","\n","    # 3. Any unmatched ground truths are false negatives\n","    # and any unmatched predictions are false positives.\n","    fp_pred_ids = [p for p in joined[\"pred_id\"].unique() if p not in tp_pred_ids]\n","\n","    matched_gt_ids = joined.query(\"potential_TP\")[\"gt_id\"].unique()\n","    unmatched_gt_ids = [c for c in joined[\"gt_id\"].unique() if c not in matched_gt_ids]\n","\n","    # Get numbers of each type\n","    TP = len(tp_pred_ids)\n","    FP = len(fp_pred_ids)\n","    FN = len(unmatched_gt_ids)\n","    # calc microf1\n","    my_f1_score = TP / (TP + 0.5 * (FP + FN))\n","    return my_f1_score\n","\n","\n","def score_feedback_comp(pred_df, gt_df, return_class_scores=False):\n","    class_scores = {}\n","    pred_df = pred_df[[\"id\", \"class\", \"predictionstring\"]].reset_index(drop=True).copy()\n","    for discourse_type, gt_subset in gt_df.groupby(\"discourse_type\"):\n","        pred_subset = pred_df.loc[pred_df[\"class\"] == discourse_type].reset_index(drop=True).copy()\n","        class_score = score_feedback_comp_micro(pred_subset, gt_subset)\n","        class_scores[discourse_type] = class_score\n","    f1 = np.mean([v for v in class_scores.values()])\n","    if return_class_scores:\n","        return f1, class_scores\n","    return f1\n","\n","\n","class FeedbackDatasetValid:\n","    def __init__(self, samples, max_len, tokenizer):\n","        self.samples = samples\n","        self.max_len = max_len\n","        self.tokenizer = tokenizer\n","        self.length = len(samples)\n","\n","    def __len__(self):\n","        return self.length\n","\n","    def __getitem__(self, idx):\n","        input_ids = self.samples[idx][\"input_ids\"]\n","        input_ids = [self.tokenizer.cls_token_id] + input_ids\n","\n","        if len(input_ids) > self.max_len - 1:\n","            input_ids = input_ids[: self.max_len - 1]\n","\n","        # add end token id to the input_ids\n","        input_ids = input_ids + [self.tokenizer.sep_token_id]\n","        attention_mask = [1] * len(input_ids)\n","\n","        return {\n","            \"ids\": input_ids,\n","            \"mask\": attention_mask,\n","        }\n","\n","\n","class Collate:\n","    def __init__(self, tokenizer):\n","        self.tokenizer = tokenizer\n","\n","    def __call__(self, batch):\n","        output = dict()\n","        output[\"ids\"] = [sample[\"ids\"] for sample in batch]\n","        output[\"mask\"] = [sample[\"mask\"] for sample in batch]\n","\n","        # calculate max token length of this batch\n","        batch_max = max([len(ids) for ids in output[\"ids\"]])\n","\n","        # add padding\n","        if self.tokenizer.padding_side == \"right\":\n","            output[\"ids\"] = [s + (batch_max - len(s)) * [self.tokenizer.pad_token_id] for s in output[\"ids\"]]\n","            output[\"mask\"] = [s + (batch_max - len(s)) * [0] for s in output[\"mask\"]]\n","        else:\n","            output[\"ids\"] = [(batch_max - len(s)) * [self.tokenizer.pad_token_id] + s for s in output[\"ids\"]]\n","            output[\"mask\"] = [(batch_max - len(s)) * [0] + s for s in output[\"mask\"]]\n","\n","        # convert to tensors\n","        output[\"ids\"] = torch.tensor(output[\"ids\"], dtype=torch.long)\n","        output[\"mask\"] = torch.tensor(output[\"mask\"], dtype=torch.long)\n","\n","        return output\n","\n","\n","class EarlyStopping(Callback):\n","    def __init__(\n","        self,\n","        model_path,\n","        valid_df,\n","        valid_samples,\n","        batch_size,\n","        tokenizer,\n","        patience=5,\n","        mode=\"max\",\n","        delta=0.001,\n","        save_weights_only=True,\n","    ):\n","        self.patience = patience\n","        self.counter = 0\n","        self.mode = mode\n","        self.best_score = None\n","        self.early_stop = False\n","        self.delta = delta\n","        self.save_weights_only = save_weights_only\n","        self.model_path = model_path\n","        self.valid_samples = valid_samples\n","        self.batch_size = batch_size\n","        self.valid_df = valid_df\n","        self.tokenizer = tokenizer\n","\n","        if self.mode == \"min\":\n","            self.val_score = np.Inf\n","        else:\n","            self.val_score = -np.Inf\n","\n","    def on_epoch_end(self, model):\n","        model.eval()\n","        valid_dataset = FeedbackDatasetValid(self.valid_samples, 4096, self.tokenizer)\n","        collate = Collate(self.tokenizer)\n","\n","        preds_iter = model.predict(\n","            valid_dataset,\n","            batch_size=self.batch_size,\n","            n_jobs=-1,\n","            collate_fn=collate,\n","        )\n","\n","        final_preds = []\n","        final_scores = []\n","        for preds in preds_iter:\n","            pred_class = np.argmax(preds, axis=2)\n","            pred_scrs = np.max(preds, axis=2)\n","            for pred, pred_scr in zip(pred_class, pred_scrs):\n","                final_preds.append(pred.tolist())\n","                final_scores.append(pred_scr.tolist())\n","\n","        for j in range(len(self.valid_samples)):\n","            tt = [id_target_map[p] for p in final_preds[j][1:]]\n","            tt_score = final_scores[j][1:]\n","            self.valid_samples[j][\"preds\"] = tt\n","            self.valid_samples[j][\"pred_scores\"] = tt_score\n","\n","        submission = []\n","        min_thresh = {\n","            \"Lead\": 9,\n","            \"Position\": 5,\n","            \"Evidence\": 14,\n","            \"Claim\": 3,\n","            \"Concluding Statement\": 11,\n","            \"Counterclaim\": 6,\n","            \"Rebuttal\": 4,\n","        }\n","        proba_thresh = {\n","            \"Lead\": 0.7,\n","            \"Position\": 0.55,\n","            \"Evidence\": 0.65,\n","            \"Claim\": 0.55,\n","            \"Concluding Statement\": 0.7,\n","            \"Counterclaim\": 0.5,\n","            \"Rebuttal\": 0.55,\n","        }\n","\n","        for _, sample in enumerate(self.valid_samples):\n","            preds = sample[\"preds\"]\n","            offset_mapping = sample[\"offset_mapping\"]\n","            sample_id = sample[\"id\"]\n","            sample_text = sample[\"text\"]\n","            sample_pred_scores = sample[\"pred_scores\"]\n","\n","            # pad preds to same length as offset_mapping\n","            if len(preds) < len(offset_mapping):\n","                preds = preds + [\"O\"] * (len(offset_mapping) - len(preds))\n","                sample_pred_scores = sample_pred_scores + [0] * (len(offset_mapping) - len(sample_pred_scores))\n","\n","            idx = 0\n","            phrase_preds = []\n","            while idx < len(offset_mapping):\n","                start, _ = offset_mapping[idx]\n","                if preds[idx] != \"O\":\n","                    label = preds[idx][2:]\n","                else:\n","                    label = \"O\"\n","                phrase_scores = []\n","                phrase_scores.append(sample_pred_scores[idx])\n","                idx += 1\n","                while idx < len(offset_mapping):\n","                    if label == \"O\":\n","                        matching_label = \"O\"\n","                    else:\n","                        matching_label = f\"I-{label}\"\n","                    if preds[idx] == matching_label:\n","                        _, end = offset_mapping[idx]\n","                        phrase_scores.append(sample_pred_scores[idx])\n","                        idx += 1\n","                    else:\n","                        break\n","                if \"end\" in locals():\n","                    phrase = sample_text[start:end]\n","                    phrase_preds.append((phrase, start, end, label, phrase_scores))\n","\n","            temp_df = []\n","            for phrase_idx, (phrase, start, end, label, phrase_scores) in enumerate(phrase_preds):\n","                word_start = len(sample_text[:start].split())\n","                word_end = word_start + len(sample_text[start:end].split())\n","                word_end = min(word_end, len(sample_text.split()))\n","                ps = \" \".join([str(x) for x in range(word_start, word_end)])\n","                if label != \"O\":\n","                    if sum(phrase_scores) / len(phrase_scores) >= proba_thresh[label]:\n","                        temp_df.append((sample_id, label, ps))\n","\n","            temp_df = pd.DataFrame(temp_df, columns=[\"id\", \"class\", \"predictionstring\"])\n","\n","            submission.append(temp_df)\n","\n","        submission = pd.concat(submission).reset_index(drop=True)\n","        submission[\"len\"] = submission.predictionstring.apply(lambda x: len(x.split()))\n","\n","        def threshold(df):\n","            df = df.copy()\n","            for key, value in min_thresh.items():\n","                index = df.loc[df[\"class\"] == key].query(f\"len<{value}\").index\n","                df.drop(index, inplace=True)\n","            return df\n","\n","        submission = threshold(submission)\n","\n","        # drop len\n","        submission = submission.drop(columns=[\"len\"])\n","\n","        scr = score_feedback_comp(submission, self.valid_df, return_class_scores=True)\n","        print(scr)\n","        model.train()\n","\n","        epoch_score = scr[0]\n","        if self.mode == \"min\":\n","            score = -1.0 * epoch_score\n","        else:\n","            score = np.copy(epoch_score)\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(epoch_score, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            print(\"EarlyStopping counter: {} out of {}\".format(self.counter, self.patience))\n","            if self.counter >= self.patience:\n","                model.model_state = enums.ModelState.END\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(epoch_score, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, epoch_score, model):\n","        if epoch_score not in [-np.inf, np.inf, -np.nan, np.nan]:\n","            print(\"Validation score improved ({} --> {}). Saving model!\".format(self.val_score, epoch_score))\n","            model.save(self.model_path, weights_only=self.save_weights_only)\n","        self.val_score = epoch_score\n"],"metadata":{"id":"DqtRFPaUPlYR","executionInfo":{"status":"ok","timestamp":1646631181863,"user_tz":-540,"elapsed":2027,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"}},"execution":{"iopub.status.busy":"2022-03-05T17:25:19.798219Z","iopub.execute_input":"2022-03-05T17:25:19.798682Z","iopub.status.idle":"2022-03-05T17:25:20.969041Z","shell.execute_reply.started":"2022-03-05T17:25:19.798623Z","shell.execute_reply":"2022-03-05T17:25:20.968305Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["import argparse\n","import os\n","import random\n","import warnings\n","\n","import numpy as np\n","import pandas as pd\n","import tez\n","import torch\n","import torch.nn as nn\n","from sklearn import metrics\n","from torch.nn import functional as F\n","from transformers import AdamW, AutoConfig, AutoModel, AutoTokenizer, get_cosine_schedule_with_warmup\n","\n","# from utils import EarlyStopping, prepare_training_data, target_id_map\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","\n","def seed_everything(seed: int):\n","    random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    np.random.seed(seed)\n","#     torch.manual_seed(seed)\n","#     torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True\n","\n","\n","# def parse_args():\n","#     parser = argparse.ArgumentParser()\n","#     parser.add_argument(\"--fold\", type=int, required=True)\n","#     parser.add_argument(\"--model\", type=str, required=True)\n","#     parser.add_argument(\"--lr\", type=float, required=True)\n","#     parser.add_argument(\"--output\", type=str, default=\"../model\", required=False)\n","#     parser.add_argument(\"--input\", type=str, default=\"../input\", required=False)\n","#     parser.add_argument(\"--max_len\", type=int, default=1024, required=False)\n","#     parser.add_argument(\"--batch_size\", type=int, default=8, required=False)\n","#     parser.add_argument(\"--valid_batch_size\", type=int, default=8, required=False)\n","#     parser.add_argument(\"--epochs\", type=int, default=20, required=False)\n","#     parser.add_argument(\"--accumulation_steps\", type=int, default=1, required=False)\n","#     return parser.parse_args()\n","\n","# class args:\n","#     fold = 0\n","#     model = allenai/longformer-large-4096\n","#     lr = 1e-5\n","#     output = ../model\n","#     input = ../model\n","#     max_len = 1536\n","#     batch_size = 4\n","#     valid_batch_size = 4\n","#     epochs = 10\n","#     accumulation_steps = 1\n","\n","\n","class FeedbackDataset:\n","    def __init__(self, samples, max_len, tokenizer):\n","        self.samples = samples\n","        self.max_len = max_len\n","        self.tokenizer = tokenizer\n","        self.length = len(samples)\n","\n","    def __len__(self):\n","        return self.length\n","\n","    def __getitem__(self, idx):\n","        input_ids = self.samples[idx][\"input_ids\"]\n","        input_labels = self.samples[idx][\"input_labels\"]\n","        input_labels = [target_id_map[x] for x in input_labels]\n","        other_label_id = target_id_map[\"O\"]\n","        padding_label_id = target_id_map[\"PAD\"]\n","        # print(input_ids)\n","        # print(input_labels)\n","\n","        # add start token id to the input_ids\n","        input_ids = [self.tokenizer.cls_token_id] + input_ids\n","        input_labels = [other_label_id] + input_labels\n","\n","        if len(input_ids) > self.max_len - 1:\n","            input_ids = input_ids[: self.max_len - 1]\n","            input_labels = input_labels[: self.max_len - 1]\n","\n","        # add end token id to the input_ids\n","        input_ids = input_ids + [self.tokenizer.sep_token_id]\n","        input_labels = input_labels + [other_label_id]\n","\n","        attention_mask = [1] * len(input_ids)\n","\n","        padding_length = self.max_len - len(input_ids)\n","        if padding_length > 0:\n","            if self.tokenizer.padding_side == \"right\":\n","                input_ids = input_ids + [self.tokenizer.pad_token_id] * padding_length\n","                input_labels = input_labels + [padding_label_id] * padding_length\n","                attention_mask = attention_mask + [0] * padding_length\n","            else:\n","                input_ids = [self.tokenizer.pad_token_id] * padding_length + input_ids\n","                input_labels = [padding_label_id] * padding_length + input_labels\n","                attention_mask = [0] * padding_length + attention_mask\n","\n","        return {\n","            \"ids\": torch.tensor(input_ids, dtype=torch.long),\n","            \"mask\": torch.tensor(attention_mask, dtype=torch.long),\n","            \"targets\": torch.tensor(input_labels, dtype=torch.long),\n","        }\n"],"metadata":{"id":"UHZLF2TgPMLo","executionInfo":{"status":"ok","timestamp":1646631181863,"user_tz":-540,"elapsed":5,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"}},"execution":{"iopub.status.busy":"2022-03-05T17:25:28.263942Z","iopub.execute_input":"2022-03-05T17:25:28.264181Z","iopub.status.idle":"2022-03-05T17:25:28.610914Z","shell.execute_reply.started":"2022-03-05T17:25:28.264145Z","shell.execute_reply":"2022-03-05T17:25:28.610235Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["class FeedbackModel(tez.Model):\n","    def __init__(self, model_name, num_train_steps, learning_rate, num_labels, steps_per_epoch):\n","        super().__init__()\n","        self.learning_rate = learning_rate\n","        self.model_name = model_name\n","        self.num_train_steps = num_train_steps\n","        self.num_labels = num_labels\n","        self.steps_per_epoch = steps_per_epoch\n","        self.step_scheduler_after = \"batch\"\n","\n","        hidden_dropout_prob: float = 0.1\n","        layer_norm_eps: float = 1e-7\n","\n","        config = AutoConfig.from_pretrained(model_name)\n","\n","        config.update(\n","            {\n","                \"output_hidden_states\": True,\n","                \"hidden_dropout_prob\": hidden_dropout_prob,\n","                \"layer_norm_eps\": layer_norm_eps,\n","                \"add_pooling_layer\": False,\n","                \"num_labels\": self.num_labels,\n","            }\n","        )\n","        self.transformer = AutoModel.from_pretrained(model_name, config=config)\n","        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n","        self.dropout1 = nn.Dropout(0.1)\n","        self.dropout2 = nn.Dropout(0.2)\n","        self.dropout3 = nn.Dropout(0.3)\n","        self.dropout4 = nn.Dropout(0.4)\n","        self.dropout5 = nn.Dropout(0.5)\n","        self.output = nn.Linear(config.hidden_size, self.num_labels)\n","\n","    def fetch_optimizer(self):\n","        param_optimizer = list(self.named_parameters())\n","        no_decay = [\"bias\", \"LayerNorm.bias\"]\n","        optimizer_parameters = [\n","            {\n","                \"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","                \"weight_decay\": 0.01,\n","            },\n","            {\n","                \"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","                \"weight_decay\": 0.0,\n","            },\n","        ]\n","        opt = AdamW(optimizer_parameters, lr=self.learning_rate)\n","        return opt\n","\n","    def fetch_scheduler(self):\n","        sch = get_cosine_schedule_with_warmup(\n","            self.optimizer,\n","            num_warmup_steps=int(0.1 * self.num_train_steps),\n","            num_training_steps=self.num_train_steps,\n","            num_cycles=1,\n","            last_epoch=-1,\n","        )\n","        return sch\n","\n","    def loss(self, outputs, targets, attention_mask):\n","        loss_fct = nn.CrossEntropyLoss()\n","\n","        active_loss = attention_mask.view(-1) == 1\n","        active_logits = outputs.view(-1, self.num_labels)\n","        true_labels = targets.view(-1)\n","        outputs = active_logits.argmax(dim=-1)\n","        idxs = np.where(active_loss.cpu().numpy() == 1)[0]\n","        active_logits = active_logits[idxs]\n","        true_labels = true_labels[idxs].to(torch.long)\n","\n","        loss = loss_fct(active_logits, true_labels)\n","        return loss\n","\n","    def monitor_metrics(self, outputs, targets, attention_mask):\n","        active_loss = (attention_mask.view(-1) == 1).cpu().numpy()\n","        active_logits = outputs.view(-1, self.num_labels)\n","        true_labels = targets.view(-1).cpu().numpy()\n","        outputs = active_logits.argmax(dim=-1).cpu().numpy()\n","        idxs = np.where(active_loss == 1)[0]\n","        f1_score = metrics.f1_score(true_labels[idxs], outputs[idxs], average=\"macro\")\n","        return {\"f1\": f1_score}\n","\n","    def forward(self, ids, mask, token_type_ids=None, targets=None):\n","\n","        if token_type_ids:\n","            transformer_out = self.transformer(ids, mask, token_type_ids)\n","        else:\n","            transformer_out = self.transformer(ids, mask)\n","        sequence_output = transformer_out.last_hidden_state #(batch_size, sequence_length, hidden_size)\n","        sequence_output = self.dropout(sequence_output)\n","\n","        logits1 = self.output(self.dropout1(sequence_output))\n","        logits2 = self.output(self.dropout2(sequence_output))\n","        logits3 = self.output(self.dropout3(sequence_output))\n","        logits4 = self.output(self.dropout4(sequence_output))\n","        logits5 = self.output(self.dropout5(sequence_output))\n","\n","        logits = (logits1 + logits2 + logits3 + logits4 + logits5) / 5\n","        logits = torch.softmax(logits, dim=-1)\n","        loss = 0\n","\n","        if targets is not None:\n","            loss1 = self.loss(logits1, targets, attention_mask=mask)\n","            loss2 = self.loss(logits2, targets, attention_mask=mask)\n","            loss3 = self.loss(logits3, targets, attention_mask=mask)\n","            loss4 = self.loss(logits4, targets, attention_mask=mask)\n","            loss5 = self.loss(logits5, targets, attention_mask=mask)\n","            loss = (loss1 + loss2 + loss3 + loss4 + loss5) / 5\n","            f1_1 = self.monitor_metrics(logits1, targets, attention_mask=mask)[\"f1\"]\n","            f1_2 = self.monitor_metrics(logits2, targets, attention_mask=mask)[\"f1\"]\n","            f1_3 = self.monitor_metrics(logits3, targets, attention_mask=mask)[\"f1\"]\n","            f1_4 = self.monitor_metrics(logits4, targets, attention_mask=mask)[\"f1\"]\n","            f1_5 = self.monitor_metrics(logits5, targets, attention_mask=mask)[\"f1\"]\n","            f1 = (f1_1 + f1_2 + f1_3 + f1_4 + f1_5) / 5\n","            metric = {\"f1\": f1}\n","            return logits, loss, metric\n","\n","        return logits, loss, {}"],"metadata":{"id":"HfYui6e2PMJn","executionInfo":{"status":"ok","timestamp":1646631182206,"user_tz":-540,"elapsed":348,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"}},"execution":{"iopub.status.busy":"2022-03-05T17:25:28.613741Z","iopub.execute_input":"2022-03-05T17:25:28.614000Z","iopub.status.idle":"2022-03-05T17:25:28.639372Z","shell.execute_reply.started":"2022-03-05T17:25:28.613965Z","shell.execute_reply":"2022-03-05T17:25:28.638473Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import KFold\n","from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n","\n","df = pd.read_csv('../input/feedback-prize-2021/train.csv')\n","\n","# debug\n","if Config.debug :\n","    df = df.sample(n=100).reset_index(drop=True)\n","\n","dfx = pd.get_dummies(df, columns=[\"discourse_type\"]).groupby([\"id\"], as_index=False).sum()\n","cols = [c for c in dfx.columns if c.startswith(\"discourse_type_\") or c == \"id\" and c != \"discourse_type_num\"]\n","dfx = dfx[cols]\n","\n","mskf = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","labels = [c for c in dfx.columns if c != \"id\"]\n","dfx_labels = dfx[labels]\n","dfx[\"kfold\"] = -1\n","\n","for fold, (trn_, val_) in enumerate(mskf.split(dfx, dfx_labels)):\n","    print(len(trn_), len(val_))\n","    dfx.loc[val_, \"kfold\"] = fold\n","\n","df = df.merge(dfx[[\"id\", \"kfold\"]], on=\"id\", how=\"left\")\n","print(df.kfold.value_counts())\n","# df.to_csv(\"train_folds.csv\", index=False)"],"metadata":{"id":"4EbHe3WeBp5q","executionInfo":{"status":"ok","timestamp":1646631183942,"user_tz":-540,"elapsed":1738,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"}},"outputId":"49582c93-1698-44cb-8fa2-cbf83c809b82","execution":{"iopub.status.busy":"2022-03-05T17:25:36.455333Z","iopub.execute_input":"2022-03-05T17:25:36.457319Z","iopub.status.idle":"2022-03-05T17:25:38.200041Z","shell.execute_reply.started":"2022-03-05T17:25:36.457276Z","shell.execute_reply":"2022-03-05T17:25:38.199339Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["12477 3117\n","12474 3120\n","12475 3119\n","12475 3119\n","12475 3119\n","0    28997\n","2    28968\n","3    28904\n","1    28737\n","4    28687\n","Name: kfold, dtype: int64\n"]}]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    NUM_JOBS = 2\n","    \n","    class args:\n","        fold = 0\n","        model = 'google/bigbird-roberta-base'\n","        lr = 1e-5\n","        output = OUTPUT_EXP\n","        input = INPUT\n","        max_len = 1024 #1536\n","        batch_size = 4\n","        valid_batch_size = 4\n","        epochs = 10\n","        accumulation_steps = 1\n","\n","    # args = parse_args()\n","    seed_everything(42)\n","    os.makedirs(args.output, exist_ok=True)\n","    # df = pd.read_csv(os.path.join(args.input, \"train_folds.csv\"))\n","\n","    train_df = df[df[\"kfold\"] != args.fold].reset_index(drop=True)\n","    valid_df = df[df[\"kfold\"] == args.fold].reset_index(drop=True)\n","\n","    tokenizer = AutoTokenizer.from_pretrained(args.model)\n","    training_samples = prepare_training_data(train_df, tokenizer, args, num_jobs=NUM_JOBS)\n","    valid_samples = prepare_training_data(valid_df, tokenizer, args, num_jobs=NUM_JOBS)\n","\n","    train_dataset = FeedbackDataset(training_samples, args.max_len, tokenizer)\n","\n","    num_train_steps = int(len(train_dataset) / args.batch_size / args.accumulation_steps * args.epochs)\n","    print(num_train_steps)\n","\n","    model = FeedbackModel(\n","        model_name=args.model,\n","        num_train_steps=num_train_steps,\n","        learning_rate=args.lr,\n","        num_labels=len(target_id_map) - 1,\n","        steps_per_epoch=len(train_dataset) / args.batch_size,\n","    )\n","\n","    es = EarlyStopping(\n","        model_path=os.path.join(args.output, f\"model_{args.fold}.bin\"),\n","        valid_df=valid_df,\n","        valid_samples=valid_samples,\n","        batch_size=args.valid_batch_size,\n","        patience=5,\n","        mode=\"max\",\n","        delta=0.001,\n","        save_weights_only=True,\n","        tokenizer=tokenizer,\n","    )\n","\n","    model.fit(\n","        train_dataset,\n","        train_bs=args.batch_size,\n","        device=\"cuda\",\n","        epochs=args.epochs,\n","        callbacks=[es],\n","        fp16=True,\n","        accumulation_steps=args.accumulation_steps,\n","    )"],"metadata":{"id":"w1Iuv_ZPPMGf","outputId":"d315ad59-4e66-47ea-89b1-6896a1c0b877","executionInfo":{"status":"error","timestamp":1646632821423,"user_tz":-540,"elapsed":1637484,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"}},"execution":{"iopub.status.busy":"2022-03-05T17:25:38.201235Z","iopub.execute_input":"2022-03-05T17:25:38.201489Z","iopub.status.idle":"2022-03-05T17:27:50.989422Z","shell.execute_reply.started":"2022-03-05T17:25:38.201453Z","shell.execute_reply":"2022-03-05T17:27:50.988558Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":392}},"execution_count":22,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-23d11e55b63c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mtraining_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_JOBS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mvalid_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_JOBS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-18-ed19f3654d1e>\u001b[0m in \u001b[0;36mprepare_training_data\u001b[0;34m(df, tokenizer, args, num_jobs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     results = Parallel(n_jobs=num_jobs,)( \n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prepare_training_data_helper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_ids_splits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     )\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":[""],"metadata":{"id":"dSpBmd6t15ng","executionInfo":{"status":"aborted","timestamp":1646630941002,"user_tz":-540,"elapsed":10,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"}}},"execution_count":null,"outputs":[]}]}