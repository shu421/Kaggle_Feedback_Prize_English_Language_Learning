{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"colab":{"name":"nb003.ipynb","provenance":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","import sys\n","from pathlib import Path\n","\n","class Config:\n","    nb_name = 'nb003'\n","    if 'google.colab' in sys.modules:\n","        %cd drive/MyDrive/Kaggle_Feedback-Prize-Evaluating-Student-Writing/main/\n","    input = Path('../input/')\n","\n","# install packages\n","!pip install transformers sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EYful3zL8GIJ","executionInfo":{"status":"ok","timestamp":1643444798413,"user_tz":-540,"elapsed":11063,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"}},"outputId":"528a2741-12a0-4305-878a-6d3cf1be9a2a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n","[Errno 2] No such file or directory: 'drive/MyDrive/Kaggle_Feedback-Prize-Evaluating-Student-Writing/main/'\n","/content/drive/MyDrive/Kaggle_Feedback-Prize-Evaluating-Student-Writing/main\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.16.1)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n","Collecting tez\n","  Downloading tez-0.2.0-py3-none-any.whl (16 kB)\n","Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.4)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tez) (1.10.0+cu111)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Installing collected packages: tez\n","Successfully installed tez-0.2.0\n"]}]},{"cell_type":"code","source":["import gc\n","gc.enable()\n","\n","import sys\n","sys.path.append(\"../input/tez-lib/\")\n","\n","import os\n","\n","import numpy as np\n","import pandas as pd\n","import tez\n","import torch\n","import torch.nn as nn\n","from joblib import Parallel, delayed\n","from transformers import AutoConfig, AutoModel, AutoTokenizer"],"metadata":{"_uuid":"66c995cf-7cbb-421b-bdd3-24906f5fb886","_cell_guid":"e0e4bdf6-bcd9-4f82-a53b-9c5f685500a8","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-05T18:19:34.765636Z","iopub.execute_input":"2022-01-05T18:19:34.766525Z","iopub.status.idle":"2022-01-05T18:19:43.074135Z","shell.execute_reply.started":"2022-01-05T18:19:34.76641Z","shell.execute_reply":"2022-01-05T18:19:43.072934Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":394},"id":"Rw_XclMv8Esr","executionInfo":{"status":"error","timestamp":1643444776404,"user_tz":-540,"elapsed":727,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"}},"outputId":"287cbb22-f1bf-4a20-dd2a-ae0f3082b4ff"},"execution_count":3,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-1aceca6db2c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtez\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tez'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["target_id_map = {\n","    \"B-Lead\": 0,\n","    \"I-Lead\": 1,\n","    \"B-Position\": 2,\n","    \"I-Position\": 3,\n","    \"B-Evidence\": 4,\n","    \"I-Evidence\": 5,\n","    \"B-Claim\": 6,\n","    \"I-Claim\": 7,\n","    \"B-Concluding Statement\": 8,\n","    \"I-Concluding Statement\": 9,\n","    \"B-Counterclaim\": 10,\n","    \"I-Counterclaim\": 11,\n","    \"B-Rebuttal\": 12,\n","    \"I-Rebuttal\": 13,\n","    \"O\": 14,\n","    \"PAD\": -100,\n","}\n","\n","\n","id_target_map = {v: k for k, v in target_id_map.items()}\n","\n","class args1:\n","    input_path = \"../input/feedback-prize-2021/\"\n","    model = \"../input/longformerlarge4096/longformer-large-4096/\"\n","    tez_model= \"../input/fblongformerlarge1536/\"\n","    output = \".\"\n","    batch_size = 8\n","    max_len = 4096\n","    \n","class args2:\n","    input_path = \"../input/feedback-prize-2021/\"\n","    model = \"../input/longformerlarge4096/longformer-large-4096/\"\n","    tez_model= \"../input/tez-fb-large/\"\n","    output = \".\"\n","    batch_size = 8\n","    max_len = 4096"],"metadata":{"execution":{"iopub.status.busy":"2022-01-05T18:20:25.812387Z","iopub.execute_input":"2022-01-05T18:20:25.812686Z","iopub.status.idle":"2022-01-05T18:20:25.822348Z","shell.execute_reply.started":"2022-01-05T18:20:25.812656Z","shell.execute_reply":"2022-01-05T18:20:25.821316Z"},"trusted":true,"id":"3xfMxR5X8Esv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class FeedbackDataset:\n","    def __init__(self, samples, max_len, tokenizer):\n","        self.samples = samples\n","        self.max_len = max_len\n","        self.tokenizer = tokenizer\n","        self.length = len(samples)\n","\n","    def __len__(self):\n","        return self.length\n","\n","    def __getitem__(self, idx):\n","        input_ids = self.samples[idx][\"input_ids\"]\n","        # print(input_ids)\n","        # print(input_labels)\n","\n","        # add start token id to the input_ids\n","        input_ids = [self.tokenizer.cls_token_id] + input_ids\n","\n","        if len(input_ids) > self.max_len - 1:\n","            input_ids = input_ids[: self.max_len - 1]\n","\n","        # add end token id to the input_ids\n","        input_ids = input_ids + [self.tokenizer.sep_token_id]\n","        attention_mask = [1] * len(input_ids)\n","\n","        # padding_length = self.max_len - len(input_ids)\n","        # if padding_length > 0:\n","        #     if self.tokenizer.padding_side == \"right\":\n","        #         input_ids = input_ids + [self.tokenizer.pad_token_id] * padding_length\n","        #         attention_mask = attention_mask + [0] * padding_length\n","        #     else:\n","        #         input_ids = [self.tokenizer.pad_token_id] * padding_length + input_ids\n","        #         attention_mask = [0] * padding_length + attention_mask\n","\n","        # return {\n","        #     \"ids\": torch.tensor(input_ids, dtype=torch.long),\n","        #     \"mask\": torch.tensor(attention_mask, dtype=torch.long),\n","        # }\n","\n","        return {\n","            \"ids\": input_ids,\n","            \"mask\": attention_mask,\n","        }"],"metadata":{"execution":{"iopub.status.busy":"2022-01-05T18:20:26.277132Z","iopub.execute_input":"2022-01-05T18:20:26.277591Z","iopub.status.idle":"2022-01-05T18:20:26.28869Z","shell.execute_reply.started":"2022-01-05T18:20:26.277556Z","shell.execute_reply":"2022-01-05T18:20:26.287697Z"},"trusted":true,"id":"op0bREfm8Esv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Collate:\n","    def __init__(self, tokenizer):\n","        self.tokenizer = tokenizer\n","\n","    def __call__(self, batch):\n","        output = dict()\n","        output[\"ids\"] = [sample[\"ids\"] for sample in batch]\n","        output[\"mask\"] = [sample[\"mask\"] for sample in batch]\n","\n","        # calculate max token length of this batch\n","        batch_max = max([len(ids) for ids in output[\"ids\"]])\n","\n","        # add padding\n","        if self.tokenizer.padding_side == \"right\":\n","            output[\"ids\"] = [s + (batch_max - len(s)) * [self.tokenizer.pad_token_id] for s in output[\"ids\"]]\n","            output[\"mask\"] = [s + (batch_max - len(s)) * [0] for s in output[\"mask\"]]\n","        else:\n","            output[\"ids\"] = [(batch_max - len(s)) * [self.tokenizer.pad_token_id] + s for s in output[\"ids\"]]\n","            output[\"mask\"] = [(batch_max - len(s)) * [0] + s for s in output[\"mask\"]]\n","\n","        # convert to tensors\n","        output[\"ids\"] = torch.tensor(output[\"ids\"], dtype=torch.long)\n","        output[\"mask\"] = torch.tensor(output[\"mask\"], dtype=torch.long)\n","\n","        return output"],"metadata":{"id":"6oMCyrbX8Esw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class FeedbackModel(tez.Model):\n","    def __init__(self, model_name, num_labels):\n","        super().__init__()\n","        self.model_name = model_name\n","        self.num_labels = num_labels\n","        config = AutoConfig.from_pretrained(model_name)\n","\n","        hidden_dropout_prob: float = 0.1\n","        layer_norm_eps: float = 1e-7\n","        config.update(\n","            {\n","                \"output_hidden_states\": True,\n","                \"hidden_dropout_prob\": hidden_dropout_prob,\n","                \"layer_norm_eps\": layer_norm_eps,\n","                \"add_pooling_layer\": False,\n","            }\n","        )\n","        self.transformer = AutoModel.from_config(config)\n","        self.output = nn.Linear(config.hidden_size, self.num_labels)\n","\n","    def forward(self, ids, mask):\n","        transformer_out = self.transformer(ids, mask)\n","        sequence_output = transformer_out.last_hidden_state\n","        logits = self.output(sequence_output)\n","        logits = torch.softmax(logits, dim=-1)\n","        return logits, 0, {}"],"metadata":{"execution":{"iopub.status.busy":"2022-01-05T18:20:26.502033Z","iopub.execute_input":"2022-01-05T18:20:26.50234Z","iopub.status.idle":"2022-01-05T18:20:26.511671Z","shell.execute_reply.started":"2022-01-05T18:20:26.502308Z","shell.execute_reply":"2022-01-05T18:20:26.510519Z"},"trusted":true,"id":"QFSS1PxS8Esx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def _prepare_test_data_helper(args, tokenizer, ids):\n","    test_samples = []\n","    for idx in ids:\n","        filename = os.path.join(args.input_path, \"test\", idx + \".txt\")\n","        with open(filename, \"r\") as f:\n","            text = f.read()\n","\n","        encoded_text = tokenizer.encode_plus(\n","            text,\n","            add_special_tokens=False,\n","            return_offsets_mapping=True,\n","        )\n","        input_ids = encoded_text[\"input_ids\"]\n","        offset_mapping = encoded_text[\"offset_mapping\"]\n","\n","        sample = {\n","            \"id\": idx,\n","            \"input_ids\": input_ids,\n","            \"text\": text,\n","            \"offset_mapping\": offset_mapping,\n","        }\n","\n","        test_samples.append(sample)\n","    return test_samples\n","\n","\n","def prepare_test_data(df, tokenizer, args):\n","    test_samples = []\n","    ids = df[\"id\"].unique()\n","    ids_splits = np.array_split(ids, 4)\n","\n","    results = Parallel(n_jobs=4, backend=\"multiprocessing\")(\n","        delayed(_prepare_test_data_helper)(args, tokenizer, idx) for idx in ids_splits\n","    )\n","    for result in results:\n","        test_samples.extend(result)\n","\n","    return test_samples"],"metadata":{"execution":{"iopub.status.busy":"2022-01-05T18:20:26.715129Z","iopub.execute_input":"2022-01-05T18:20:26.715408Z","iopub.status.idle":"2022-01-05T18:20:26.725686Z","shell.execute_reply.started":"2022-01-05T18:20:26.715365Z","shell.execute_reply":"2022-01-05T18:20:26.724696Z"},"trusted":true,"id":"q5reqkxD8Esy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv(os.path.join(\"../input/feedback-prize-2021/\", \"sample_submission.csv\"))\n","df_ids = df[\"id\"].unique()\n","\n","tokenizer = AutoTokenizer.from_pretrained(args1.model)\n","test_samples = prepare_test_data(df, tokenizer, args1)\n","collate = Collate(tokenizer=tokenizer)\n","\n","raw_preds = []\n","for fold_ in range(10):\n","    current_idx = 0\n","    test_dataset = FeedbackDataset(test_samples, args1.max_len, tokenizer)\n","    \n","    if fold_ < 5:\n","        model = FeedbackModel(model_name=args1.model, num_labels=len(target_id_map) - 1)\n","        model.load(os.path.join(args1.tez_model, f\"model_{fold_}.bin\"), weights_only=True)\n","        preds_iter = model.predict(test_dataset, batch_size=args1.batch_size, n_jobs=-1, collate_fn=collate)\n","    else:\n","        model = FeedbackModel(model_name=args2.model, num_labels=len(target_id_map) - 1)\n","        model.load(os.path.join(args2.tez_model, f\"model_{fold_-5}.bin\"), weights_only=True)\n","        preds_iter = model.predict(test_dataset, batch_size=args2.batch_size, n_jobs=-1, collate_fn=collate)\n","        \n","    current_idx = 0\n","    \n","    for preds in preds_iter:\n","        preds = preds.astype(np.float16)\n","        preds = preds / 10\n","        if fold_ == 0:\n","            raw_preds.append(preds)\n","        else:\n","            raw_preds[current_idx] += preds\n","            current_idx += 1\n","    torch.cuda.empty_cache()\n","    gc.collect()"],"metadata":{"id":"XGxxz3408Esz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["final_preds = []\n","final_scores = []\n","\n","for rp in raw_preds:\n","    pred_class = np.argmax(rp, axis=2)\n","    pred_scrs = np.max(rp, axis=2)\n","    for pred, pred_scr in zip(pred_class, pred_scrs):\n","        pred = pred.tolist()\n","        pred_scr = pred_scr.tolist()\n","        final_preds.append(pred)\n","        final_scores.append(pred_scr)\n","\n","for j in range(len(test_samples)):\n","    tt = [id_target_map[p] for p in final_preds[j][1:]]\n","    tt_score = final_scores[j][1:]\n","    test_samples[j][\"preds\"] = tt\n","    test_samples[j][\"pred_scores\"] = tt_score"],"metadata":{"id":"Zu_2_1TH8Es2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def jn(pst, start, end):\n","    return \" \".join([str(x) for x in pst[start:end]])\n","\n","\n","def link_evidence(oof):\n","    thresh = 1\n","    idu = oof['id'].unique()\n","    idc = idu[1]\n","    eoof = oof[oof['class'] == \"Evidence\"]\n","    neoof = oof[oof['class'] != \"Evidence\"]\n","    for thresh2 in range(26,27, 1):\n","        retval = []\n","        for idv in idu:\n","            for c in  ['Lead', 'Position', 'Evidence', 'Claim', 'Concluding Statement',\n","                   'Counterclaim', 'Rebuttal']:\n","                q = eoof[(eoof['id'] == idv) & (eoof['class'] == c)]\n","                if len(q) == 0:\n","                    continue\n","                pst = []\n","                for i,r in q.iterrows():\n","                    pst = pst +[-1] + [int(x) for x in r['predictionstring'].split()]\n","                start = 1\n","                end = 1\n","                for i in range(2,len(pst)):\n","                    cur = pst[i]\n","                    end = i\n","                    #if pst[start] == 205:\n","                    #   print(cur, pst[start], cur - pst[start])\n","                    if (cur == -1 and c != 'Evidence') or ((cur == -1) and ((pst[i+1] > pst[end-1] + thresh) or (pst[i+1] - pst[start] > thresh2))):\n","                        retval.append((idv, c, jn(pst, start, end)))\n","                        start = i + 1\n","                v = (idv, c, jn(pst, start, end+1))\n","                #print(v)\n","                retval.append(v)\n","        roof = pd.DataFrame(retval, columns = ['id', 'class', 'predictionstring']) \n","        roof = roof.merge(neoof, how='outer')\n","        return roof\n","    "],"metadata":{"id":"_aLJ-qPe8Es3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["proba_thresh = {\n","    \"Lead\": 0.7,\n","    \"Position\": 0.55,\n","    \"Evidence\": 0.65,\n","    \"Claim\": 0.55,\n","    \"Concluding Statement\": 0.7,\n","    \"Counterclaim\": 0.5,\n","    \"Rebuttal\": 0.55,\n","}\n","\n","min_thresh = {\n","    \"Lead\": 9,\n","    \"Position\": 5,\n","    \"Evidence\": 14,\n","    \"Claim\": 3,\n","    \"Concluding Statement\": 11,\n","    \"Counterclaim\": 6,\n","    \"Rebuttal\": 4,\n","}\n","\n","submission = []\n","for sample_idx, sample in enumerate(test_samples):\n","    preds = sample[\"preds\"]\n","    offset_mapping = sample[\"offset_mapping\"]\n","    sample_id = sample[\"id\"]\n","    sample_text = sample[\"text\"]\n","    sample_input_ids = sample[\"input_ids\"]\n","    sample_pred_scores = sample[\"pred_scores\"]\n","    sample_preds = []\n","\n","    if len(preds) < len(offset_mapping):\n","        preds = preds + [\"O\"] * (len(offset_mapping) - len(preds))\n","        sample_pred_scores = sample_pred_scores + [0] * (len(offset_mapping) - len(sample_pred_scores))\n","    \n","    idx = 0\n","    phrase_preds = []\n","    while idx < len(offset_mapping):\n","        start, _ = offset_mapping[idx]\n","        if preds[idx] != \"O\":\n","            label = preds[idx][2:]\n","        else:\n","            label = \"O\"\n","        phrase_scores = []\n","        phrase_scores.append(sample_pred_scores[idx])\n","        idx += 1\n","        while idx < len(offset_mapping):\n","            if label == \"O\":\n","                matching_label = \"O\"\n","            else:\n","                matching_label = f\"I-{label}\"\n","            if preds[idx] == matching_label:\n","                _, end = offset_mapping[idx]\n","                phrase_scores.append(sample_pred_scores[idx])\n","                idx += 1\n","            else:\n","                break\n","        if \"end\" in locals():\n","            phrase = sample_text[start:end]\n","            phrase_preds.append((phrase, start, end, label, phrase_scores))\n","\n","    temp_df = []\n","    for phrase_idx, (phrase, start, end, label, phrase_scores) in enumerate(phrase_preds):\n","        word_start = len(sample_text[:start].split())\n","        word_end = word_start + len(sample_text[start:end].split())\n","        word_end = min(word_end, len(sample_text.split()))\n","        ps = \" \".join([str(x) for x in range(word_start, word_end)])\n","        if label != \"O\":\n","            if sum(phrase_scores) / len(phrase_scores) >= proba_thresh[label]:\n","                if len(ps.split()) >= min_thresh[label]:\n","                    temp_df.append((sample_id, label, ps))\n","    \n","    temp_df = pd.DataFrame(temp_df, columns=[\"id\", \"class\", \"predictionstring\"])\n","    submission.append(temp_df)\n","\n","submission = pd.concat(submission).reset_index(drop=True)\n","submission = link_evidence(submission)\n","submission.to_csv(\"submission.csv\", index=False)"],"metadata":{"id":"Y7l0Dbm88Es3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["submission.head()"],"metadata":{"execution":{"iopub.status.busy":"2022-01-05T18:26:47.003019Z","iopub.status.idle":"2022-01-05T18:26:47.004284Z","shell.execute_reply.started":"2022-01-05T18:26:47.003972Z","shell.execute_reply":"2022-01-05T18:26:47.004003Z"},"trusted":true,"id":"dgHwYj-D8Es4"},"execution_count":null,"outputs":[]}]}