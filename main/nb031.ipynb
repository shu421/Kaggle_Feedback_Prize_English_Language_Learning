{"cells":[{"cell_type":"markdown","metadata":{"id":"yHHiMfFSkk5Y"},"source":["# 概要\n","- train_test_split"]},{"cell_type":"markdown","metadata":{"id":"7bDVKrA728Vn"},"source":["## setup envirionment"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":132173,"status":"ok","timestamp":1646614251758,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"},"user_tz":-540},"id":"3zuiIZsfklQp","outputId":"f58331e3-6d9a-4dfe-fcdf-752025ad706f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Kaggle_Feedback-Prize-Evaluating-Student-Writing/main\n","\u001b[K     |████████████████████████████████| 1.2 MB 13.9 MB/s \n","\u001b[K     |████████████████████████████████| 3.8 MB 75.7 MB/s \n","\u001b[K     |████████████████████████████████| 831.4 MB 6.2 kB/s \n","\u001b[K     |████████████████████████████████| 22.1 MB 356 kB/s \n","\u001b[K     |████████████████████████████████| 1.9 MB 80.8 MB/s \n","\u001b[K     |████████████████████████████████| 7.6 MB 76.4 MB/s \n","\u001b[K     |████████████████████████████████| 67 kB 6.3 MB/s \n","\u001b[K     |████████████████████████████████| 596 kB 80.0 MB/s \n","\u001b[K     |████████████████████████████████| 6.5 MB 74.0 MB/s \n","\u001b[K     |████████████████████████████████| 895 kB 65.0 MB/s \n","\u001b[?25hMon Mar  7 00:50:51 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P0    24W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["import os\n","\n","if os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\") is None:\n","    ON_KAGGLE = False\n","else:\n","    ON_KAGGLE = True\n","if not ON_KAGGLE:\n","    import shutil\n","    from requests import get\n","\n","    from google.colab import drive, files\n","    # mount Google Drive\n","    drive.mount(\"/content/drive\")\n","    %cd drive/MyDrive/Kaggle_Feedback-Prize-Evaluating-Student-Writing/main/\n","    !pip install -qq sentencepiece transformers torch==1.9.1 torchvision==0.10.1 torchAudio==0.9.1 torchtext==0.10.1\n","    for dirname, _, filenames in os.walk('/kaggle/input'):\n","        for filename in filenames:\n","            print(os.path.join(dirname, filename))\n","!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"Ip73rtLOC8tV"},"source":["Config"]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":543,"status":"ok","timestamp":1646616213321,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"},"user_tz":-540},"id":"KgOMqia7C8Rn"},"outputs":[],"source":["class Config:\n","    name = 'nb031'\n","    model_savename = 'longformer-base'\n","    \n","    if ON_KAGGLE:\n","        model_name = '../input/pt-longformer-base' # https://www.kaggle.com/kishalmandal/pt-longformer-base\n","        # base_dir = '/content/drive/MyDrive/petfinder'\n","        data_dir = '../input/feedback-prize-2021/'\n","        pre_data_dir = './preprocessed/'\n","        model_dir = '.'\n","        output_dir = '.'\n","    else:\n","        # customize for my own Google Colab Environment\n","        # model_name = 'SpanBERT/spanbert-base-cased'\n","        model_name = 'allenai/longformer-base-4096' # download from Internet\n","        base_dir = '/content/drive/MyDrive/Kaggle_Feedback-Prize-Evaluating-Student-Writing/'\n","        data_dir = os.path.join(base_dir, 'input/feedback-prize-2021/')\n","        pre_data_dir = os.path.join(base_dir, 'data/preprocessed')\n","        model_dir = os.path.join(base_dir, f'model/{name}')\n","        output_dir = os.path.join(base_dir, f'output/{name}')\n","\n","    is_debug = False\n","    load_texts = True\n","    n_epoch = 15 # not to exceed runtime limits on Kaggle\n","    n_fold = 5\n","    verbose_steps = 50\n","    random_seed = 71\n","    max_length = 1024\n","    train_batch_size = 4\n","    valid_batch_size = 4\n","    lr = 5e-5\n","    num_labels = 15\n","    label_subtokens = True\n","    output_hidden_states = True\n","    hidden_dropout_prob = 0.1\n","    layer_norm_eps = 1e-7\n","    add_pooling_layer = False\n","    max_grad_norm = 10\n","    es_patience=1\n","    weight_decay = 0.01\n","    warmup_ratio = 0.1\n","    if is_debug:\n","        debug_sample = 1000\n","        verbose_steps = 16\n","        n_epoch = 1\n","        n_fold = 2"]},{"cell_type":"markdown","metadata":{"id":"iP34ixYneANA"},"source":["constants"]},{"cell_type":"code","execution_count":41,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1646616213686,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"},"user_tz":-540},"id":"e0IRAsjceDS2"},"outputs":[],"source":["IGNORE_INDEX = -100\n","NON_LABEL = -1\n","OUTPUT_LABELS = ['0', 'B-Lead', 'I-Lead', 'B-Position', 'I-Position', 'B-Claim', 'I-Claim', 'B-Counterclaim', 'I-Counterclaim', \n","                 'B-Rebuttal', 'I-Rebuttal', 'B-Evidence', 'I-Evidence', 'B-Concluding Statement', 'I-Concluding Statement']\n","LABELS_TO_IDS = {v:k for k,v in enumerate(OUTPUT_LABELS)}\n","IDS_TO_LABELS = {k:v for k,v in enumerate(OUTPUT_LABELS)}\n","\n","MIN_THRESH = {\n","    \"I-Lead\": 9,\n","    \"I-Position\": 5,\n","    \"I-Evidence\": 14,\n","    \"I-Claim\": 3,\n","    \"I-Concluding Statement\": 11,\n","    \"I-Counterclaim\": 6,\n","    \"I-Rebuttal\": 4,\n","}\n","\n","PROB_THRESH = {\n","    \"I-Lead\": 0.7,\n","    \"I-Position\": 0.55,\n","    \"I-Evidence\": 0.65,\n","    \"I-Claim\": 0.55,\n","    \"I-Concluding Statement\": 0.7,\n","    \"I-Counterclaim\": 0.5,\n","    \"I-Rebuttal\": 0.55,\n","}"]},{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1646616213687,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"},"user_tz":-540},"id":"ah8WKsqGHja0"},"outputs":[],"source":["if not ON_KAGGLE:\n","    if not os.path.exists(Config.model_dir):\n","        os.makedirs(Config.model_dir, exist_ok=True)\n","    if not os.path.exists(Config.output_dir):\n","        os.makedirs(Config.output_dir, exist_ok=True)"]},{"cell_type":"markdown","metadata":{"id":"1MzNuNB1kvb3"},"source":["### libraries"]},{"cell_type":"code","execution_count":43,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1646616214520,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"},"user_tz":-540},"id":"JnVna5XqnuWN"},"outputs":[],"source":["# if not ON_KAGGLE:\n","#     !pip install -qq transformers"]},{"cell_type":"code","execution_count":44,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1646616214521,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"},"user_tz":-540},"id":"DZe70phDk1QF"},"outputs":[],"source":["# general\n","import pandas as pd\n","import numpy as np\n","import time\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","%matplotlib inline\n","sns.set()\n","import random\n","from tqdm.notebook import tqdm\n","from sklearn.model_selection import KFold, train_test_split\n","from sklearn.metrics import accuracy_score\n","import gc\n","from collections import defaultdict\n","# nlp\n","from sklearn.feature_extraction.text import CountVectorizer\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","from transformers import (\n","    LongformerConfig, \n","    LongformerModel, \n","    LongformerTokenizerFast,\n","    AutoConfig,\n","    AutoModel, \n","    AutoTokenizer,\n","    logging)\n","logging.set_verbosity_warning()\n","logging.set_verbosity_error()\n","from torch.utils.data import Dataset, DataLoader\n","from torch.cuda.amp import autocast, GradScaler\n","\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","metadata":{"id":"OzvQtzK4ni9Q"},"source":["## preprocess\n","use corrected train.csv\n","\n","https://www.kaggle.com/nbroad/corrected-train-csv-feedback-prize/notebook"]},{"cell_type":"code","execution_count":45,"metadata":{"executionInfo":{"elapsed":2083,"status":"ok","timestamp":1646616216907,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"},"user_tz":-540},"id":"-wS1I6Xsmnla"},"outputs":[],"source":["if ON_KAGGLE:\n","    df_alltrain = pd.read_csv('../input/corrected-train-csv-feedback-prize/corrected_train.csv')\n","else:\n","    df_alltrain = pd.read_csv(f'{Config.data_dir}/corrected_train.csv')"]},{"cell_type":"code","execution_count":46,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1646616216907,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"},"user_tz":-540},"id":"wkADwF11m1nK"},"outputs":[],"source":["def agg_essays(train_flg):\n","    folder = 'train' if train_flg else 'test'\n","    names, texts =[], []\n","    for f in tqdm(list(os.listdir(f'{Config.data_dir}/{folder}'))):\n","        names.append(f.replace('.txt', ''))\n","        texts.append(open(f'{Config.data_dir}/{folder}/' + f, 'r').read())\n","        df_texts = pd.DataFrame({'id': names, 'text': texts})\n","\n","    df_texts['text_split'] = df_texts.text.str.split()\n","    print('Completed tokenizing texts.')\n","    return df_texts"]},{"cell_type":"code","execution_count":47,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1646616216908,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"},"user_tz":-540},"id":"5pL88Q7UqItJ"},"outputs":[],"source":["def ner(df_texts, df_train):\n","    all_entities = []\n","    for _,  row in tqdm(df_texts.iterrows(), total=len(df_texts)):\n","        total = len(row['text_split'])\n","        entities = ['0'] * total\n","\n","        for _, row2 in df_train[df_train['id'] == row['id']].iterrows():\n","            discourse = row2['discourse_type']\n","            list_ix = [int(x) for x in row2['predictionstring'].split(' ')]\n","            entities[list_ix[0]] = f'B-{discourse}'\n","            for k in list_ix[1:]: entities[k] = f'I-{discourse}'\n","        all_entities.append(entities)\n","\n","    df_texts['entities'] = all_entities\n","    print('Completed mapping discourse to each token.')\n","    return df_texts"]},{"cell_type":"code","execution_count":48,"metadata":{"executionInfo":{"elapsed":1942,"status":"ok","timestamp":1646616218841,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"},"user_tz":-540},"id":"IZKDoHIhhZiO"},"outputs":[],"source":["if not Config.load_texts:    \n","    def preprocess(df_train = None):\n","        if df_train is None:\n","            train_flg = False\n","        else:\n","            train_flg = True\n","        \n","        df_texts = agg_essays(train_flg)\n","\n","        if train_flg:\n","            df_texts = ner(df_texts, df_train)\n","        return df_texts\n","    \n","    alltrain_texts = preprocess(df_alltrain)\n","    test_texts = preprocess()\n","    # alltrain_texts.to_pickle('../input/fb-data/alltrain_texts_correct.pkl')\n","    # test_texts.to_pickle('../input/fb-data/test_texts_correct.pkl')\n","else:\n","    alltrain_texts = pd.read_pickle('../input/fb-data/alltrain_texts_correct.pkl')\n","    test_texts = pd.read_pickle('../input/fb-data/test_texts_correct.pkl')"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1646616218842,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"},"user_tz":-540},"id":"yDSJobRdjdqs","outputId":"8b2fb08d-1f94-4715-e9b4-15367d5edc49"},"outputs":[{"name":"stdout","output_type":"stream","text":["15594\n"]}],"source":["if Config.is_debug:\n","    alltrain_texts = alltrain_texts.sample(Config.debug_sample).reset_index(drop=True)\n","print(len(alltrain_texts))"]},{"cell_type":"markdown","metadata":{"id":"DKENi2ZOkJv1"},"source":["set seed \u0026 split train/test"]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1646616218842,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"},"user_tz":-540},"id":"zrYLMWzfljQ0","outputId":"dc52d3d1-48d8-47e0-e5e2-3640cdf32634"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n"]}],"source":["def seed_everything(seed=Config.random_seed):\n","    #os.environ['PYTHONSEED'] = str(seed)\n","    np.random.seed(seed%(2**32-1))\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic=True\n","    torch.backends.cudnn.benchmark = False\n","\n","seed_everything()\n","# device optimization\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else:\n","    device = torch.device('cpu')\n","\n","print(f'Using device: {device}')"]},{"cell_type":"code","execution_count":53,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1646616244748,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"},"user_tz":-540},"id":"zsZXHSH-vcGA"},"outputs":[],"source":["# def split_fold(df_train):\n","#     ids = df_train['id'].unique()\n","#     kf = KFold(n_splits=Config.n_fold, shuffle = True, random_state=Config.random_seed)\n","#     for i_fold, (_, valid_index) in enumerate(kf.split(ids)):\n","#         df_train.loc[valid_index,'fold'] = i_fold\n","    \n","#     return df_train\n","# alltrain_texts = split_fold(alltrain_texts)\n","# alltrain_texts.head()\n","\n","IDS = alltrain_texts['id'].unique()\n","train_idx = np.random.choice(np.arange(len(IDS)),int(0.9*len(IDS)),replace=False)\n","valid_idx = np.setdiff1d(np.arange(len(IDS)),train_idx)\n","\n","df_train = alltrain_texts[alltrain_texts.index.isin(train_idx)].reset_index(drop=True)\n","df_val = alltrain_texts[alltrain_texts.index.isin(valid_idx)].reset_index(drop=True)\n","\n","print('train:', df_train.shape)\n","print('valid:', df_val.shape)"]},{"cell_type":"markdown","metadata":{"id":"NjsguQtHonKZ"},"source":["## dataset"]},{"cell_type":"code","execution_count":54,"metadata":{"executionInfo":{"elapsed":451,"status":"ok","timestamp":1646616246608,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"},"user_tz":-540},"id":"-eRhZHHNprqv"},"outputs":[],"source":["class FeedbackPrizeDataset(Dataset):\n","    def __init__(self, dataframe, tokenizer, max_len, has_labels):\n","        self.len = len(dataframe)\n","        self.data = dataframe\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","        self.has_labels = has_labels\n","    \n","    def __getitem__(self, index):\n","        text = self.data['text'][index]\n","        encoding = self.tokenizer(\n","            text.split(),\n","            is_split_into_words = True,\n","            padding = 'max_length',\n","            truncation = True,\n","            max_length = self.max_len\n","        )\n","        word_ids = encoding.word_ids()\n","\n","        # targets\n","        if self.has_labels:\n","            word_labels = self.data.entities[index]\n","            prev_word_idx = None\n","            labels_ids = []\n","            for word_idx in word_ids:\n","                if word_idx is None:\n","                    labels_ids.append(IGNORE_INDEX)\n","                elif word_idx != prev_word_idx:\n","                    labels_ids.append(LABELS_TO_IDS[word_labels[word_idx]])\n","                else:\n","                    if Config.label_subtokens:\n","                        labels_ids.append(LABELS_TO_IDS[word_labels[word_idx]])\n","                    else:\n","                        labels_ids.append(IGNORE_INDEX)\n","                prev_word_idx = word_idx\n","            encoding['labels'] = labels_ids\n","        # convert to torch.tensor\n","        item = {k: torch.as_tensor(v) for k, v in encoding.items()}\n","        word_ids2 = [w if w is not None else NON_LABEL for w in word_ids]\n","        item['word_ids'] = torch.as_tensor(word_ids2)\n","        return item\n","\n","    def __len__(self):\n","        return self.len"]},{"cell_type":"markdown","metadata":{"id":"tIzPUw0n21Cq"},"source":["## utility function"]},{"cell_type":"code","execution_count":55,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1646616246608,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"},"user_tz":-540},"id":"CHZI4rsi2yO-"},"outputs":[],"source":["def active_logits(raw_logits, word_ids):\n","    word_ids = word_ids.view(-1)\n","    active_mask = word_ids.unsqueeze(1).expand(word_ids.shape[0], Config.num_labels)\n","    active_mask = active_mask != NON_LABEL\n","    active_logits = raw_logits.view(-1, Config.num_labels)\n","    active_logits = torch.masked_select(active_logits, active_mask) # return 1dTensor\n","    active_logits = active_logits.view(-1, Config.num_labels) \n","    return active_logits\n","\n","def active_labels(labels):\n","    active_mask = labels.view(-1) != IGNORE_INDEX\n","    active_labels = torch.masked_select(labels.view(-1), active_mask)\n","    return active_labels\n","\n","def active_preds_prob(active_logits):\n","    active_preds = torch.argmax(active_logits, axis = 1)\n","    active_preds_prob, _ = torch.max(active_logits, axis = 1)\n","    return active_preds, active_preds_prob"]},{"cell_type":"markdown","metadata":{"id":"6tJJuIK01jGT"},"source":["## evaluating function"]},{"cell_type":"code","execution_count":56,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1646616247135,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"},"user_tz":-540},"id":"NGIRUiBf1rkM"},"outputs":[],"source":["def calc_overlap(row):\n","    \"\"\"\n","    calculate the overlap between prediction and ground truth\n","    \"\"\"\n","    set_pred = set(row.new_predictionstring_pred.split(' '))\n","    set_gt = set(row.new_predictionstring_gt.split(' '))\n","    # length of each end intersection\n","    len_pred = len(set_pred)\n","    len_gt = len(set_gt)\n","    intersection = len(set_gt.intersection(set_pred))\n","    overlap_1 = intersection / len_gt\n","    overlap_2 = intersection / len_pred\n","    return [overlap_1, overlap_2]\n","\n","def score_feedback_comp(pred_df, gt_df):\n","    \"\"\"\n","    A function that scores for the kaggle\n","        Student Writing Competition\n","        \n","    Uses the steps in the evaluation page here:\n","        https://www.kaggle.com/c/feedback-prize-2021/overview/evaluation\n","    \"\"\"\n","    gt_df = gt_df[['id', 'discourse_type', 'new_predictionstring']].reset_index(drop = True).copy()\n","    pred_df = pred_df[['id', 'class', 'new_predictionstring']].reset_index(drop = True).copy()\n","    gt_df['gt_id'] = gt_df.index\n","    pred_df['pred_id'] = pred_df.index\n","    joined = pred_df.merge(\n","        gt_df,\n","        left_on = ['id', 'class'],\n","        right_on = ['id', 'discourse_type'],\n","        how = 'outer',\n","        suffixes = ['_pred', '_gt']\n","    )\n","    joined['new_predictionstring_gt'] =  joined['new_predictionstring_gt'].fillna(' ')\n","    joined['new_predictionstring_pred'] =  joined['new_predictionstring_pred'].fillna(' ')\n","    joined['overlaps'] = joined.apply(calc_overlap, axis = 1)\n","    # overlap over 0.5: true positive\n","    # If nultiple overlaps exists, the higher is taken.\n","    joined['overlap1'] = joined['overlaps'].apply(lambda x: eval(str(x))[0])\n","    joined['overlap2'] = joined['overlaps'].apply(lambda x: eval(str(x))[1])\n","\n","    joined['potential_TP'] = (joined['overlap1'] \u003e= 0.5) \u0026 (joined['overlap2'] \u003e= 0.5)\n","    joined['max_overlap'] = joined[['overlap1', 'overlap2']].max(axis = 1)\n","    tp_pred_ids = joined.query('potential_TP').sort_values('max_overlap', ascending = False)\\\n","                  .groupby(['id', 'new_predictionstring_gt']).first()['pred_id'].values\n","    \n","    fp_pred_ids = [p for p in joined['pred_id'].unique() if p not in tp_pred_ids]\n","    matched_gt_ids = joined.query('potential_TP')['gt_id'].unique()\n","    unmatched_gt_ids = [c for c in joined['gt_id'].unique() if c not in matched_gt_ids]\n","\n","    TP = len(tp_pred_ids)\n","    FP = len(fp_pred_ids)\n","    FN = len(unmatched_gt_ids)\n","    macro_f1_score = TP / (TP + 1/2 * (FP + FN))\n","    return macro_f1_score\n","\n","def oof_score(df_val, oof):\n","    f1score = []\n","    classes = ['Lead', 'Position','Claim', 'Counterclaim', 'Rebuttal','Evidence','Concluding Statement']\n","    for c in classes:\n","        pred_df = oof.loc[oof['class'] == c].copy()\n","        gt_df = df_val.loc[df_val['discourse_type'] == c].copy()\n","        f1 = score_feedback_comp(pred_df, gt_df)\n","        print(f'{c:\u003c10}: {f1:4f}')\n","        f1score.append(f1)\n","    f1avg = np.mean(f1score)\n","    return f1avg"]},{"cell_type":"markdown","metadata":{"id":"a6NYa6Op2Cwu"},"source":["## inferencing function"]},{"cell_type":"code","execution_count":57,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1646616248108,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"},"user_tz":-540},"id":"9wKfL0KO28Vy"},"outputs":[],"source":["def inference(model, dl, criterion, valid_flg):\n","    final_predictions = []\n","    final_predictions_prob = []\n","    stream = tqdm(dl)\n","    model.eval()\n","    \n","    valid_loss = 0\n","    valid_accuracy = 0\n","    all_logits = None\n","    for batch_idx, batch in enumerate(stream, start = 1):\n","        ids = batch['input_ids'].to(device, dtype = torch.long)\n","        mask = batch['attention_mask'].to(device, dtype = torch.long)\n","        with torch.no_grad():\n","            raw_logits = model(input_ids=ids, mask = mask)\n","        del ids, mask\n","        \n","        word_ids = batch['word_ids'].to(device, dtype = torch.long)\n","        if valid_flg:    \n","            raw_labels = batch['labels'].to(device, dtype = torch.long)\n","            logits = active_logits(raw_logits, word_ids)\n","            labels = active_labels(raw_labels)\n","            preds, preds_prob = active_preds_prob(logits)\n","            valid_accuracy += accuracy_score(labels.cpu().numpy(), preds.cpu().numpy())\n","            loss = criterion(logits, labels)\n","            valid_loss += loss.item()\n","        \n","        if batch_idx == 1:\n","            all_logits = raw_logits.cpu().numpy()\n","        else:\n","            all_logits = np.append(all_logits, raw_logits.cpu().numpy(), axis=0)\n","\n","    \n","    if valid_flg:        \n","        epoch_loss = valid_loss / batch_idx\n","        epoch_accuracy = valid_accuracy / batch_idx\n","    else:\n","        epoch_loss, epoch_accuracy = 0, 0\n","    return all_logits, epoch_loss, epoch_accuracy\n","\n","\n","def preds_class_prob(all_logits, dl):\n","    print(\"predict target class and its probabilty\")\n","    final_predictions = []\n","    final_predictions_score = []\n","    stream = tqdm(dl)\n","    len_sample = all_logits.shape[0]\n","\n","    for batch_idx, batch in enumerate(stream, start=0):\n","        for minibatch_idx in range(Config.valid_batch_size):\n","            sample_idx = int(batch_idx * Config.valid_batch_size + minibatch_idx)\n","            if sample_idx \u003e len_sample - 1 : break\n","            word_ids = batch['word_ids'][minibatch_idx].numpy()\n","            predictions =[]\n","            predictions_prob = []\n","            pred_class_id = np.argmax(all_logits[sample_idx], axis=1)\n","            pred_score = np.max(all_logits[sample_idx], axis=1)\n","            pred_class_labels = [IDS_TO_LABELS[i] for i in pred_class_id]\n","            prev_word_idx = -1\n","            for idx, word_idx in enumerate(word_ids):\n","                if word_idx == -1:\n","                    pass\n","                elif word_idx != prev_word_idx:\n","                    predictions.append(pred_class_labels[idx])\n","                    predictions_prob.append(pred_score[idx])\n","                    prev_word_idx = word_idx\n","            final_predictions.append(predictions)\n","            final_predictions_score.append(predictions_prob)\n","    return final_predictions, final_predictions_score"]},{"cell_type":"code","execution_count":58,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1646616248523,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"},"user_tz":-540},"id":"DwjxrC2WZYH8"},"outputs":[],"source":["def get_preds_onefold(model, df, dl, criterion, valid_flg):\n","    logits, valid_loss, valid_acc = inference(model, dl, criterion, valid_flg)\n","    all_preds, all_preds_prob = preds_class_prob(logits, dl)\n","    df_pred = post_process_pred(df, all_preds, all_preds_prob)\n","    return df_pred, valid_loss, valid_acc\n","\n","def get_preds_folds(df, dl, criterion, valid_flg=False):\n","    for i_fold in range(Config.n_fold):\n","        model_filename = os.path.join(Config.model_dir, f\"{Config.model_savename}_{i_fold}.bin\")\n","        print(f\"{model_filename} inference\")\n","        model = FeedbackModel()\n","        model = model.to(device)\n","        model.load_state_dict(torch.load(model_filename))\n","        logits, valid_loss, valid_acc = inference(model, dl, criterion, valid_flg)\n","        if i_fold == 0:\n","            avg_pred_logits = logits\n","        else:\n","            avg_pred_logits += logits\n","    avg_pred_logits /= Config.n_fold\n","    all_preds, all_preds_prob = preds_class_prob(avg_pred_logits, dl)\n","    df_pred = post_process_pred(df, all_preds, all_preds_prob)\n","    return df_pred\n","\n","def post_process_pred(df, all_preds, all_preds_prob):\n","    final_preds = []\n","    for i in range(len(df)):\n","        idx = df.id.values[i]\n","        pred = all_preds[i]\n","        pred_prob = all_preds_prob[i]\n","        j = 0\n","        while j \u003c len(pred):\n","            cls = pred[j]\n","            if cls == '0': j += 1\n","            else: cls = cls.replace('B', 'I')\n","            end = j + 1\n","            while end \u003c len(pred) and pred[end] == cls:\n","                end += 1\n","            if cls != '0' and cls !='':\n","                avg_score = np.mean(pred_prob[j:end])\n","                if end - j \u003e MIN_THRESH[cls] and avg_score \u003e PROB_THRESH[cls]:\n","                    final_preds.append((idx, cls.replace('I-', ''), ' '.join(map(str, list(range(j, end))))))\n","            j = end\n","    df_pred = pd.DataFrame(final_preds)\n","    df_pred.columns = ['id', 'class', 'new_predictionstring']\n","    return df_pred"]},{"cell_type":"markdown","metadata":{"id":"hCw88fKN2bWF"},"source":["## training and validating function"]},{"cell_type":"code","execution_count":59,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1646616248524,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"},"user_tz":-540},"id":"EJUnTD0w2aZJ"},"outputs":[],"source":["def train_fn(model, dl_train, optimizer, epoch, criterion, scheduler):\n","    model.train()\n","    train_loss = 0\n","    train_accuracy = 0\n","    stream = tqdm(dl_train)\n","    scaler = GradScaler()\n","\n","    for batch_idx, batch in enumerate(stream, start = 1):\n","        ids = batch['input_ids'].to(device, dtype = torch.long)\n","        mask = batch['attention_mask'].to(device, dtype = torch.long)\n","        raw_labels = batch['labels'].to(device, dtype = torch.long)\n","        word_ids = batch['word_ids'].to(device, dtype = torch.long)\n","        optimizer.zero_grad()\n","        with autocast():\n","            raw_logits = model(input_ids = ids, mask = mask)\n","        \n","        logits = active_logits(raw_logits, word_ids)\n","        labels = active_labels(raw_labels)\n","        preds, preds_prob = active_preds_prob(logits)\n","        train_accuracy += accuracy_score(labels.cpu().numpy(), preds.cpu().numpy())\n","        criterion = nn.CrossEntropyLoss()\n","        loss = criterion(logits, labels)\n","\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","        scheduler.step(loss)\n","        train_loss += loss.item()\n","\n","        if batch_idx % Config.verbose_steps == 0:\n","            loss_step = train_loss / batch_idx\n","            print(f'Epoch {epoch}/{Config.n_epoch} | {batch_idx:04d} steps: {loss_step}')\n","\n","    epoch_loss = train_loss / batch_idx\n","    epoch_accuracy = train_accuracy / batch_idx\n","    del dl_train, raw_logits, logits, raw_labels, preds, labels\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    print(f'epoch {epoch} - training loss: {epoch_loss:.4f}')\n","    print(f'epoch {epoch} - training accuracy: {epoch_accuracy:.4f}')\n","    return epoch_loss"]},{"cell_type":"code","execution_count":73,"metadata":{"executionInfo":{"elapsed":422,"status":"ok","timestamp":1646618468291,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"},"user_tz":-540},"id":"SUNaOnL5a5UM"},"outputs":[],"source":["def valid_fn(model, df_val, df_val_eval, dl_val, epoch, criterion):\n","    oof, valid_loss, valid_acc  = get_preds_onefold(model, df_val, dl_val, criterion, valid_flg=True)\n","    f1score =[]\n","    # classes = oof['class'].unique()\n","    classes = ['Lead', 'Position', 'Claim','Counterclaim', 'Rebuttal','Evidence','Concluding Statement']\n","    print(f\"Validation F1 scores\")\n","\n","    for c in classes:\n","        pred_df = oof.loc[oof['class'] == c].copy()\n","        gt_df = df_val_eval.loc[df_val_eval['discourse_type'] == c].copy()\n","        f1 = score_feedback_comp(pred_df, gt_df)\n","        print(f' * {c:\u003c10}: {f1:4f}')\n","        f1score.append(f1)\n","    f1avg = np.mean(f1score)\n","    print(f'Overall Validation avg F1: {f1avg:.4f} val_loss:{valid_loss:.4f} val_accuracy:{valid_acc:.4f}')\n","    return valid_loss, oof, f1avg"]},{"cell_type":"markdown","metadata":{"id":"EWkqnxVxZvgq"},"source":["# Early Stopping"]},{"cell_type":"code","execution_count":74,"metadata":{"executionInfo":{"elapsed":464,"status":"ok","timestamp":1646618471405,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"},"user_tz":-540},"id":"Jp3TgzKoZxHz"},"outputs":[],"source":["class EarlyStopping:\n","    \"\"\"earlystoppingクラス\"\"\"\n","\n","    def __init__(self, patience=5, verbose=False, direction='max'):\n","        \"\"\"引数：最小値の非更新数カウンタ、表示設定、モデル格納path\"\"\"\n","\n","        self.patience = patience    #設定ストップカウンタ\n","        self.verbose = verbose      #表示の有無\n","        self.counter = 0            #現在のカウンタ値\n","        self.best_score = None      #ベストスコア\n","        self.early_stop = False     #ストップフラグ\n","        self.direction = direction\n","        if self.direction == 'max':\n","            self.val_loss_init = -np.Inf\n","        elif self.direction == 'min':\n","            self.val_loss_init = np.Inf\n","\n","    def __call__(self, val_loss, model):\n","        \"\"\"\n","        特殊(call)メソッド\n","        実際に学習ループ内で最小lossを更新したか否かを計算させる部分\n","        \"\"\"\n","        if self.direction == 'max':\n","            self.score = val_loss\n","        elif self.direction == 'min':\n","            self.score = -val_loss\n","\n","        if self.best_score is None:  #1Epoch目の処理\n","            self.best_score = self.score   #1Epoch目はそのままベストスコアとして記録する\n","            self.checkpoint(val_loss, model)  #記録後にモデルを保存してスコア表示する\n","        elif self.score \u003c self.best_score:  # ベストスコアを更新できなかった場合\n","            self.counter += 1   #ストップカウンタを+1\n","            if self.verbose:  #表示を有効にした場合は経過を表示\n","                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')  #現在のカウンタを表示する \n","            if self.counter \u003e= self.patience:  #設定カウントを上回ったらストップフラグをTrueに変更\n","                self.early_stop = True\n","        else:  #ベストスコアを更新した場合\n","            self.best_score = self.score  #ベストスコアを上書き\n","            self.checkpoint(val_loss, model)  #モデルを保存してスコア表示\n","            self.counter = 0  #ストップカウンタリセット\n","\n","    def checkpoint(self, val_loss, model):\n","        '''ベストスコア更新時に実行されるチェックポイント関数'''\n","        if self.verbose:  #表示を有効にした場合は、前回のベストスコアからどれだけ更新したか？を表示\n","            if self.direction == 'max':\n","                print(f'Validation loss increased ({self.val_loss_init:.6f} --\u003e {val_loss:.6f}).  Saving model ...')\n","            else:\n","                print(f'Validation loss decreased ({self.val_loss_init:.6f} --\u003e {val_loss:.6f}).  Saving model ...')\n","        self.val_loss_init = val_loss  #その時のlossを記録する"]},{"cell_type":"markdown","metadata":{"id":"1IlhXGIXZeml"},"source":["# Model"]},{"cell_type":"code","execution_count":75,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1646618471405,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"},"user_tz":-540},"id":"0Tg5LxPbZglV"},"outputs":[],"source":["class FeedbackModel(nn.Module):\n","    def __init__(self):\n","        super(FeedbackModel, self).__init__()\n","        model_config = LongformerConfig.from_pretrained(Config.model_name)\n","        model_config.update({\"output_hidden_states\":True, \n","                             \"hidden_dropout_prob\": 0.0,\n","                            #  \"add_pooling_layer\": False,\n","                             \"layer_norm_eps\": 1e-7})\n","        self.attention = nn.Sequential(           \n","            nn.Linear(768, 512),            \n","            nn.Tanh(),                       \n","            nn.Linear(512, 1),\n","            nn.Softmax(dim=1)\n","        )\n","        self.lstm = nn.LSTM(model_config.hidden_size, model_config.hidden_size, batch_first=True)                            \n","        self.model = LongformerModel.from_pretrained(Config.model_name, config=model_config)\n","        self.model.gradient_checkpointing_enable()\n","        self.head = nn.Linear(model_config.hidden_size, Config.num_labels)\n","        # self.dropout = nn.Dropout(0.1)\n","    \n","    def forward(self, input_ids, mask):\n","        model_output = self.model(\n","                            input_ids=input_ids, \n","                            attention_mask=mask)\n","        sequence_output = model_output['last_hidden_state']\n","        # print(sequence_output.shape) # (32, 1024, 768)\n","        # print(sequence_output[-1].shape) # (1024, 768)\n","        logits = self.head(sequence_output) # (32, 1024, 15)\n","        \n","        # attention\n","        # last_layer_hidden_states = model_output.hidden_states[-1]\n","        # weights = self.attention(last_layer_hidden_states)\n","        # context_vector = weights * last_layer_hidden_states # (32, 1024, 768)\n","\n","        # max pooling\n","        # output= model_output['last_hidden_state']\n","        # print(output.shape)\n","        # logits = self.head(output)\n","        # print(logits.shape) # (32, 1024, 15)\n","\n","        # lstm\n","        # out, _ = self.lstm(model_output['last_hidden_state'], None)\n","        # sequence_output = out[:, -1, :]\n","        # logits = self.head(sequence_output)\n","        return logits"]},{"cell_type":"markdown","metadata":{"id":"83QJcq4h1Wy2"},"source":["# Training loop\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000},"id":"Z8VJd-zodQyg"},"outputs":[{"name":"stdout","output_type":"stream","text":["------------------------------ Epoch1 ------------------------------\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"21c756905de14c2e8ee1ae2d93629144","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3509 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1/15 | 0050 steps: 1.58763671875\n","Epoch 1/15 | 0100 steps: 1.401689453125\n","Epoch 1/15 | 0150 steps: 1.3063346354166667\n","Epoch 1/15 | 0200 steps: 1.3052490234375\n","Epoch 1/15 | 0250 steps: 1.272275390625\n","Epoch 1/15 | 0300 steps: 1.2322347005208334\n","Epoch 1/15 | 0350 steps: 1.2024693080357143\n","Epoch 1/15 | 0400 steps: 1.170775146484375\n","Epoch 1/15 | 0450 steps: 1.1457552083333333\n","Epoch 1/15 | 0500 steps: 1.1373349609375\n","Epoch 1/15 | 0550 steps: 1.11572265625\n","Epoch 1/15 | 0600 steps: 1.1063509114583334\n","Epoch 1/15 | 0650 steps: 1.093309044471154\n","Epoch 1/15 | 0700 steps: 1.0852162388392856\n","Epoch 1/15 | 0750 steps: 1.0801796875\n","Epoch 1/15 | 0800 steps: 1.0730572509765626\n","Epoch 1/15 | 0850 steps: 1.060520450367647\n","Epoch 1/15 | 0900 steps: 1.0500821940104166\n","Epoch 1/15 | 0950 steps: 1.0394114925986842\n","Epoch 1/15 | 1000 steps: 1.030926025390625\n","Epoch 1/15 | 1050 steps: 1.0227099609375\n","Epoch 1/15 | 1100 steps: 1.0156043590198864\n","Epoch 1/15 | 1150 steps: 1.0066147248641304\n","Epoch 1/15 | 1200 steps: 0.9971824137369791\n","Epoch 1/15 | 1250 steps: 0.9902017578125\n","Epoch 1/15 | 1300 steps: 0.9834226637620193\n","Epoch 1/15 | 1350 steps: 0.9790661168981482\n","Epoch 1/15 | 1400 steps: 0.9730172293526785\n","Epoch 1/15 | 1450 steps: 0.9681586745689655\n","Epoch 1/15 | 1500 steps: 0.9627591145833333\n","Epoch 1/15 | 1550 steps: 0.9565051663306452\n","Epoch 1/15 | 1600 steps: 0.9539434814453125\n","Epoch 1/15 | 1650 steps: 0.949249082623106\n","Epoch 1/15 | 1700 steps: 0.9452827722886029\n","Epoch 1/15 | 1750 steps: 0.9424603794642857\n","Epoch 1/15 | 1800 steps: 0.9386488172743056\n","Epoch 1/15 | 1850 steps: 0.9365308277027027\n","Epoch 1/15 | 1900 steps: 0.9325840357730263\n","Epoch 1/15 | 1950 steps: 0.9296133814102564\n","Epoch 1/15 | 2000 steps: 0.9296439208984375\n","Epoch 1/15 | 2050 steps: 0.9288594464557927\n","Epoch 1/15 | 2100 steps: 0.9284935360863096\n","Epoch 1/15 | 2150 steps: 0.9275029523982559\n","Epoch 1/15 | 2200 steps: 0.9260091885653409\n","Epoch 1/15 | 2250 steps: 0.9243272569444444\n","Epoch 1/15 | 2300 steps: 0.9226396908967391\n","Epoch 1/15 | 2350 steps: 0.9206754903590425\n","Epoch 1/15 | 2400 steps: 0.9190382893880208\n","Epoch 1/15 | 2450 steps: 0.9261766581632653\n","Epoch 1/15 | 2500 steps: 0.938673828125\n","Epoch 1/15 | 2550 steps: 0.9452180989583333\n","Epoch 1/15 | 2600 steps: 0.9453036733774038\n","Epoch 1/15 | 2650 steps: 0.9457241303066037\n","Epoch 1/15 | 2700 steps: 0.9442041015625\n","Epoch 1/15 | 2750 steps: 0.9427583451704545\n","Epoch 1/15 | 2800 steps: 0.9414000592912947\n","Epoch 1/15 | 2850 steps: 0.9388802939967106\n","Epoch 1/15 | 2900 steps: 0.9364581930226293\n","Epoch 1/15 | 2950 steps: 0.9333842856197034\n","Epoch 1/15 | 3000 steps: 0.942810791015625\n","Epoch 1/15 | 3050 steps: 0.9529856397284836\n","Epoch 1/15 | 3100 steps: 0.9628158864667339\n","Epoch 1/15 | 3150 steps: 0.9729237196180556\n","Epoch 1/15 | 3200 steps: 0.9827742767333985\n","Epoch 1/15 | 3250 steps: 0.9922811748798077\n","Epoch 1/15 | 3300 steps: 1.002199854995265\n","Epoch 1/15 | 3350 steps: 1.0105473851445896\n","Epoch 1/15 | 3400 steps: 1.0191678394990809\n","Epoch 1/15 | 3450 steps: 1.0276216457201086\n","Epoch 1/15 | 3500 steps: 1.0356575753348214\n","epoch 1 - training loss: 1.0372\n","epoch 1 - training accuracy: 0.6738\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7c38b7393c084f0083ceeb7e7906a791","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/390 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["predict target class and its probabilty\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"71497dea34e240e0a65b17062eabbb99","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/390 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Validation F1 scores\n"," * Lead      : 0.000000\n"," * Position  : 0.000000\n"," * Claim     : 0.000000\n"," * Counterclaim: 0.000000\n"," * Rebuttal  : 0.000000\n"," * Evidence  : 0.033421\n"," * Concluding Statement: 0.000000\n","Overall Validation avg F1: 0.0048 val_loss:1.6024 val_accuracy:0.5261\n","/content/drive/MyDrive/Kaggle_Feedback-Prize-Evaluating-Student-Writing/model/nb031/longformer-base.bin saved\n","Validation loss increased (-inf --\u003e 0.004774).  Saving model ...\n","------------------------------ Epoch2 ------------------------------\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8413c0095487442c8461760d28d8ff02","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3509 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 2/15 | 0050 steps: 1.54416015625\n","Epoch 2/15 | 0100 steps: 1.5795703125\n","Epoch 2/15 | 0150 steps: 1.5915364583333333\n","Epoch 2/15 | 0200 steps: 1.5873583984375\n","Epoch 2/15 | 0250 steps: 1.591015625\n","Epoch 2/15 | 0300 steps: 1.585625\n","Epoch 2/15 | 0350 steps: 1.58953125\n","Epoch 2/15 | 0400 steps: 1.59238037109375\n","Epoch 2/15 | 0450 steps: 1.5953081597222223\n","Epoch 2/15 | 0500 steps: 1.595763671875\n","Epoch 2/15 | 0550 steps: 1.5957191051136363\n","Epoch 2/15 | 0600 steps: 1.5940641276041667\n","Epoch 2/15 | 0650 steps: 1.5985426682692307\n","Epoch 2/15 | 0700 steps: 1.5973590959821429\n","Epoch 2/15 | 0750 steps: 1.5993489583333333\n","Epoch 2/15 | 0800 steps: 1.599674072265625\n","Epoch 2/15 | 0850 steps: 1.5980721507352942\n","Epoch 2/15 | 0900 steps: 1.5986241319444445\n","Epoch 2/15 | 0950 steps: 1.6010444078947368\n","Epoch 2/15 | 1000 steps: 1.6021650390625\n","Epoch 2/15 | 1050 steps: 1.602432105654762\n","Epoch 2/15 | 1100 steps: 1.603251953125\n","Epoch 2/15 | 1150 steps: 1.6033457880434783\n","Epoch 2/15 | 1200 steps: 1.6018839518229167\n","Epoch 2/15 | 1250 steps: 1.60068515625\n","Epoch 2/15 | 1300 steps: 1.6005401141826923\n","Epoch 2/15 | 1350 steps: 1.599790943287037\n","Epoch 2/15 | 1400 steps: 1.5989969308035714\n","Epoch 2/15 | 1450 steps: 1.5995541487068965\n","Epoch 2/15 | 1500 steps: 1.6000735677083333\n","Epoch 2/15 | 1550 steps: 1.600144279233871\n","Epoch 2/15 | 1600 steps: 1.5991253662109375\n","Epoch 2/15 | 1650 steps: 1.5988257575757576\n","Epoch 2/15 | 1700 steps: 1.5987339154411764\n","Epoch 2/15 | 1750 steps: 1.5983549107142858\n","Epoch 2/15 | 1800 steps: 1.5998529730902777\n","Epoch 2/15 | 1850 steps: 1.599670608108108\n","Epoch 2/15 | 1900 steps: 1.5989329769736842\n","Epoch 2/15 | 1950 steps: 1.5992723357371794\n","Epoch 2/15 | 2000 steps: 1.5996103515625\n","Epoch 2/15 | 2050 steps: 1.5995774580792683\n","Epoch 2/15 | 2100 steps: 1.5995126488095237\n","Epoch 2/15 | 2150 steps: 1.6004628452034884\n","Epoch 2/15 | 2200 steps: 1.6008988813920455\n","Epoch 2/15 | 2250 steps: 1.6006901041666666\n","Epoch 2/15 | 2300 steps: 1.6004369055706522\n","Epoch 2/15 | 2350 steps: 1.600543550531915\n","Epoch 2/15 | 2400 steps: 1.600230712890625\n","Epoch 2/15 | 2450 steps: 1.5993207908163265\n","Epoch 2/15 | 2500 steps: 1.599209765625\n","Epoch 2/15 | 2550 steps: 1.599098881740196\n","Epoch 2/15 | 2600 steps: 1.5990981820913461\n","Epoch 2/15 | 2650 steps: 1.5991973761792453\n","Epoch 2/15 | 2700 steps: 1.5992476851851851\n","Epoch 2/15 | 2750 steps: 1.599411221590909\n","Epoch 2/15 | 2800 steps: 1.5994771902901785\n","Epoch 2/15 | 2850 steps: 1.599036800986842\n","Epoch 2/15 | 2900 steps: 1.5997730334051725\n","Epoch 2/15 | 2950 steps: 1.6002065677966102\n","Epoch 2/15 | 3000 steps: 1.5997740885416667\n","Epoch 2/15 | 3050 steps: 1.599303919057377\n","Epoch 2/15 | 3100 steps: 1.5993006552419355\n","Epoch 2/15 | 3150 steps: 1.5991356646825396\n","Epoch 2/15 | 3200 steps: 1.5986703491210938\n","Epoch 2/15 | 3250 steps: 1.5982247596153847\n","Epoch 2/15 | 3300 steps: 1.5982016453598484\n","Epoch 2/15 | 3350 steps: 1.5982783348880596\n","Epoch 2/15 | 3400 steps: 1.5983071001838236\n","Epoch 2/15 | 3450 steps: 1.5980788609601448\n","Epoch 2/15 | 3500 steps: 1.598921875\n","epoch 2 - training loss: 1.5988\n","epoch 2 - training accuracy: 0.5291\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c8e0ba16ded249fbb297a3f1885e9c9e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/390 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["predict target class and its probabilty\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6513c4464eb6471591dd0df8a811a2d3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/390 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Validation F1 scores\n"," * Lead      : 0.000000\n"," * Position  : 0.000000\n"," * Claim     : 0.000000\n"," * Counterclaim: 0.000000\n"," * Rebuttal  : 0.000000\n"," * Evidence  : 0.033421\n"," * Concluding Statement: 0.000000\n","Overall Validation avg F1: 0.0048 val_loss:1.6009 val_accuracy:0.5261\n","/content/drive/MyDrive/Kaggle_Feedback-Prize-Evaluating-Student-Writing/model/nb031/longformer-base.bin saved\n","Validation loss increased (0.004774 --\u003e 0.004774).  Saving model ...\n","------------------------------ Epoch3 ------------------------------\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c0c388eb6f9e4adfa60a008609643fc1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3509 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 3/15 | 0050 steps: 1.6173828125\n","Epoch 3/15 | 0100 steps: 1.5978515625\n","Epoch 3/15 | 0150 steps: 1.6082356770833333\n","Epoch 3/15 | 0200 steps: 1.599169921875\n","Epoch 3/15 | 0250 steps: 1.59947265625\n","Epoch 3/15 | 0300 steps: 1.5960970052083334\n","Epoch 3/15 | 0350 steps: 1.593657924107143\n","Epoch 3/15 | 0400 steps: 1.5934619140625\n","Epoch 3/15 | 0450 steps: 1.5947612847222221\n","Epoch 3/15 | 0500 steps: 1.594490234375\n","Epoch 3/15 | 0550 steps: 1.5957102272727273\n","Epoch 3/15 | 0600 steps: 1.5983610026041666\n","Epoch 3/15 | 0650 steps: 1.5945012019230769\n","Epoch 3/15 | 0700 steps: 1.5967047991071428\n","Epoch 3/15 | 0750 steps: 1.59849609375\n","Epoch 3/15 | 0800 steps: 1.597879638671875\n","Epoch 3/15 | 0850 steps: 1.59482421875\n","Epoch 3/15 | 0900 steps: 1.594572482638889\n","Epoch 3/15 | 0950 steps: 1.5910536595394738\n","Epoch 3/15 | 1000 steps: 1.59415234375\n","Epoch 3/15 | 1050 steps: 1.5950027901785715\n","Epoch 3/15 | 1100 steps: 1.5940314275568181\n","Epoch 3/15 | 1150 steps: 1.5948811141304349\n","Epoch 3/15 | 1200 steps: 1.5939290364583334\n","Epoch 3/15 | 1250 steps: 1.59513203125\n","Epoch 3/15 | 1300 steps: 1.595733173076923\n","Epoch 3/15 | 1350 steps: 1.5931098090277778\n","Epoch 3/15 | 1400 steps: 1.5930050223214285\n","Epoch 3/15 | 1450 steps: 1.5936408943965517\n","Epoch 3/15 | 1500 steps: 1.593482421875\n","Epoch 3/15 | 1550 steps: 1.594582283266129\n","Epoch 3/15 | 1600 steps: 1.594075927734375\n","Epoch 3/15 | 1650 steps: 1.5929758522727273\n","Epoch 3/15 | 1700 steps: 1.5932806755514706\n","Epoch 3/15 | 1750 steps: 1.5937533482142856\n","Epoch 3/15 | 1800 steps: 1.5933414713541667\n","Epoch 3/15 | 1850 steps: 1.594859058277027\n","Epoch 3/15 | 1900 steps: 1.5956003289473684\n","Epoch 3/15 | 1950 steps: 1.595986077724359\n","Epoch 3/15 | 2000 steps: 1.59596923828125\n","Epoch 3/15 | 2050 steps: 1.5946579649390245\n","Epoch 3/15 | 2100 steps: 1.5948428199404763\n","Epoch 3/15 | 2150 steps: 1.5967237463662791\n","Epoch 3/15 | 2200 steps: 1.5979243607954545\n","Epoch 3/15 | 2250 steps: 1.59725390625\n","Epoch 3/15 | 2300 steps: 1.5964695142663043\n","Epoch 3/15 | 2350 steps: 1.597495428856383\n","Epoch 3/15 | 2400 steps: 1.5963370768229166\n","Epoch 3/15 | 2450 steps: 1.5966681281887756\n","Epoch 3/15 | 2500 steps: 1.596466796875\n","Epoch 3/15 | 2550 steps: 1.5964100796568628\n","Epoch 3/15 | 2600 steps: 1.5957572115384615\n","Epoch 3/15 | 2650 steps: 1.5952900206367924\n","Epoch 3/15 | 2700 steps: 1.5957107204861112\n","Epoch 3/15 | 2750 steps: 1.5957727272727273\n","Epoch 3/15 | 2800 steps: 1.5963874162946428\n","Epoch 3/15 | 2850 steps: 1.596958950109649\n","Epoch 3/15 | 2900 steps: 1.596517712823276\n","Epoch 3/15 | 2950 steps: 1.5969468352754237\n","Epoch 3/15 | 3000 steps: 1.59731640625\n","Epoch 3/15 | 3050 steps: 1.5966915343237704\n","Epoch 3/15 | 3100 steps: 1.5968551537298388\n","Epoch 3/15 | 3150 steps: 1.5973087177579366\n","Epoch 3/15 | 3200 steps: 1.5974459838867188\n","Epoch 3/15 | 3250 steps: 1.5971844951923078\n","Epoch 3/15 | 3300 steps: 1.597251124526515\n","Epoch 3/15 | 3350 steps: 1.5975405200559702\n","Epoch 3/15 | 3400 steps: 1.597691291360294\n","Epoch 3/15 | 3450 steps: 1.5969771852355072\n","Epoch 3/15 | 3500 steps: 1.5964517299107144\n","epoch 3 - training loss: 1.5965\n","epoch 3 - training accuracy: 0.5295\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9eaaabc63836433aa6c24e8a2ad07391","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/390 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["predict target class and its probabilty\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"00ea9df8177c435f83c11ca977592a70","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/390 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Validation F1 scores\n"," * Lead      : 0.000000\n"," * Position  : 0.000000\n"," * Claim     : 0.000000\n"," * Counterclaim: 0.000000\n"," * Rebuttal  : 0.000000\n"," * Evidence  : 0.033421\n"," * Concluding Statement: 0.000000\n","Overall Validation avg F1: 0.0048 val_loss:1.6023 val_accuracy:0.5261\n","Validation loss increased (0.004774 --\u003e 0.004774).  Saving model ...\n","------------------------------ Epoch4 ------------------------------\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a4eb98f033f4444d9e58b201d9423875","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3509 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 4/15 | 0050 steps: 1.58208984375\n","Epoch 4/15 | 0100 steps: 1.607724609375\n","Epoch 4/15 | 0150 steps: 1.5955143229166666\n","Epoch 4/15 | 0200 steps: 1.5998876953125\n","Epoch 4/15 | 0250 steps: 1.5985703125\n","Epoch 4/15 | 0300 steps: 1.6017643229166667\n","Epoch 4/15 | 0350 steps: 1.5994252232142858\n","Epoch 4/15 | 0400 steps: 1.5990478515625\n","Epoch 4/15 | 0450 steps: 1.5989105902777778\n","Epoch 4/15 | 0500 steps: 1.5978046875\n","Epoch 4/15 | 0550 steps: 1.5926988636363637\n","Epoch 4/15 | 0600 steps: 1.5902848307291666\n","Epoch 4/15 | 0650 steps: 1.5923061899038462\n","Epoch 4/15 | 0700 steps: 1.593099888392857\n","Epoch 4/15 | 0750 steps: 1.5934856770833334\n","Epoch 4/15 | 0800 steps: 1.595323486328125\n","Epoch 4/15 | 0850 steps: 1.59783203125\n","Epoch 4/15 | 0900 steps: 1.5995659722222222\n","Epoch 4/15 | 0950 steps: 1.5985361842105263\n","Epoch 4/15 | 1000 steps: 1.5974150390625\n","Epoch 4/15 | 1050 steps: 1.5971233258928572\n","Epoch 4/15 | 1100 steps: 1.5981214488636364\n","Epoch 4/15 | 1150 steps: 1.598762737771739\n","Epoch 4/15 | 1200 steps: 1.5998795572916666\n","Epoch 4/15 | 1250 steps: 1.59819609375\n","Epoch 4/15 | 1300 steps: 1.5973106971153845\n","Epoch 4/15 | 1350 steps: 1.5988310185185186\n","Epoch 4/15 | 1400 steps: 1.5981284877232143\n","Epoch 4/15 | 1450 steps: 1.598721713362069\n","Epoch 4/15 | 1500 steps: 1.59925390625\n","Epoch 4/15 | 1550 steps: 1.5997259324596773\n","Epoch 4/15 | 1600 steps: 1.599466552734375\n","Epoch 4/15 | 1650 steps: 1.598291903409091\n","Epoch 4/15 | 1700 steps: 1.5973288143382354\n","Epoch 4/15 | 1750 steps: 1.59687109375\n","Epoch 4/15 | 1800 steps: 1.5965207248263888\n","Epoch 4/15 | 1850 steps: 1.5966670185810812\n","Epoch 4/15 | 1900 steps: 1.5963240131578946\n","Epoch 4/15 | 1950 steps: 1.5961157852564103\n","Epoch 4/15 | 2000 steps: 1.59546826171875\n","Epoch 4/15 | 2050 steps: 1.5945917492378048\n","Epoch 4/15 | 2100 steps: 1.593730003720238\n","Epoch 4/15 | 2150 steps: 1.5939980014534885\n","Epoch 4/15 | 2200 steps: 1.5936421342329545\n","Epoch 4/15 | 2250 steps: 1.5929535590277777\n","Epoch 4/15 | 2300 steps: 1.5929598335597825\n","Epoch 4/15 | 2350 steps: 1.592436835106383\n","Epoch 4/15 | 2400 steps: 1.5932194010416667\n","Epoch 4/15 | 2450 steps: 1.5940174585459184\n"]}],"source":["start_time = time.time()\n","\n","oof = pd.DataFrame()\n","tokenizer = LongformerTokenizerFast.from_pretrained(Config.model_name, add_prefix_space = True)\n","model = FeedbackModel()\n","model = model.to(device)\n","optimizer = torch.optim.AdamW(params=model.parameters(), lr=1e-4, weight_decay=Config.weight_decay)\n","scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20)\n","\n","# df_train = alltrain_texts[alltrain_texts['fold'] != i_fold].reset_index(drop = True)\n","ds_train = FeedbackPrizeDataset(df_train, tokenizer, Config.max_length, True)\n","# df_val = alltrain_texts[alltrain_texts['fold'] == i_fold].reset_index(drop = True)\n","val_idlist = df_val['id'].unique().tolist()\n","df_val_eval = df_alltrain.query('id==@val_idlist').reset_index(drop=True)\n","ds_val = FeedbackPrizeDataset(df_val, tokenizer, Config.max_length, True)\n","dl_train = DataLoader(ds_train, batch_size=Config.train_batch_size, shuffle=True, num_workers=2, pin_memory=True)\n","dl_val = DataLoader(ds_val, batch_size=Config.valid_batch_size, shuffle=False, num_workers=2, pin_memory=True)\n","\n","best_val_loss = np.inf\n","criterion = nn.CrossEntropyLoss()\n","\n","train_loss_history = []\n","valid_loss_history = []\n","valid_f1_history = []\n","\n","# Early Stopping\n","model_filename = f'{Config.model_dir}/{Config.model_savename}.bin'\n","earlystopping = EarlyStopping(patience=Config.es_patience, verbose=True, direction='max') \n","\n","for epoch in range(1, Config.n_epoch + 1):\n","    print('-'*30, f'Epoch{epoch}', '-'*30)\n","    # Training\n","    train_loss = train_fn(model, dl_train, optimizer, epoch, criterion, scheduler) # train\n","    train_loss_history.append(train_loss) # train lossの保存\n","\n","    # Validation\n","    valid_loss, _oof, val_f1avg = valid_fn(model, df_val, df_val_eval, dl_val, epoch, criterion) # validation\n","    valid_loss_history.append(valid_loss) # valid lossの保存\n","    valid_f1_history.append(val_f1avg) # valid f1の保存\n","\n","    if valid_loss \u003c best_val_loss:\n","        best_val_loss = valid_loss\n","        _oof_fold_best = _oof\n","        # _oof_fold_best['fold'] = i_fold\n","        # validation lossを更新したらモデルを保存する\n","        torch.save(model.state_dict(), model_filename)\n","        print(f'{model_filename} saved')\n","\n","    # early stoppingに引っ掛かったらmodelを保存する\n","    earlystopping(val_f1avg, model) # callメソッド呼び出し\n","    if earlystopping.early_stop: #ストップフラグがTrueの場合、breakでforループを抜ける\n","        print(\"Early Stopping!\")\n","        break\n","print(f'Best f1 score: {np.max(valid_f1_history)}')\n","\n","# lossの描画\n","fig, ax = plt.subplots(1, 1, figsize=(10,6))\n","sns.lineplot(data=train_loss_history, label='train loss')\n","sns.lineplot(data=valid_loss_history, label='valid loss')\n","ax.set_title(f'loss history')\n","plt.legend();\n","\n","oof = pd.concat([oof, _oof_fold_best])\n","del df_train, ds_train, df_val, val_idlist, df_val_eval, ds_val, dl_train, dl_val, tokenizer, model, optimizer\n","gc.collect()\n","torch.cuda.empty_cache()\n","\n","# oof score\n","oof.to_csv(f'{Config.output_dir}/oof_{Config.name}.csv', index=False)\n","oof = pd.read_csv(f'{Config.output_dir}/oof_{Config.name}.csv')\n","\n","if Config.is_debug:\n","    idlist = alltrain_texts['id'].unique().tolist()\n","    df_train = df_alltrain.query('id==@idlist')\n","else:\n","    df_train = df_alltrain.copy()\n","print(f'overall cv score: {oof_score(df_train, oof)}')\n","\n","print('elapsed time:', f'{time.time() - start_time:.1f}s')\n","# 1.53396484375"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yAZya0QBvdOc"},"outputs":[],"source":["# oof score\n","oof = pd.read_csv(f'{Config.output_dir}/oof_{Config.name}.csv')\n","\n","if Config.is_debug:\n","    idlist = alltrain_texts['id'].unique().tolist()\n","    df_train = df_alltrain.query('id==@idlist')\n","else:\n","    df_train = df_alltrain.copy()\n","print(f'overall cv score: {oof_score(df_train, oof)}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"If6c97rHvdrB"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"nb031.ipynb","version":""},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"00db14986c834cc5b65b47f934fa2d1b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d708d8b13fba47588633853ff2bb103a","placeholder":"​","style":"IPY_MODEL_82a7e10a6ead4f96b8d8b0ba30f150ef","value":" 390/390 [00:02\u0026lt;00:00, 150.70it/s]"}},"03ac466a1fa543c6ab866871c079dd51":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c46c6323e2d94a64aef691bdd4a5938b","placeholder":"​","style":"IPY_MODEL_ae2b5f7c4ea44bdea2022c774ca1bcaf","value":" 390/390 [00:57\u0026lt;00:00,  6.30it/s]"}},"057166f11e594bbd9d90174d2ce4ef82":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b267f3f66714ada834d793a266b463f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a15c6a9cade4c04a28a80de3e5f8c4e","placeholder":"​","style":"IPY_MODEL_f8e96c50d77d497087649a98583487f0","value":" 3509/3509 [23:29\u0026lt;00:00,  2.85it/s]"}},"0c3bf9646d0e44929c60ba4ffdfbc22c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f56ecc35fd446869476c6289c209154","max":3509,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d71bd54e7bb2412fb5dffb28b167a441","value":3509}},"21c756905de14c2e8ee1ae2d93629144":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a4f0cb26c9b9452c8a0cc967b703cec2","IPY_MODEL_0c3bf9646d0e44929c60ba4ffdfbc22c","IPY_MODEL_0b267f3f66714ada834d793a266b463f"],"layout":"IPY_MODEL_2fdbff6f69214444bb6b5c0c95fb4be2"}},"25d3e67d99e54cf8bc9f600a0d0f89fd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"295142e2ad5b41d9b170469ebed1b371":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2aaaf7cc55d24f679ec90e9f90f6d9d7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2cfc6c10080144e1a2f3333644eab825":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f56ecc35fd446869476c6289c209154":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2fdbff6f69214444bb6b5c0c95fb4be2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a15c6a9cade4c04a28a80de3e5f8c4e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3dbc0006496941a0b6655d32ca395ebd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"425695c1b94147d6815da9b1ff1f6f3a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4bdf663440a444dfbec316fb59955db1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_db4d9a8f246d4113a9709eaf70eba98f","placeholder":"​","style":"IPY_MODEL_a8f70f3de6054d41b5f2487b2ef8cb8d","value":" 31%"}},"55442931f4d44d79a6381ff5ac3ad1e6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_da045247ac9b4fd4b93aa34d6aaaace7","max":390,"min":0,"orientation":"horizontal","style":"IPY_MODEL_25d3e67d99e54cf8bc9f600a0d0f89fd","value":390}},"57917a74e0d3452582477855c1405697":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_df5737d22e5a4c76bdf30f9df9de3cb3","max":390,"min":0,"orientation":"horizontal","style":"IPY_MODEL_425695c1b94147d6815da9b1ff1f6f3a","value":390}},"71497dea34e240e0a65b17062eabbb99":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b978231c2eeb4c46884b56ed76f4a270","IPY_MODEL_57917a74e0d3452582477855c1405697","IPY_MODEL_00db14986c834cc5b65b47f934fa2d1b"],"layout":"IPY_MODEL_abafec8b5c9d49798110596827a2f355"}},"7c38b7393c084f0083ceeb7e7906a791":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8c7d4b3fbf0a4119addb0860488e6fe2","IPY_MODEL_55442931f4d44d79a6381ff5ac3ad1e6","IPY_MODEL_03ac466a1fa543c6ab866871c079dd51"],"layout":"IPY_MODEL_2aaaf7cc55d24f679ec90e9f90f6d9d7"}},"82a7e10a6ead4f96b8d8b0ba30f150ef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8413c0095487442c8461760d28d8ff02":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4bdf663440a444dfbec316fb59955db1","IPY_MODEL_a8274b9617fa423f94701a79b9c338f2","IPY_MODEL_ed4065858dd74bf8a139f0a0f4b08f0a"],"layout":"IPY_MODEL_3dbc0006496941a0b6655d32ca395ebd"}},"8c7d4b3fbf0a4119addb0860488e6fe2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_057166f11e594bbd9d90174d2ce4ef82","placeholder":"​","style":"IPY_MODEL_e40d5b967e2749258de3545ff49e82fe","value":"100%"}},"936ce70e9fb6466bb74cf7858a32c959":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"98665f80351b47f5b4768f714ffe184b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4f0cb26c9b9452c8a0cc967b703cec2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_98665f80351b47f5b4768f714ffe184b","placeholder":"​","style":"IPY_MODEL_295142e2ad5b41d9b170469ebed1b371","value":"100%"}},"a8274b9617fa423f94701a79b9c338f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_f58b91cb518e444faed274f08c888b7c","max":3509,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f3f9d603a7754dad9013f200f02979b8","value":1085}},"a8f70f3de6054d41b5f2487b2ef8cb8d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"abafec8b5c9d49798110596827a2f355":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae2b5f7c4ea44bdea2022c774ca1bcaf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b978231c2eeb4c46884b56ed76f4a270":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2cfc6c10080144e1a2f3333644eab825","placeholder":"​","style":"IPY_MODEL_f42b5a6bc2e4497480f169627c311db3","value":"100%"}},"c46c6323e2d94a64aef691bdd4a5938b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d708d8b13fba47588633853ff2bb103a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d71bd54e7bb2412fb5dffb28b167a441":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"da045247ac9b4fd4b93aa34d6aaaace7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db4d9a8f246d4113a9709eaf70eba98f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df5737d22e5a4c76bdf30f9df9de3cb3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e40d5b967e2749258de3545ff49e82fe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed4065858dd74bf8a139f0a0f4b08f0a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f83dc99fe11c497ab3afe5974a5b9b4c","placeholder":"​","style":"IPY_MODEL_936ce70e9fb6466bb74cf7858a32c959","value":" 1085/3509 [07:15\u0026lt;16:12,  2.49it/s]"}},"f3f9d603a7754dad9013f200f02979b8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f42b5a6bc2e4497480f169627c311db3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f58b91cb518e444faed274f08c888b7c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f83dc99fe11c497ab3afe5974a5b9b4c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8e96c50d77d497087649a98583487f0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}