{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### reference https://github.com/abhishekkrthakur/long-text-token-classification/tree/8f636ea23b7e1842583581d9cbdbe9f0f54d3191 ","metadata":{"id":"5_2g37QvKzWg"}},{"cell_type":"markdown","source":"MyDrive/kaggle/feedback のディレクトリを作ってその中に入れると動くと思います","metadata":{"id":"QAZK6ncQTXsf"}},{"cell_type":"code","source":"class Config:\n    name = \"exp-001\" # 実験のたびにコピーしてここの名前を変えて実行するとoutputが別のファイルに保存される\n    debug = False # debug用の小さいデータになる\n\n    # Colab Env\n    upload_from_colab = False\n    api_path = \"/content/drive/MyDrive/kaggle/kaggle.json\" # kaggle.jsonを置いた場所\n    drive_path = \"/content/drive/MyDrive/kaggle/feedback\"\n    \n    # Kaggle Env\n    kaggle_dataset_path = None","metadata":{"id":"z7YNmSGL1p_5","executionInfo":{"status":"ok","timestamp":1645951033276,"user_tz":-540,"elapsed":7,"user":{"displayName":"鳴川彰将","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00422213483226230461"}},"execution":{"iopub.status.busy":"2022-03-05T17:24:57.951047Z","iopub.execute_input":"2022-03-05T17:24:57.951495Z","iopub.status.idle":"2022-03-05T17:24:57.980082Z","shell.execute_reply.started":"2022-03-05T17:24:57.951387Z","shell.execute_reply":"2022-03-05T17:24:57.979441Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport json\nimport warnings\nimport shutil\nimport logging\nimport joblib\nimport random\nimport datetime\nimport sys\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom tqdm.auto import tqdm\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\n\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\n\nimport lightgbm\nimport pickle\nfrom datetime import datetime\nfrom matplotlib import pyplot as plt\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.preprocessing import StandardScaler\nimport dateutil.easter as easter\nimport random\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import SGD, Adam\nfrom keras.layers.advanced_activations import ReLU, PReLU\nseed = 334","metadata":{"id":"VbXtfty816RE","executionInfo":{"status":"ok","timestamp":1645951038972,"user_tz":-540,"elapsed":5701,"user":{"displayName":"鳴川彰将","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00422213483226230461"}},"execution":{"iopub.status.busy":"2022-03-05T17:24:57.981343Z","iopub.execute_input":"2022-03-05T17:24:57.982091Z","iopub.status.idle":"2022-03-05T17:25:05.958789Z","shell.execute_reply.started":"2022-03-05T17:24:57.982051Z","shell.execute_reply":"2022-03-05T17:25:05.958075Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"COLAB = \"google.colab\" in sys.modules","metadata":{"id":"LhXvf-UB16Ol","executionInfo":{"status":"ok","timestamp":1645951038972,"user_tz":-540,"elapsed":4,"user":{"displayName":"鳴川彰将","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00422213483226230461"}},"execution":{"iopub.status.busy":"2022-03-05T17:25:05.961306Z","iopub.execute_input":"2022-03-05T17:25:05.961734Z","iopub.status.idle":"2022-03-05T17:25:05.965906Z","shell.execute_reply.started":"2022-03-05T17:25:05.961697Z","shell.execute_reply":"2022-03-05T17:25:05.965309Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!pip install --upgrade --force-reinstall --no-deps kaggle","metadata":{"id":"Ea4nxNzi16LE","executionInfo":{"status":"ok","timestamp":1645951044777,"user_tz":-540,"elapsed":5808,"user":{"displayName":"鳴川彰将","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00422213483226230461"}},"outputId":"1e53ce39-fb88-4658-e78a-d8055a2c1389","execution":{"iopub.status.busy":"2022-03-05T17:25:05.967513Z","iopub.execute_input":"2022-03-05T17:25:05.967886Z","iopub.status.idle":"2022-03-05T17:25:10.736937Z","shell.execute_reply.started":"2022-03-05T17:25:05.967851Z","shell.execute_reply":"2022-03-05T17:25:10.736148Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"if COLAB:\n    print(\"This environment is Google Colab\")\n    \n    # mount\n    from google.colab import drive\n    if not os.path.isdir(\"/content/drive\"):\n        drive.mount('/content/drive') \n\t\n    \n    # use kaggle api (need kaggle token)\n    f = open(Config.api_path, 'r')\n    json_data = json.load(f) \n    os.environ[\"KAGGLE_USERNAME\"] = json_data[\"username\"]\n    os.environ[\"KAGGLE_KEY\"] = json_data[\"key\"]\n    \n    # set dirs\n    DRIVE = Config.drive_path\n    EXP = Config.name\n    INPUT = os.path.join(DRIVE, \"Input\")\n    OUTPUT = os.path.join(DRIVE, \"Output\")\n    SCRIPT = os.path.join(DRIVE, \"Script\")\n    OUTPUT_EXP = os.path.join(OUTPUT, EXP) \n    # EXP_MODEL = os.path.join(OUTPUT_EXP, \"model\")\n    # EXP_FIG = os.path.join(OUTPUT_EXP, \"fig\")\n    # EXP_PREDS = os.path.join(OUTPUT_EXP, \"preds\")\n    INPUT = os.path.join(INPUT, 'feedback-prize-2021')\n    \n    # make dirs\n    for d in [INPUT, SCRIPT, OUTPUT, OUTPUT_EXP]:\n        os.makedirs(d, exist_ok=True)\n    \n\n    if not os.path.isfile(os.path.join(INPUT, \"train.csv\")):\n        # load dataset\n        ! kaggle competitions download -c feedback-prize-2021 -p $INPUT \n        unzip_file = os.path.join(INPUT, 'feedback-prize-2021.zip')\n        ! unzip $unzip_file -d $INPUT\n    \n\nelse:\n    print(\"This environment is Kaggle Kernel\")\n    \n    # set dirs\n    INPUT = \"../input/feedback-prize-2021\"\n#     EXP, OUTPUT, SUBMISSION = \"./\", \"./\", \"./\"\n#     EXP_MODEL = os.path.join(EXP, \"model\")\n#     EXP_FIG = os.path.join(EXP, \"fig\")\n#     EXP_PREDS = os.path.join(EXP, \"preds\")\n    \n#     # copy dirs\n#     if Config.kaggle_dataset_path is not None:\n#         KD_MODEL = os.path.join(Config.kaggle_dataset_path, \"model\")\n#         KD_EXP_PREDS = os.path.join(Config.kaggle_dataset_path, \"preds\")\n#         shutil.copytree(KD_MODEL, EXP_MODEL)\n#         shutil.copytree(KD_EXP_PREDS, EXP_PREDS)\n\n#     # make dirs\n#     for d in [EXP_MODEL, EXP_FIG, EXP_PREDS]:\n#         os.makedirs(d, exist_ok=True)\n    OUTPUT_EXP = './'\n        \n    ","metadata":{"id":"1YQXcS4z16IF","executionInfo":{"status":"ok","timestamp":1645951234827,"user_tz":-540,"elapsed":190053,"user":{"displayName":"鳴川彰将","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00422213483226230461"}},"outputId":"778a3f07-df5f-4191-bf04-a4c2afa5381a","execution":{"iopub.status.busy":"2022-03-05T17:25:10.738790Z","iopub.execute_input":"2022-03-05T17:25:10.739042Z","iopub.status.idle":"2022-03-05T17:25:10.759397Z","shell.execute_reply.started":"2022-03-05T17:25:10.739008Z","shell.execute_reply":"2022-03-05T17:25:10.758727Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"! pip install tez","metadata":{"id":"uZgt1q-iAuvk","executionInfo":{"status":"ok","timestamp":1645951240095,"user_tz":-540,"elapsed":5272,"user":{"displayName":"鳴川彰将","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00422213483226230461"}},"outputId":"0c5d5209-b952-4e98-cd2f-0763cc25950a","execution":{"iopub.status.busy":"2022-03-05T17:25:10.760494Z","iopub.execute_input":"2022-03-05T17:25:10.760726Z","iopub.status.idle":"2022-03-05T17:25:19.796195Z","shell.execute_reply.started":"2022-03-05T17:25:10.760692Z","shell.execute_reply":"2022-03-05T17:25:19.795409Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import copy\nimport os\n\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom joblib import Parallel, delayed\nfrom tez import enums\nfrom tez.callbacks import Callback\nfrom tqdm import tqdm\n\ntarget_id_map = {\n    \"B-Lead\": 0,\n    \"I-Lead\": 1,\n    \"B-Position\": 2,\n    \"I-Position\": 3,\n    \"B-Evidence\": 4,\n    \"I-Evidence\": 5,\n    \"B-Claim\": 6,\n    \"I-Claim\": 7,\n    \"B-Concluding Statement\": 8,\n    \"I-Concluding Statement\": 9,\n    \"B-Counterclaim\": 10,\n    \"I-Counterclaim\": 11,\n    \"B-Rebuttal\": 12,\n    \"I-Rebuttal\": 13,\n    \"O\": 14,\n    \"PAD\": -100,\n}\n\n\nid_target_map = {v: k for k, v in target_id_map.items()}\n\n\ndef _prepare_training_data_helper(args, tokenizer, df, train_ids):\n    training_samples = []\n    for idx in tqdm(train_ids):\n        filename = os.path.join(args.input, \"train\", idx + \".txt\")\n        with open(filename, \"r\") as f:\n            text = f.read()\n\n        encoded_text = tokenizer.encode_plus(\n            text,\n            add_special_tokens=False,\n            return_offsets_mapping=True,\n        )\n        input_ids = encoded_text[\"input_ids\"] # トークンごとに固有の数がふられる\n        input_labels = copy.deepcopy(input_ids)\n        offset_mapping = encoded_text[\"offset_mapping\"] # トークンの始まりと終わりの文字数\n\n        for k in range(len(input_labels)):\n            input_labels[k] = \"O\"\n\n        sample = {\n            \"id\": idx,\n            \"input_ids\": input_ids,\n            \"text\": text,\n            \"offset_mapping\": offset_mapping,\n        }\n\n        temp_df = df[df[\"id\"] == idx]\n        for _, row in temp_df.iterrows():\n            text_labels = [0] * len(text)\n            discourse_start = int(row[\"discourse_start\"])\n            discourse_end = int(row[\"discourse_end\"])\n            prediction_label = row[\"discourse_type\"]\n            text_labels[discourse_start:discourse_end] = [1] * (discourse_end - discourse_start)\n            target_idx = []\n            for map_idx, (offset1, offset2) in enumerate(encoded_text[\"offset_mapping\"]):\n                if sum(text_labels[offset1:offset2]) > 0:\n                    if len(text[offset1:offset2].split()) > 0:\n                        target_idx.append(map_idx)\n\n            targets_start = target_idx[0]\n            targets_end = target_idx[-1]\n            pred_start = \"B-\" + prediction_label\n            pred_end = \"I-\" + prediction_label\n            input_labels[targets_start] = pred_start\n            input_labels[targets_start + 1 : targets_end + 1] = [pred_end] * (targets_end - targets_start)\n\n        sample[\"input_ids\"] = input_ids\n        sample[\"input_labels\"] = input_labels\n        training_samples.append(sample)\n    return training_samples\n\n\ndef prepare_training_data(df, tokenizer, args, num_jobs):\n    training_samples = []\n    train_ids = df[\"id\"].unique()\n\n    train_ids_splits = np.array_split(train_ids, num_jobs)\n\n    results = Parallel(n_jobs=num_jobs,)( \n        delayed(_prepare_training_data_helper)(args, tokenizer, df, idx) for idx in train_ids_splits\n    )\n    for result in results:\n        training_samples.extend(result)\n\n    return training_samples\n\n\ndef calc_overlap(row):\n    \"\"\"\n    Calculates the overlap between prediction and\n    ground truth and overlap percentages used for determining\n    true positives.\n    \"\"\"\n    set_pred = set(row.predictionstring_pred.split(\" \"))\n    set_gt = set(row.predictionstring_gt.split(\" \"))\n    # Length of each and intersection\n    len_gt = len(set_gt)\n    len_pred = len(set_pred)\n    inter = len(set_gt.intersection(set_pred))\n    overlap_1 = inter / len_gt\n    overlap_2 = inter / len_pred\n    return [overlap_1, overlap_2]\n\n\ndef score_feedback_comp_micro(pred_df, gt_df):\n    \"\"\"\n    A function that scores for the kaggle\n        Student Writing Competition\n\n    Uses the steps in the evaluation page here:\n        https://www.kaggle.com/c/feedback-prize-2021/overview/evaluation\n    This code is from Rob Mulla's Kaggle kernel.\n    \"\"\"\n    gt_df = gt_df[[\"id\", \"discourse_type\", \"predictionstring\"]].reset_index(drop=True).copy()\n    pred_df = pred_df[[\"id\", \"class\", \"predictionstring\"]].reset_index(drop=True).copy()\n    pred_df[\"pred_id\"] = pred_df.index\n    gt_df[\"gt_id\"] = gt_df.index\n    # Step 1. all ground truths and predictions for a given class are compared.\n    joined = pred_df.merge(\n        gt_df,\n        left_on=[\"id\", \"class\"],\n        right_on=[\"id\", \"discourse_type\"],\n        how=\"outer\",\n        suffixes=(\"_pred\", \"_gt\"),\n    )\n    joined[\"predictionstring_gt\"] = joined[\"predictionstring_gt\"].fillna(\" \")\n    joined[\"predictionstring_pred\"] = joined[\"predictionstring_pred\"].fillna(\" \")\n\n    joined[\"overlaps\"] = joined.apply(calc_overlap, axis=1)\n\n    # 2. If the overlap between the ground truth and prediction is >= 0.5,\n    # and the overlap between the prediction and the ground truth >= 0.5,\n    # the prediction is a match and considered a true positive.\n    # If multiple matches exist, the match with the highest pair of overlaps is taken.\n    joined[\"overlap1\"] = joined[\"overlaps\"].apply(lambda x: eval(str(x))[0])\n    joined[\"overlap2\"] = joined[\"overlaps\"].apply(lambda x: eval(str(x))[1])\n\n    joined[\"potential_TP\"] = (joined[\"overlap1\"] >= 0.5) & (joined[\"overlap2\"] >= 0.5)\n    joined[\"max_overlap\"] = joined[[\"overlap1\", \"overlap2\"]].max(axis=1)\n    tp_pred_ids = (\n        joined.query(\"potential_TP\")\n        .sort_values(\"max_overlap\", ascending=False)\n        .groupby([\"id\", \"predictionstring_gt\"])\n        .first()[\"pred_id\"]\n        .values\n    )\n\n    # 3. Any unmatched ground truths are false negatives\n    # and any unmatched predictions are false positives.\n    fp_pred_ids = [p for p in joined[\"pred_id\"].unique() if p not in tp_pred_ids]\n\n    matched_gt_ids = joined.query(\"potential_TP\")[\"gt_id\"].unique()\n    unmatched_gt_ids = [c for c in joined[\"gt_id\"].unique() if c not in matched_gt_ids]\n\n    # Get numbers of each type\n    TP = len(tp_pred_ids)\n    FP = len(fp_pred_ids)\n    FN = len(unmatched_gt_ids)\n    # calc microf1\n    my_f1_score = TP / (TP + 0.5 * (FP + FN))\n    return my_f1_score\n\n\ndef score_feedback_comp(pred_df, gt_df, return_class_scores=False):\n    class_scores = {}\n    pred_df = pred_df[[\"id\", \"class\", \"predictionstring\"]].reset_index(drop=True).copy()\n    for discourse_type, gt_subset in gt_df.groupby(\"discourse_type\"):\n        pred_subset = pred_df.loc[pred_df[\"class\"] == discourse_type].reset_index(drop=True).copy()\n        class_score = score_feedback_comp_micro(pred_subset, gt_subset)\n        class_scores[discourse_type] = class_score\n    f1 = np.mean([v for v in class_scores.values()])\n    if return_class_scores:\n        return f1, class_scores\n    return f1\n\n\nclass FeedbackDatasetValid:\n    def __init__(self, samples, max_len, tokenizer):\n        self.samples = samples\n        self.max_len = max_len\n        self.tokenizer = tokenizer\n        self.length = len(samples)\n\n    def __len__(self):\n        return self.length\n\n    def __getitem__(self, idx):\n        input_ids = self.samples[idx][\"input_ids\"]\n        input_ids = [self.tokenizer.cls_token_id] + input_ids\n\n        if len(input_ids) > self.max_len - 1:\n            input_ids = input_ids[: self.max_len - 1]\n\n        # add end token id to the input_ids\n        input_ids = input_ids + [self.tokenizer.sep_token_id]\n        attention_mask = [1] * len(input_ids)\n\n        return {\n            \"ids\": input_ids,\n            \"mask\": attention_mask,\n        }\n\n\nclass Collate:\n    def __init__(self, tokenizer):\n        self.tokenizer = tokenizer\n\n    def __call__(self, batch):\n        output = dict()\n        output[\"ids\"] = [sample[\"ids\"] for sample in batch]\n        output[\"mask\"] = [sample[\"mask\"] for sample in batch]\n\n        # calculate max token length of this batch\n        batch_max = max([len(ids) for ids in output[\"ids\"]])\n\n        # add padding\n        if self.tokenizer.padding_side == \"right\":\n            output[\"ids\"] = [s + (batch_max - len(s)) * [self.tokenizer.pad_token_id] for s in output[\"ids\"]]\n            output[\"mask\"] = [s + (batch_max - len(s)) * [0] for s in output[\"mask\"]]\n        else:\n            output[\"ids\"] = [(batch_max - len(s)) * [self.tokenizer.pad_token_id] + s for s in output[\"ids\"]]\n            output[\"mask\"] = [(batch_max - len(s)) * [0] + s for s in output[\"mask\"]]\n\n        # convert to tensors\n        output[\"ids\"] = torch.tensor(output[\"ids\"], dtype=torch.long)\n        output[\"mask\"] = torch.tensor(output[\"mask\"], dtype=torch.long)\n\n        return output\n\n\nclass EarlyStopping(Callback):\n    def __init__(\n        self,\n        model_path,\n        valid_df,\n        valid_samples,\n        batch_size,\n        tokenizer,\n        patience=5,\n        mode=\"max\",\n        delta=0.001,\n        save_weights_only=True,\n    ):\n        self.patience = patience\n        self.counter = 0\n        self.mode = mode\n        self.best_score = None\n        self.early_stop = False\n        self.delta = delta\n        self.save_weights_only = save_weights_only\n        self.model_path = model_path\n        self.valid_samples = valid_samples\n        self.batch_size = batch_size\n        self.valid_df = valid_df\n        self.tokenizer = tokenizer\n\n        if self.mode == \"min\":\n            self.val_score = np.Inf\n        else:\n            self.val_score = -np.Inf\n\n    def on_epoch_end(self, model):\n        model.eval()\n        valid_dataset = FeedbackDatasetValid(self.valid_samples, 4096, self.tokenizer)\n        collate = Collate(self.tokenizer)\n\n        preds_iter = model.predict(\n            valid_dataset,\n            batch_size=self.batch_size,\n            n_jobs=-1,\n            collate_fn=collate,\n        )\n\n        final_preds = []\n        final_scores = []\n        for preds in preds_iter:\n            pred_class = np.argmax(preds, axis=2)\n            pred_scrs = np.max(preds, axis=2)\n            for pred, pred_scr in zip(pred_class, pred_scrs):\n                final_preds.append(pred.tolist())\n                final_scores.append(pred_scr.tolist())\n\n        for j in range(len(self.valid_samples)):\n            tt = [id_target_map[p] for p in final_preds[j][1:]]\n            tt_score = final_scores[j][1:]\n            self.valid_samples[j][\"preds\"] = tt\n            self.valid_samples[j][\"pred_scores\"] = tt_score\n\n        submission = []\n        min_thresh = {\n            \"Lead\": 9,\n            \"Position\": 5,\n            \"Evidence\": 14,\n            \"Claim\": 3,\n            \"Concluding Statement\": 11,\n            \"Counterclaim\": 6,\n            \"Rebuttal\": 4,\n        }\n        proba_thresh = {\n            \"Lead\": 0.7,\n            \"Position\": 0.55,\n            \"Evidence\": 0.65,\n            \"Claim\": 0.55,\n            \"Concluding Statement\": 0.7,\n            \"Counterclaim\": 0.5,\n            \"Rebuttal\": 0.55,\n        }\n\n        for _, sample in enumerate(self.valid_samples):\n            preds = sample[\"preds\"]\n            offset_mapping = sample[\"offset_mapping\"]\n            sample_id = sample[\"id\"]\n            sample_text = sample[\"text\"]\n            sample_pred_scores = sample[\"pred_scores\"]\n\n            # pad preds to same length as offset_mapping\n            if len(preds) < len(offset_mapping):\n                preds = preds + [\"O\"] * (len(offset_mapping) - len(preds))\n                sample_pred_scores = sample_pred_scores + [0] * (len(offset_mapping) - len(sample_pred_scores))\n\n            idx = 0\n            phrase_preds = []\n            while idx < len(offset_mapping):\n                start, _ = offset_mapping[idx]\n                if preds[idx] != \"O\":\n                    label = preds[idx][2:]\n                else:\n                    label = \"O\"\n                phrase_scores = []\n                phrase_scores.append(sample_pred_scores[idx])\n                idx += 1\n                while idx < len(offset_mapping):\n                    if label == \"O\":\n                        matching_label = \"O\"\n                    else:\n                        matching_label = f\"I-{label}\"\n                    if preds[idx] == matching_label:\n                        _, end = offset_mapping[idx]\n                        phrase_scores.append(sample_pred_scores[idx])\n                        idx += 1\n                    else:\n                        break\n                if \"end\" in locals():\n                    phrase = sample_text[start:end]\n                    phrase_preds.append((phrase, start, end, label, phrase_scores))\n\n            temp_df = []\n            for phrase_idx, (phrase, start, end, label, phrase_scores) in enumerate(phrase_preds):\n                word_start = len(sample_text[:start].split())\n                word_end = word_start + len(sample_text[start:end].split())\n                word_end = min(word_end, len(sample_text.split()))\n                ps = \" \".join([str(x) for x in range(word_start, word_end)])\n                if label != \"O\":\n                    if sum(phrase_scores) / len(phrase_scores) >= proba_thresh[label]:\n                        temp_df.append((sample_id, label, ps))\n\n            temp_df = pd.DataFrame(temp_df, columns=[\"id\", \"class\", \"predictionstring\"])\n\n            submission.append(temp_df)\n\n        submission = pd.concat(submission).reset_index(drop=True)\n        submission[\"len\"] = submission.predictionstring.apply(lambda x: len(x.split()))\n\n        def threshold(df):\n            df = df.copy()\n            for key, value in min_thresh.items():\n                index = df.loc[df[\"class\"] == key].query(f\"len<{value}\").index\n                df.drop(index, inplace=True)\n            return df\n\n        submission = threshold(submission)\n\n        # drop len\n        submission = submission.drop(columns=[\"len\"])\n\n        scr = score_feedback_comp(submission, self.valid_df, return_class_scores=True)\n        print(scr)\n        model.train()\n\n        epoch_score = scr[0]\n        if self.mode == \"min\":\n            score = -1.0 * epoch_score\n        else:\n            score = np.copy(epoch_score)\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(epoch_score, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            print(\"EarlyStopping counter: {} out of {}\".format(self.counter, self.patience))\n            if self.counter >= self.patience:\n                model.model_state = enums.ModelState.END\n        else:\n            self.best_score = score\n            self.save_checkpoint(epoch_score, model)\n            self.counter = 0\n\n    def save_checkpoint(self, epoch_score, model):\n        if epoch_score not in [-np.inf, np.inf, -np.nan, np.nan]:\n            print(\"Validation score improved ({} --> {}). Saving model!\".format(self.val_score, epoch_score))\n            model.save(self.model_path, weights_only=self.save_weights_only)\n        self.val_score = epoch_score\n","metadata":{"id":"DqtRFPaUPlYR","executionInfo":{"status":"ok","timestamp":1645951249061,"user_tz":-540,"elapsed":8973,"user":{"displayName":"鳴川彰将","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00422213483226230461"}},"execution":{"iopub.status.busy":"2022-03-05T17:25:19.798219Z","iopub.execute_input":"2022-03-05T17:25:19.798682Z","iopub.status.idle":"2022-03-05T17:25:20.969041Z","shell.execute_reply.started":"2022-03-05T17:25:19.798623Z","shell.execute_reply":"2022-03-05T17:25:20.968305Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### ここからが本題","metadata":{"id":"-ViWgSJEPhr8"}},{"cell_type":"code","source":"! pip install transformers","metadata":{"id":"ptO-eHjXA2xs","executionInfo":{"status":"ok","timestamp":1645951265502,"user_tz":-540,"elapsed":16449,"user":{"displayName":"鳴川彰将","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00422213483226230461"}},"outputId":"4f43dbb7-2d7f-4d3f-a99b-7b2b96d9495c","execution":{"iopub.status.busy":"2022-03-05T17:25:20.970164Z","iopub.execute_input":"2022-03-05T17:25:20.970390Z","iopub.status.idle":"2022-03-05T17:25:28.260397Z","shell.execute_reply.started":"2022-03-05T17:25:20.970358Z","shell.execute_reply":"2022-03-05T17:25:28.259475Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import argparse\nimport os\nimport random\nimport warnings\n\nimport numpy as np\nimport pandas as pd\nimport tez\nimport torch\nimport torch.nn as nn\nfrom sklearn import metrics\nfrom torch.nn import functional as F\nfrom transformers import AdamW, AutoConfig, AutoModel, AutoTokenizer, get_cosine_schedule_with_warmup\n\n# from utils import EarlyStopping, prepare_training_data, target_id_map\n\nwarnings.filterwarnings(\"ignore\")\n\n\ndef seed_everything(seed: int):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n#     torch.manual_seed(seed)\n#     torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\n\n# def parse_args():\n#     parser = argparse.ArgumentParser()\n#     parser.add_argument(\"--fold\", type=int, required=True)\n#     parser.add_argument(\"--model\", type=str, required=True)\n#     parser.add_argument(\"--lr\", type=float, required=True)\n#     parser.add_argument(\"--output\", type=str, default=\"../model\", required=False)\n#     parser.add_argument(\"--input\", type=str, default=\"../input\", required=False)\n#     parser.add_argument(\"--max_len\", type=int, default=1024, required=False)\n#     parser.add_argument(\"--batch_size\", type=int, default=8, required=False)\n#     parser.add_argument(\"--valid_batch_size\", type=int, default=8, required=False)\n#     parser.add_argument(\"--epochs\", type=int, default=20, required=False)\n#     parser.add_argument(\"--accumulation_steps\", type=int, default=1, required=False)\n#     return parser.parse_args()\n\n# class args:\n#     fold = 0\n#     model = allenai/longformer-large-4096\n#     lr = 1e-5\n#     output = ../model\n#     input = ../model\n#     max_len = 1536\n#     batch_size = 4\n#     valid_batch_size = 4\n#     epochs = 10\n#     accumulation_steps = 1\n\n\nclass FeedbackDataset:\n    def __init__(self, samples, max_len, tokenizer):\n        self.samples = samples\n        self.max_len = max_len\n        self.tokenizer = tokenizer\n        self.length = len(samples)\n\n    def __len__(self):\n        return self.length\n\n    def __getitem__(self, idx):\n        input_ids = self.samples[idx][\"input_ids\"]\n        input_labels = self.samples[idx][\"input_labels\"]\n        input_labels = [target_id_map[x] for x in input_labels]\n        other_label_id = target_id_map[\"O\"]\n        padding_label_id = target_id_map[\"PAD\"]\n        # print(input_ids)\n        # print(input_labels)\n\n        # add start token id to the input_ids\n        input_ids = [self.tokenizer.cls_token_id] + input_ids\n        input_labels = [other_label_id] + input_labels\n\n        if len(input_ids) > self.max_len - 1:\n            input_ids = input_ids[: self.max_len - 1]\n            input_labels = input_labels[: self.max_len - 1]\n\n        # add end token id to the input_ids\n        input_ids = input_ids + [self.tokenizer.sep_token_id]\n        input_labels = input_labels + [other_label_id]\n\n        attention_mask = [1] * len(input_ids)\n\n        padding_length = self.max_len - len(input_ids)\n        if padding_length > 0:\n            if self.tokenizer.padding_side == \"right\":\n                input_ids = input_ids + [self.tokenizer.pad_token_id] * padding_length\n                input_labels = input_labels + [padding_label_id] * padding_length\n                attention_mask = attention_mask + [0] * padding_length\n            else:\n                input_ids = [self.tokenizer.pad_token_id] * padding_length + input_ids\n                input_labels = [padding_label_id] * padding_length + input_labels\n                attention_mask = [0] * padding_length + attention_mask\n\n        return {\n            \"ids\": torch.tensor(input_ids, dtype=torch.long),\n            \"mask\": torch.tensor(attention_mask, dtype=torch.long),\n            \"targets\": torch.tensor(input_labels, dtype=torch.long),\n        }\n","metadata":{"id":"UHZLF2TgPMLo","executionInfo":{"status":"ok","timestamp":1645951266067,"user_tz":-540,"elapsed":577,"user":{"displayName":"鳴川彰将","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00422213483226230461"}},"execution":{"iopub.status.busy":"2022-03-05T17:25:28.263942Z","iopub.execute_input":"2022-03-05T17:25:28.264181Z","iopub.status.idle":"2022-03-05T17:25:28.610914Z","shell.execute_reply.started":"2022-03-05T17:25:28.264145Z","shell.execute_reply":"2022-03-05T17:25:28.610235Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class FeedbackModel(tez.Model):\n    def __init__(self, model_name, num_train_steps, learning_rate, num_labels, steps_per_epoch):\n        super().__init__()\n        self.learning_rate = learning_rate\n        self.model_name = model_name\n        self.num_train_steps = num_train_steps\n        self.num_labels = num_labels\n        self.steps_per_epoch = steps_per_epoch\n        self.step_scheduler_after = \"batch\"\n\n        hidden_dropout_prob: float = 0.1\n        layer_norm_eps: float = 1e-7\n\n        config = AutoConfig.from_pretrained(model_name)\n\n        config.update(\n            {\n                \"output_hidden_states\": True,\n                \"hidden_dropout_prob\": hidden_dropout_prob,\n                \"layer_norm_eps\": layer_norm_eps,\n                \"add_pooling_layer\": False,\n                \"num_labels\": self.num_labels,\n            }\n        )\n        self.transformer = AutoModel.from_pretrained(model_name, config=config)\n        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n        self.dropout1 = nn.Dropout(0.1)\n        self.dropout2 = nn.Dropout(0.2)\n        self.dropout3 = nn.Dropout(0.3)\n        self.dropout4 = nn.Dropout(0.4)\n        self.dropout5 = nn.Dropout(0.5)\n        self.output = nn.Linear(config.hidden_size, self.num_labels)\n\n    def fetch_optimizer(self):\n        param_optimizer = list(self.named_parameters())\n        no_decay = [\"bias\", \"LayerNorm.bias\"]\n        optimizer_parameters = [\n            {\n                \"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n                \"weight_decay\": 0.01,\n            },\n            {\n                \"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n                \"weight_decay\": 0.0,\n            },\n        ]\n        opt = AdamW(optimizer_parameters, lr=self.learning_rate)\n        return opt\n\n    def fetch_scheduler(self):\n        sch = get_cosine_schedule_with_warmup(\n            self.optimizer,\n            num_warmup_steps=int(0.1 * self.num_train_steps),\n            num_training_steps=self.num_train_steps,\n            num_cycles=1,\n            last_epoch=-1,\n        )\n        return sch\n\n    def loss(self, outputs, targets, attention_mask):\n        loss_fct = nn.CrossEntropyLoss()\n\n        active_loss = attention_mask.view(-1) == 1\n        active_logits = outputs.view(-1, self.num_labels)\n        true_labels = targets.view(-1)\n        outputs = active_logits.argmax(dim=-1)\n        idxs = np.where(active_loss.cpu().numpy() == 1)[0]\n        active_logits = active_logits[idxs]\n        true_labels = true_labels[idxs].to(torch.long)\n\n        loss = loss_fct(active_logits, true_labels)\n        return loss\n\n    def monitor_metrics(self, outputs, targets, attention_mask):\n        active_loss = (attention_mask.view(-1) == 1).cpu().numpy()\n        active_logits = outputs.view(-1, self.num_labels)\n        true_labels = targets.view(-1).cpu().numpy()\n        outputs = active_logits.argmax(dim=-1).cpu().numpy()\n        idxs = np.where(active_loss == 1)[0]\n        f1_score = metrics.f1_score(true_labels[idxs], outputs[idxs], average=\"macro\")\n        return {\"f1\": f1_score}\n\n    def forward(self, ids, mask, token_type_ids=None, targets=None):\n\n        if token_type_ids:\n            transformer_out = self.transformer(ids, mask, token_type_ids)\n        else:\n            transformer_out = self.transformer(ids, mask)\n        sequence_output = transformer_out.last_hidden_state #(batch_size, sequence_length, hidden_size)\n        sequence_output = self.dropout(sequence_output)\n\n        logits1 = self.output(self.dropout1(sequence_output))\n        logits2 = self.output(self.dropout2(sequence_output))\n        logits3 = self.output(self.dropout3(sequence_output))\n        logits4 = self.output(self.dropout4(sequence_output))\n        logits5 = self.output(self.dropout5(sequence_output))\n\n        logits = (logits1 + logits2 + logits3 + logits4 + logits5) / 5\n        logits = torch.softmax(logits, dim=-1)\n        loss = 0\n\n        if targets is not None:\n            loss1 = self.loss(logits1, targets, attention_mask=mask)\n            loss2 = self.loss(logits2, targets, attention_mask=mask)\n            loss3 = self.loss(logits3, targets, attention_mask=mask)\n            loss4 = self.loss(logits4, targets, attention_mask=mask)\n            loss5 = self.loss(logits5, targets, attention_mask=mask)\n            loss = (loss1 + loss2 + loss3 + loss4 + loss5) / 5\n            f1_1 = self.monitor_metrics(logits1, targets, attention_mask=mask)[\"f1\"]\n            f1_2 = self.monitor_metrics(logits2, targets, attention_mask=mask)[\"f1\"]\n            f1_3 = self.monitor_metrics(logits3, targets, attention_mask=mask)[\"f1\"]\n            f1_4 = self.monitor_metrics(logits4, targets, attention_mask=mask)[\"f1\"]\n            f1_5 = self.monitor_metrics(logits5, targets, attention_mask=mask)[\"f1\"]\n            f1 = (f1_1 + f1_2 + f1_3 + f1_4 + f1_5) / 5\n            metric = {\"f1\": f1}\n            return logits, loss, metric\n\n        return logits, loss, {}","metadata":{"id":"HfYui6e2PMJn","executionInfo":{"status":"ok","timestamp":1645951266406,"user_tz":-540,"elapsed":343,"user":{"displayName":"鳴川彰将","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00422213483226230461"}},"execution":{"iopub.status.busy":"2022-03-05T17:25:28.613741Z","iopub.execute_input":"2022-03-05T17:25:28.614000Z","iopub.status.idle":"2022-03-05T17:25:28.639372Z","shell.execute_reply.started":"2022-03-05T17:25:28.613965Z","shell.execute_reply":"2022-03-05T17:25:28.638473Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"!pip install -q iterative-stratification","metadata":{"id":"clAawD7LBosi","executionInfo":{"status":"ok","timestamp":1645951271401,"user_tz":-540,"elapsed":5001,"user":{"displayName":"鳴川彰将","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00422213483226230461"}},"execution":{"iopub.status.busy":"2022-03-05T17:25:28.640840Z","iopub.execute_input":"2022-03-05T17:25:28.641097Z","iopub.status.idle":"2022-03-05T17:25:36.450487Z","shell.execute_reply.started":"2022-03-05T17:25:28.641058Z","shell.execute_reply":"2022-03-05T17:25:36.449646Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n\ndf = pd.read_csv(os.path.join(INPUT, 'train.csv'))\n\n# debug\nif Config.debug :\n    df = df.sample(n=100).reset_index(drop=True)\n\ndfx = pd.get_dummies(df, columns=[\"discourse_type\"]).groupby([\"id\"], as_index=False).sum()\ncols = [c for c in dfx.columns if c.startswith(\"discourse_type_\") or c == \"id\" and c != \"discourse_type_num\"]\ndfx = dfx[cols]\n\nmskf = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nlabels = [c for c in dfx.columns if c != \"id\"]\ndfx_labels = dfx[labels]\ndfx[\"kfold\"] = -1\n\nfor fold, (trn_, val_) in enumerate(mskf.split(dfx, dfx_labels)):\n    print(len(trn_), len(val_))\n    dfx.loc[val_, \"kfold\"] = fold\n\ndf = df.merge(dfx[[\"id\", \"kfold\"]], on=\"id\", how=\"left\")\nprint(df.kfold.value_counts())\n# df.to_csv(\"train_folds.csv\", index=False)","metadata":{"id":"4EbHe3WeBp5q","executionInfo":{"status":"ok","timestamp":1645951273099,"user_tz":-540,"elapsed":1702,"user":{"displayName":"鳴川彰将","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00422213483226230461"}},"outputId":"fe4beb94-e796-4deb-d88d-264e6e90634e","execution":{"iopub.status.busy":"2022-03-05T17:25:36.455333Z","iopub.execute_input":"2022-03-05T17:25:36.457319Z","iopub.status.idle":"2022-03-05T17:25:38.200041Z","shell.execute_reply.started":"2022-03-05T17:25:36.457276Z","shell.execute_reply":"2022-03-05T17:25:38.199339Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    NUM_JOBS = 2\n    class args:\n        fold = 0\n        model = 'google/bigbird-roberta-base'\n        lr = 1e-5\n        output = OUTPUT_EXP\n        input = INPUT\n        max_len = 1024 #1536\n        batch_size = 4\n        valid_batch_size = 4\n        epochs = 10\n        accumulation_steps = 1\n\n    # args = parse_args()\n    seed_everything(42)\n    os.makedirs(args.output, exist_ok=True)\n    # df = pd.read_csv(os.path.join(args.input, \"train_folds.csv\"))\n\n    train_df = df[df[\"kfold\"] != args.fold].reset_index(drop=True)\n    valid_df = df[df[\"kfold\"] == args.fold].reset_index(drop=True)\n\n    tokenizer = AutoTokenizer.from_pretrained(args.model)\n    training_samples = prepare_training_data(train_df, tokenizer, args, num_jobs=NUM_JOBS)\n    valid_samples = prepare_training_data(valid_df, tokenizer, args, num_jobs=NUM_JOBS)\n\n    train_dataset = FeedbackDataset(training_samples, args.max_len, tokenizer)\n\n    num_train_steps = int(len(train_dataset) / args.batch_size / args.accumulation_steps * args.epochs)\n    print(num_train_steps)\n\n    model = FeedbackModel(\n        model_name=args.model,\n        num_train_steps=num_train_steps,\n        learning_rate=args.lr,\n        num_labels=len(target_id_map) - 1,\n        steps_per_epoch=len(train_dataset) / args.batch_size,\n    )\n\n    es = EarlyStopping(\n        model_path=os.path.join(args.output, f\"model_{args.fold}.bin\"),\n        valid_df=valid_df,\n        valid_samples=valid_samples,\n        batch_size=args.valid_batch_size,\n        patience=5,\n        mode=\"max\",\n        delta=0.001,\n        save_weights_only=True,\n        tokenizer=tokenizer,\n    )\n\n    model.fit(\n        train_dataset,\n        train_bs=args.batch_size,\n        device=\"cuda\",\n        epochs=args.epochs,\n        callbacks=[es],\n        fp16=True,\n        accumulation_steps=args.accumulation_steps,\n    )","metadata":{"id":"w1Iuv_ZPPMGf","outputId":"805e8a0e-30df-4d65-dbcf-48d34cf7bac8","executionInfo":{"status":"error","timestamp":1645951388535,"user_tz":-540,"elapsed":115440,"user":{"displayName":"鳴川彰将","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00422213483226230461"}},"execution":{"iopub.status.busy":"2022-03-05T17:25:38.201235Z","iopub.execute_input":"2022-03-05T17:25:38.201489Z","iopub.status.idle":"2022-03-05T17:27:50.989422Z","shell.execute_reply.started":"2022-03-05T17:25:38.201453Z","shell.execute_reply":"2022-03-05T17:27:50.988558Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"os.path.isfile('/content/drive/MyDrive/kaggle/feed_back/Input/feedback-prize-2021/train/FAAC3CC5476F.txt')","metadata":{"id":"6SZMkws-PMDY","executionInfo":{"status":"aborted","timestamp":1645951388312,"user_tz":-540,"elapsed":9,"user":{"displayName":"鳴川彰将","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00422213483226230461"}},"execution":{"iopub.status.busy":"2022-03-05T17:27:50.990897Z","iopub.execute_input":"2022-03-05T17:27:50.991145Z","iopub.status.idle":"2022-03-05T17:27:50.999748Z","shell.execute_reply.started":"2022-03-05T17:27:50.991109Z","shell.execute_reply":"2022-03-05T17:27:50.998041Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"5Q58AfR5PMAh","executionInfo":{"status":"aborted","timestamp":1645951388313,"user_tz":-540,"elapsed":10,"user":{"displayName":"鳴川彰将","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00422213483226230461"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"gpt2\n\nTypeError                                 Traceback (most recent call last)\n/tmp/ipykernel_33/2971685556.py in <module>\n     57         callbacks=[es],\n     58         fp16=True,\n---> 59         accumulation_steps=args.accumulation_steps,\n     60     )\n\n/opt/conda/lib/python3.7/site-packages/tez/model/model.py in fit(self, train_dataset, valid_dataset, train_sampler, valid_sampler, device, epochs, train_bs, valid_bs, n_jobs, callbacks, fp16, train_collate_fn, valid_collate_fn, train_shuffle, valid_shuffle, accumulation_steps, clip_grad_norm)\n    408             self.train_state = enums.TrainingState.EPOCH_START\n    409             self.train_state = enums.TrainingState.TRAIN_EPOCH_START\n--> 410             train_loss = self.train_one_epoch(self.train_loader)\n    411             self.train_state = enums.TrainingState.TRAIN_EPOCH_END\n    412             if self.valid_loader:\n\n/opt/conda/lib/python3.7/site-packages/tez/model/model.py in train_one_epoch(self, data_loader)\n    223         else:\n    224             tk0 = tqdm(data_loader, total=len(data_loader))\n--> 225         for b_idx, data in enumerate(tk0):\n    226             self.batch_index = b_idx\n    227             self.train_state = enums.TrainingState.TRAIN_STEP_START\n\n/opt/conda/lib/python3.7/site-packages/tqdm/std.py in __iter__(self)\n   1178 \n   1179         try:\n-> 1180             for obj in iterable:\n   1181                 yield obj\n   1182                 # Update and possibly print the progressbar.\n\n/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py in __next__(self)\n    519             if self._sampler_iter is None:\n    520                 self._reset()\n--> 521             data = self._next_data()\n    522             self._num_yielded += 1\n    523             if self._dataset_kind == _DatasetKind.Iterable and \\\n\n/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py in _next_data(self)\n   1201             else:\n   1202                 del self._task_info[idx]\n-> 1203                 return self._process_data(data)\n   1204 \n   1205     def _try_put_index(self):\n\n/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py in _process_data(self, data)\n   1227         self._try_put_index()\n   1228         if isinstance(data, ExceptionWrapper):\n-> 1229             data.reraise()\n   1230         return data\n   1231 \n\n/opt/conda/lib/python3.7/site-packages/torch/_utils.py in reraise(self)\n    423             # have message field\n    424             raise self.exc_type(message=msg)\n--> 425         raise self.exc_type(msg)\n    426 \n    427 \n\nTypeError: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_33/3669944669.py\", line 102, in __getitem__\n    \"ids\": torch.tensor(input_ids, dtype=torch.long),\nTypeError: an integer is required (got type NoneType)","metadata":{}},{"cell_type":"code","source":"","metadata":{"id":"EJj43_ncPL9Y","executionInfo":{"status":"aborted","timestamp":1645951388314,"user_tz":-540,"elapsed":11,"user":{"displayName":"鳴川彰将","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00422213483226230461"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"roberta-base\n\nSome weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n  1%|▏         | 1/80 [00:01<02:21,  1.79s/it, f1=0.00853, loss=2.75, stage=train]\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\n/tmp/ipykernel_34/870533841.py in <module>\n     57         callbacks=[es],\n     58         fp16=False, #True,\n---> 59         accumulation_steps=args.accumulation_steps,\n     60     )\n\n/opt/conda/lib/python3.7/site-packages/tez/model/model.py in fit(self, train_dataset, valid_dataset, train_sampler, valid_sampler, device, epochs, train_bs, valid_bs, n_jobs, callbacks, fp16, train_collate_fn, valid_collate_fn, train_shuffle, valid_shuffle, accumulation_steps, clip_grad_norm)\n    408             self.train_state = enums.TrainingState.EPOCH_START\n    409             self.train_state = enums.TrainingState.TRAIN_EPOCH_START\n--> 410             train_loss = self.train_one_epoch(self.train_loader)\n    411             self.train_state = enums.TrainingState.TRAIN_EPOCH_END\n    412             if self.valid_loader:\n\n/opt/conda/lib/python3.7/site-packages/tez/model/model.py in train_one_epoch(self, data_loader)\n    226             self.batch_index = b_idx\n    227             self.train_state = enums.TrainingState.TRAIN_STEP_START\n--> 228             loss, metrics = self.train_one_step(data)\n    229             self.train_state = enums.TrainingState.TRAIN_STEP_END\n    230             losses.update(loss.item() * self.accumulation_steps, data_loader.batch_size)\n\n/opt/conda/lib/python3.7/site-packages/tez/model/model.py in train_one_step(self, data)\n    173         if self.accumulation_steps == 1 and self.batch_index == 0:\n    174             self.zero_grad()\n--> 175         _, loss, metrics = self.model_fn(data)\n    176         loss = loss / self.accumulation_steps\n    177         if self.fp16:\n\n/opt/conda/lib/python3.7/site-packages/tez/model/model.py in model_fn(self, data)\n    167                 output, loss, metrics = self(**data)\n    168         else:\n--> 169             output, loss, metrics = self(**data)\n    170         return output, loss, metrics\n    171 \n\n/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)\n   1049         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n   1050                 or _global_forward_hooks or _global_forward_pre_hooks):\n-> 1051             return forward_call(*input, **kwargs)\n   1052         # Do not call functions when jit is used\n   1053         full_backward_hooks, non_full_backward_hooks = [], []\n\n/tmp/ipykernel_34/481160261.py in forward(self, ids, mask, token_type_ids, targets)\n     86             transformer_out = self.transformer(ids, mask, token_type_ids)\n     87         else:\n---> 88             transformer_out = self.transformer(ids, mask)\n     89         sequence_output = transformer_out.last_hidden_state\n     90         sequence_output = self.dropout(sequence_output)\n\n/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)\n   1049         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n   1050                 or _global_forward_hooks or _global_forward_pre_hooks):\n-> 1051             return forward_call(*input, **kwargs)\n   1052         # Do not call functions when jit is used\n   1053         full_backward_hooks, non_full_backward_hooks = [], []\n\n/opt/conda/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py in forward(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\n    859             output_attentions=output_attentions,\n    860             output_hidden_states=output_hidden_states,\n--> 861             return_dict=return_dict,\n    862         )\n    863         sequence_output = encoder_outputs[0]\n\n/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)\n   1049         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n   1050                 or _global_forward_hooks or _global_forward_pre_hooks):\n-> 1051             return forward_call(*input, **kwargs)\n   1052         # Do not call functions when jit is used\n   1053         full_backward_hooks, non_full_backward_hooks = [], []\n\n/opt/conda/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py in forward(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\n    531                     encoder_attention_mask,\n    532                     past_key_value,\n--> 533                     output_attentions,\n    534                 )\n    535 \n\n/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)\n   1049         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n   1050                 or _global_forward_hooks or _global_forward_pre_hooks):\n-> 1051             return forward_call(*input, **kwargs)\n   1052         # Do not call functions when jit is used\n   1053         full_backward_hooks, non_full_backward_hooks = [], []\n\n/opt/conda/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py in forward(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\n    452 \n    453         layer_output = apply_chunking_to_forward(\n--> 454             self.feed_forward_chunk, self.chunk_size_feed_forward, self.seq_len_dim, attention_output\n    455         )\n    456         outputs = (layer_output,) + outputs\n\n/opt/conda/lib/python3.7/site-packages/transformers/modeling_utils.py in apply_chunking_to_forward(forward_fn, chunk_size, chunk_dim, *input_tensors)\n   2368         return torch.cat(output_chunks, dim=chunk_dim)\n   2369 \n-> 2370     return forward_fn(*input_tensors)\n\n/opt/conda/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py in feed_forward_chunk(self, attention_output)\n    464     def feed_forward_chunk(self, attention_output):\n    465         intermediate_output = self.intermediate(attention_output)\n--> 466         layer_output = self.output(intermediate_output, attention_output)\n    467         return layer_output\n    468 \n\n/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)\n   1049         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n   1050                 or _global_forward_hooks or _global_forward_pre_hooks):\n-> 1051             return forward_call(*input, **kwargs)\n   1052         # Do not call functions when jit is used\n   1053         full_backward_hooks, non_full_backward_hooks = [], []\n\n/opt/conda/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py in forward(self, hidden_states, input_tensor)\n    378         hidden_states = self.dense(hidden_states)\n    379         hidden_states = self.dropout(hidden_states)\n--> 380         hidden_states = self.LayerNorm(hidden_states + input_tensor)\n    381         return hidden_states\n    382 \n\nRuntimeError: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.","metadata":{}},{"cell_type":"code","source":"","metadata":{"id":"Xjgma7mcPL6f","executionInfo":{"status":"aborted","timestamp":1645951388314,"user_tz":-540,"elapsed":11,"user":{"displayName":"鳴川彰将","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00422213483226230461"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"-joeM0BlPL3h","executionInfo":{"status":"aborted","timestamp":1645951388314,"user_tz":-540,"elapsed":11,"user":{"displayName":"鳴川彰将","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00422213483226230461"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"QL5N6lNEPL0d","executionInfo":{"status":"aborted","timestamp":1645951388315,"user_tz":-540,"elapsed":12,"user":{"displayName":"鳴川彰将","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00422213483226230461"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"90HgTDFYPLxF","executionInfo":{"status":"aborted","timestamp":1645951388315,"user_tz":-540,"elapsed":12,"user":{"displayName":"鳴川彰将","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00422213483226230461"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"80lZJ51CPLtm","executionInfo":{"status":"aborted","timestamp":1645951388529,"user_tz":-540,"elapsed":225,"user":{"displayName":"鳴川彰将","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00422213483226230461"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"iD8GyIhwPLpz","executionInfo":{"status":"aborted","timestamp":1645951388530,"user_tz":-540,"elapsed":226,"user":{"displayName":"鳴川彰将","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00422213483226230461"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"vXvlS_l5PLlC","executionInfo":{"status":"aborted","timestamp":1645951388530,"user_tz":-540,"elapsed":226,"user":{"displayName":"鳴川彰将","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00422213483226230461"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"eCQTnAqiPLg0","executionInfo":{"status":"aborted","timestamp":1645951388531,"user_tz":-540,"elapsed":227,"user":{"displayName":"鳴川彰将","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00422213483226230461"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"iJ3R5xjfPLbx","executionInfo":{"status":"aborted","timestamp":1645951388531,"user_tz":-540,"elapsed":227,"user":{"displayName":"鳴川彰将","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00422213483226230461"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"Pz0gLxJvPLVA","executionInfo":{"status":"aborted","timestamp":1645951388531,"user_tz":-540,"elapsed":227,"user":{"displayName":"鳴川彰将","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00422213483226230461"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#提出するときはOUTPUT_EXPに保存","metadata":{"id":"7XCwo0Ja158K","executionInfo":{"status":"aborted","timestamp":1645951388532,"user_tz":-540,"elapsed":228,"user":{"displayName":"鳴川彰将","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00422213483226230461"}},"execution":{"iopub.status.busy":"2022-03-05T17:27:51.001317Z","iopub.execute_input":"2022-03-05T17:27:51.001700Z","iopub.status.idle":"2022-03-05T17:27:51.434596Z","shell.execute_reply.started":"2022-03-05T17:27:51.001663Z","shell.execute_reply":"2022-03-05T17:27:51.432944Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"AIDxcZJV155N","executionInfo":{"status":"aborted","timestamp":1645951388533,"user_tz":-540,"elapsed":229,"user":{"displayName":"鳴川彰将","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00422213483226230461"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"iwpMlI4M15wq","executionInfo":{"status":"aborted","timestamp":1645951388533,"user_tz":-540,"elapsed":229,"user":{"displayName":"鳴川彰将","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00422213483226230461"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"YuhLGYrA15tm","executionInfo":{"status":"aborted","timestamp":1645951388533,"user_tz":-540,"elapsed":229,"user":{"displayName":"鳴川彰将","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00422213483226230461"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"-TZM9ApW15qk","executionInfo":{"status":"aborted","timestamp":1645951388534,"user_tz":-540,"elapsed":230,"user":{"displayName":"鳴川彰将","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00422213483226230461"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"dSpBmd6t15ng","executionInfo":{"status":"aborted","timestamp":1645951388534,"user_tz":-540,"elapsed":230,"user":{"displayName":"鳴川彰将","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00422213483226230461"}}},"execution_count":null,"outputs":[]}]}