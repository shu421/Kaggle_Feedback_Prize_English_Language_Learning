{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31200,"status":"ok","timestamp":1643886950395,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"},"user_tz":-540},"id":"chh2R71Xkp0c","outputId":"81adb9ea-dcab-4bf7-99a8-ac68ed729c9f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n","/content/drive/MyDrive/Kaggle_Feedback-Prize-Evaluating-Student-Writing/main\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 14.0 MB/s \n","\u001b[?25hCollecting transformers\n","  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n","\u001b[K     |████████████████████████████████| 3.5 MB 80.1 MB/s \n","\u001b[?25hCollecting torch==1.9.1\n","  Downloading torch-1.9.1-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n","\u001b[K     |██████▉                         | 178.2 MB 1.2 MB/s eta 0:08:51\n","\u001b[31mERROR: Operation cancelled by user\u001b[0m\n","\u001b[?25h"]}],"source":["import sys\n","from pathlib import Path\n","\n","if 'google.colab' in sys.modules:\n","\n","    from google.colab import drive\n","    drive.mount('/content/drive/')\n","    %cd drive/MyDrive/Kaggle_Feedback-Prize-Evaluating-Student-Writing/main/\n","\n","    # install packages\n","    !pip install sentencepiece transformers torch==1.9.1 torchvision==0.10.1 torchAudio==0.9.1"]},{"cell_type":"markdown","metadata":{"id":"uODxxuVWm_wS"},"source":["# Libraries and Config"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aHP0BEI1lCUW"},"outputs":[],"source":["import os\n","import gc\n","import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","\n","from torch import cuda\n","\n","from transformers import AutoTokenizer, AutoModelForTokenClassification\n","from torch.utils.data import Dataset, DataLoader\n","import torch\n","from sklearn.metrics import accuracy_score"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":217,"status":"ok","timestamp":1643612542925,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"},"user_tz":-540},"id":"Q-oW1kcJksOK","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f3d1799a-446b-4700-be8b-5067ed1cfb3e"},"outputs":[{"output_type":"stream","name":"stdout","text":["devide: cuda\n"]}],"source":["class Config:\n","    nb_name = 'nb004'\n","    ver = 26\n","    load_tokens = True # 基本Trueでok\n","    load_models = True # モデルをロードするときはTrue、学習するときはFalse\n","    keep_models = True # 学習したモデルを保存するときはTrue\n","\n","    if load_tokens:\n","        load_tokens_from = f'../input/py-bigbird-v{ver}'\n","    else:\n","        load_tokens_from = None\n","\n","    if load_models:\n","        load_model_from = f'../input/py-bigbird-v{ver}'\n","    else:\n","        load_model_from = None\n","\n","    if keep_models:\n","        downloaded_model_path = 'model'\n","    else:\n","        downloaded_model_path = f'../input/py-bigbird-v{ver}'\n","\n","    # testデータが5個以上(提出時)はスコアを計算しない\n","    compute_val_score = True\n","    if len(os.listdir('../input/feedback-prize-2021/test'))>5:\n","        compute_val_score = False\n","\n","\n","    load_train_text = False # 初回だけTrue\n","\n","    # os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n","    device = 'cuda' if cuda.is_available() else 'cpu'\n","\n","    # model Config\n","    model_name = 'google/bigbird-roberta-base'\n","    max_length = 1024\n","    train_batch_size = 4\n","    valid_batch_size = 4\n","    epochs = 5\n","    learning_rates = [2.5e-5, 2.5e-5, 2.5e-6, 2.5e-6, 2.5e-7]\n","    max_grad_norm = 10\n","\n","print('devide:', Config.device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y4GYkdtFxcEa"},"outputs":[],"source":["def seed_everything(seed: int):\n","    import random, os\n","    import numpy as np\n","    import torch\n","    \n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True\n","    \n","seed_everything(71)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4973,"status":"ok","timestamp":1643612256501,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"},"user_tz":-540},"id":"2wqVgvgd8Ox5","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c6e35680-8150-4006-e560-ce235e2517b0"},"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/google/bigbird-roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/d7643b757353be56f05bdd19496d6e3fb5bb9edfdf5f9e5eca88d6f479e32324.dc98375bb3e19a644a5cadd5c305949ec470186fcc20bd8c8b959a43dcc3ff21\n","Model config BigBirdConfig {\n","  \"_name_or_path\": \"google/bigbird-roberta-base\",\n","  \"architectures\": [\n","    \"BigBirdForPreTraining\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"attention_type\": \"block_sparse\",\n","  \"block_size\": 64,\n","  \"bos_token_id\": 1,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu_new\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"big_bird\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_random_blocks\": 3,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"rescale_embeddings\": false,\n","  \"sep_token_id\": 66,\n","  \"transformers_version\": \"4.16.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_bias\": true,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50358\n","}\n","\n","loading file https://huggingface.co/google/bigbird-roberta-base/resolve/main/spiece.model from cache at /root/.cache/huggingface/transformers/d318d7bb69cafb1d8964fc87515592ac3092a2c8fdb305068f9ba4020df3ee3b.271d467a9adc15fb44348481bc75c48b63cba0fd4934bc5377d63a63de052c45\n","loading file https://huggingface.co/google/bigbird-roberta-base/resolve/main/tokenizer.json from cache at None\n","loading file https://huggingface.co/google/bigbird-roberta-base/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/google/bigbird-roberta-base/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/400be7e354ea6eb77319bcc7fa34899ec9fa2e3aff0fa677f6eb7e45a01b1548.75b358ecb30fa6b001d9d87bfde336c02d9123e7a8f5b90cc890d0f6efc3d4a3\n","loading file https://huggingface.co/google/bigbird-roberta-base/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/d20a688e918d227ce5dbcd5f2b570a093cee6b095952d74b9c245b245e6510de.c8f14f85d9ff88cdd1fe7094cde11f85b74fcb7eb03616822964895bc6626c3b\n","loading configuration file https://huggingface.co/google/bigbird-roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/d7643b757353be56f05bdd19496d6e3fb5bb9edfdf5f9e5eca88d6f479e32324.dc98375bb3e19a644a5cadd5c305949ec470186fcc20bd8c8b959a43dcc3ff21\n","Model config BigBirdConfig {\n","  \"_name_or_path\": \"google/bigbird-roberta-base\",\n","  \"architectures\": [\n","    \"BigBirdForPreTraining\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"attention_type\": \"block_sparse\",\n","  \"block_size\": 64,\n","  \"bos_token_id\": 1,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu_new\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"big_bird\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_random_blocks\": 3,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"rescale_embeddings\": false,\n","  \"sep_token_id\": 66,\n","  \"transformers_version\": \"4.16.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_bias\": true,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50358\n","}\n","\n","loading configuration file https://huggingface.co/google/bigbird-roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/d7643b757353be56f05bdd19496d6e3fb5bb9edfdf5f9e5eca88d6f479e32324.dc98375bb3e19a644a5cadd5c305949ec470186fcc20bd8c8b959a43dcc3ff21\n","Model config BigBirdConfig {\n","  \"_name_or_path\": \"google/bigbird-roberta-base\",\n","  \"architectures\": [\n","    \"BigBirdForPreTraining\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"attention_type\": \"block_sparse\",\n","  \"block_size\": 64,\n","  \"bos_token_id\": 1,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu_new\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"big_bird\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_random_blocks\": 3,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"rescale_embeddings\": false,\n","  \"sep_token_id\": 66,\n","  \"transformers_version\": \"4.16.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_bias\": true,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50358\n","}\n","\n","tokenizer config file saved in nb004_model/tokenizer_config.json\n","Special tokens file saved in nb004_model/special_tokens_map.json\n","loading configuration file https://huggingface.co/google/bigbird-roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/d7643b757353be56f05bdd19496d6e3fb5bb9edfdf5f9e5eca88d6f479e32324.dc98375bb3e19a644a5cadd5c305949ec470186fcc20bd8c8b959a43dcc3ff21\n","Model config BigBirdConfig {\n","  \"_name_or_path\": \"google/bigbird-roberta-base\",\n","  \"architectures\": [\n","    \"BigBirdForPreTraining\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"attention_type\": \"block_sparse\",\n","  \"block_size\": 64,\n","  \"bos_token_id\": 1,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu_new\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"big_bird\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_random_blocks\": 3,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"rescale_embeddings\": false,\n","  \"sep_token_id\": 66,\n","  \"transformers_version\": \"4.16.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_bias\": true,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50358\n","}\n","\n","Configuration saved in nb004_model/config.json\n","loading weights file https://huggingface.co/google/bigbird-roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/c523b12608662dbff39b2c24a608a6ff30857bc7967a5c9b00cb76d1147e223b.06e7996caf35449212f17d31a2129bb55c59c19054fcf8552a847e4bcb475688\n","Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForTokenClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BigBirdForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BigBirdForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BigBirdForTokenClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Configuration saved in nb004_model/config.json\n","Model weights saved in nb004_model/pytorch_model.bin\n"]}],"source":["from transformers import *\n","if Config.downloaded_model_path == 'model':\n","    os.makedirs(f'{Config.nb_name}_model', exist_ok=True)\n","    \n","    tokenizer = AutoTokenizer.from_pretrained(Config.model_name, add_prefix_space=True)\n","    tokenizer.save_pretrained(f'{Config.nb_name}_model')\n","\n","    config_model = AutoConfig.from_pretrained(Config.model_name) \n","    config_model.num_labels = 15\n","    config_model.save_pretrained(f'{Config.nb_name}_model')\n","\n","    backbone = AutoModelForTokenClassification.from_pretrained(Config.model_name, \n","                                                               config=config_model)\n","    backbone.save_pretrained(f'{Config.nb_name}_model')"]},{"cell_type":"markdown","metadata":{"id":"0Upogw25l0lz"},"source":["# Load Data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":478},"executionInfo":{"elapsed":763,"status":"ok","timestamp":1643611949112,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"},"user_tz":-540},"id":"TfCECdqzmARo","outputId":"0a8b077f-eb73-4452-afec-6eba8c4063e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["(144293, 8)\n"]},{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-383b341d-70de-46d7-8e7d-c28a32341d7a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>discourse_id</th>\n","      <th>discourse_start</th>\n","      <th>discourse_end</th>\n","      <th>discourse_text</th>\n","      <th>discourse_type</th>\n","      <th>discourse_type_num</th>\n","      <th>predictionstring</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>423A1CA112E2</td>\n","      <td>1.622628e+12</td>\n","      <td>8.0</td>\n","      <td>229.0</td>\n","      <td>Modern humans today are always on their phone....</td>\n","      <td>Lead</td>\n","      <td>Lead 1</td>\n","      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>423A1CA112E2</td>\n","      <td>1.622628e+12</td>\n","      <td>230.0</td>\n","      <td>312.0</td>\n","      <td>They are some really bad consequences when stu...</td>\n","      <td>Position</td>\n","      <td>Position 1</td>\n","      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>423A1CA112E2</td>\n","      <td>1.622628e+12</td>\n","      <td>313.0</td>\n","      <td>401.0</td>\n","      <td>Some certain areas in the United States ban ph...</td>\n","      <td>Evidence</td>\n","      <td>Evidence 1</td>\n","      <td>60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>423A1CA112E2</td>\n","      <td>1.622628e+12</td>\n","      <td>402.0</td>\n","      <td>758.0</td>\n","      <td>When people have phones, they know about certa...</td>\n","      <td>Evidence</td>\n","      <td>Evidence 2</td>\n","      <td>76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>423A1CA112E2</td>\n","      <td>1.622628e+12</td>\n","      <td>759.0</td>\n","      <td>886.0</td>\n","      <td>Driving is one of the way how to get around. P...</td>\n","      <td>Claim</td>\n","      <td>Claim 1</td>\n","      <td>139 140 141 142 143 144 145 146 147 148 149 15...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-383b341d-70de-46d7-8e7d-c28a32341d7a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-383b341d-70de-46d7-8e7d-c28a32341d7a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-383b341d-70de-46d7-8e7d-c28a32341d7a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["             id  ...                                   predictionstring\n","0  423A1CA112E2  ...  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...\n","1  423A1CA112E2  ...       45 46 47 48 49 50 51 52 53 54 55 56 57 58 59\n","2  423A1CA112E2  ...    60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75\n","3  423A1CA112E2  ...  76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...\n","4  423A1CA112E2  ...  139 140 141 142 143 144 145 146 147 148 149 15...\n","\n","[5 rows x 8 columns]"]},"metadata":{},"execution_count":111}],"source":["train_df = pd.read_csv('../input/feedback-prize-2021/original_train.csv')\n","print(train_df.shape)\n","train_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":212,"status":"ok","timestamp":1643611953199,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"},"user_tz":-540},"id":"DvyPm3lbnd5e","outputId":"55d315f2-e9b1-4ff6-faf9-881641071099"},"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-245f2ec2-1ea9-46ef-9718-80de20cd890c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>D46BCB48440A</td>\n","      <td>When people ask for advice,they sometimes talk...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>D72CB1C11673</td>\n","      <td>Making choices in life can be very difficult. ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0FB0700DAF44</td>\n","      <td>During a group project, have you ever asked a ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>DF920E0A7337</td>\n","      <td>Have you ever asked more than one person for h...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>18409261F5C2</td>\n","      <td>80% of Americans believe seeking multiple opin...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-245f2ec2-1ea9-46ef-9718-80de20cd890c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-245f2ec2-1ea9-46ef-9718-80de20cd890c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-245f2ec2-1ea9-46ef-9718-80de20cd890c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["             id                                               text\n","0  D46BCB48440A  When people ask for advice,they sometimes talk...\n","1  D72CB1C11673  Making choices in life can be very difficult. ...\n","2  0FB0700DAF44  During a group project, have you ever asked a ...\n","3  DF920E0A7337  Have you ever asked more than one person for h...\n","4  18409261F5C2  80% of Americans believe seeking multiple opin..."]},"metadata":{},"execution_count":112}],"source":["test_names, test_texts = [], []\n","for f in list(os.listdir('../input/feedback-prize-2021/test')):\n","    test_names.append(f.replace('.txt', ''))\n","    test_texts.append(open('../input/feedback-prize-2021/test/' + f, 'r').read())\n","test_texts = pd.DataFrame({'id':test_names, 'text':test_texts})\n","test_texts.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":446,"status":"ok","timestamp":1643611953953,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"},"user_tz":-540},"id":"5ICDWUw6oqol","outputId":"e8690dbb-d8ff-41ed-8dfa-28b61d5050b2"},"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-b23f8359-2f48-470c-bb0d-b9aab0a8bb02\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>F48EF80D2ED3</td>\n","      <td>There are many programs in the world around yo...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>F8FB4470A52F</td>\n","      <td>Dear Senator,\\n\\n\"The Electoral College is a p...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>F176A8CF72BB</td>\n","      <td>In my opinion i don't think that is fair. i th...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>EBDE7FC748A4</td>\n","      <td>Unmasking the Face\\n\\nThe face on Mars was rea...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>F6C40C564E5E</td>\n","      <td>Luke think you should join the seagoing cowboy...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b23f8359-2f48-470c-bb0d-b9aab0a8bb02')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b23f8359-2f48-470c-bb0d-b9aab0a8bb02 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b23f8359-2f48-470c-bb0d-b9aab0a8bb02');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["             id                                               text\n","0  F48EF80D2ED3  There are many programs in the world around yo...\n","1  F8FB4470A52F  Dear Senator,\\n\\n\"The Electoral College is a p...\n","2  F176A8CF72BB  In my opinion i don't think that is fair. i th...\n","3  EBDE7FC748A4  Unmasking the Face\\n\\nThe face on Mars was rea...\n","4  F6C40C564E5E  Luke think you should join the seagoing cowboy..."]},"metadata":{},"execution_count":113}],"source":["if Config.load_train_text:\n","    test_names, train_texts = [], []\n","    for f in tqdm(list(os.listdir('../input/feedback-prize-2021/train'))):\n","        test_names.append(f.replace('.txt', ''))\n","        train_texts.append(open('../input/feedback-prize-2021/train/' + f, 'r').read())\n","    train_text_df = pd.DataFrame({'id': test_names, 'text': train_texts})\n","    # train_text_df.to_csv('../input/data/train_text_df.csv', index=False)\n","else:\n","    train_text_df = pd.read_csv('../input/fb-data/train_text_df.csv')\n","train_text_df.head()"]},{"cell_type":"markdown","metadata":{"id":"O0FYKpTXo24v"},"source":["# Convert Train Text to NER Labels"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12374,"status":"ok","timestamp":1643611966319,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"},"user_tz":-540},"id":"EUffSkwMpCJO","outputId":"9882e204-a743-4376-e369-7763053d3828"},"outputs":[{"output_type":"stream","name":"stdout","text":["(15594, 3)\n"]}],"source":["if not Config.load_tokens_from:\n","    all_entities = []\n","    for i in tqdm(train_text_df.iterrows()):\n","        total = i[1]['text'].split().__len__()\n","        entities = [\"O\"]*total\n","        for j in train_df[train_df['id'] == i[1]['id']].iterrows():\n","            discourse = j[1]['discourse_type']\n","            list_ix = [int(x) for x in j[1]['predictionstring'].split(' ')]\n","            entities[list_ix[0]] = f\"B-{discourse}\"\n","            for k in list_ix[1:]: entities[k] = f\"I-{discourse}\"\n","        all_entities.append(entities)\n","    train_text_df['entities'] = all_entities\n","    train_text_df.to_csv('train_NER.csv',index=False)\n","    \n","else:\n","    from ast import literal_eval\n","    train_text_df = pd.read_csv(f'{Config.load_tokens_from}/train_NER.csv')\n","    # pandas saves lists as string, we must convert back\n","    train_text_df.entities = train_text_df.entities.apply(lambda x: literal_eval(x) )\n","    \n","print( train_text_df.shape )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rP8X2QjrtKny"},"outputs":[],"source":["# create dict\n","# B: Biginning, I: Inner\n","output_labels = ['O', 'B-Lead', 'I-Lead', 'B-Position', 'I-Position', 'B-Claim', 'I-Claim', 'B-Counterclaim', 'I-Counterclaim', \n","          'B-Rebuttal', 'I-Rebuttal', 'B-Evidence', 'I-Evidence', 'B-Concluding Statement', 'I-Concluding Statement']\n","\n","labels_to_ids = {v:k for k, v in enumerate(output_labels)}\n","ids_to_labels = {k:v for k, v in enumerate(output_labels)}"]},{"cell_type":"markdown","metadata":{"id":"_Gx7fHm5s75v"},"source":["# Dataset"]},{"cell_type":"code","source":["LABEL_ALL_SUBTOKENS = True\n","\n","class dataset(Dataset):\n","    def __init__(self, dataframe, tokenizer, max_len, get_wids):\n","        self.len = len(dataframe)\n","        self.data = dataframe\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","        self.get_wids = get_wids # for validation\n","\n","    def __getitem__(self, index):\n","        # GET TEXT AND WORD LABELS \n","        text = self.data.text[index]        \n","        word_labels = self.data.entities[index] if not self.get_wids else None\n","\n","        # TOKENIZE TEXT\n","        encoding = self.tokenizer(text.split(),\n","                             is_split_into_words=True,\n","                             #return_offsets_mapping=True, \n","                             padding='max_length', \n","                             truncation=True, \n","                             max_length=self.max_len)\n","        word_ids = encoding.word_ids()  \n","        \n","        # CREATE TARGETS\n","        if not self.get_wids:\n","            previous_word_idx = None\n","            label_ids = []\n","            for word_idx in word_ids:                            \n","                if word_idx is None:\n","                    label_ids.append(-100)\n","                elif word_idx != previous_word_idx:              \n","                    label_ids.append( labels_to_ids[word_labels[word_idx]] )\n","                else:\n","                    if LABEL_ALL_SUBTOKENS:\n","                        label_ids.append( labels_to_ids[word_labels[word_idx]] )\n","                    else:\n","                        label_ids.append(-100)\n","                previous_word_idx = word_idx\n","            encoding['labels'] = label_ids\n","\n","        # CONVERT TO TORCH TENSORS\n","        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n","        if self.get_wids: \n","            word_ids2 = [w if w is not None else -1 for w in word_ids]\n","            item['wids'] = torch.as_tensor(word_ids2)\n","        \n","        return item\n","\n","    def __len__(self):\n","        return self.len"],"metadata":{"id":"dnmpDiUFzHd3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R1YgxqT9xA1H"},"source":["# DataLoaders"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1643611966320,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"},"user_tz":-540},"id":"8Or2F7wUxGo1","outputId":"4468e650-fe42-43f1-b412-124f8bed9bbf"},"outputs":[{"output_type":"stream","name":"stdout","text":["There are 15594 train texts. We will split 90% 10% for validation.\n"]}],"source":["# train_idx, test_idz\n","IDS = train_df['id'].unique()\n","print('There are',len(IDS),'train texts. We will split 90% 10% for validation.')\n","\n","train_idx = np.random.choice(np.arange(len(IDS)),int(0.9*len(IDS)),replace=False)\n","valid_idx = np.setdiff1d(np.arange(len(IDS)),train_idx)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":370,"status":"ok","timestamp":1643611966684,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"},"user_tz":-540},"id":"aPqWRVN1xx04","outputId":"c913169c-d07d-4b38-f03c-b09bb7c8c5ad"},"outputs":[{"output_type":"stream","name":"stderr","text":["Didn't find file model/added_tokens.json. We won't load it.\n","loading file model/spiece.model\n","loading file model/tokenizer.json\n","loading file None\n","loading file model/special_tokens_map.json\n","loading file model/tokenizer_config.json\n"]},{"output_type":"stream","name":"stdout","text":["FULL Dataset: (15594, 3)\n","TRAIN Dataset: (14034, 2)\n","TEST Dataset: (1560, 3)\n"]}],"source":["# create train subset and valid subset\n","data = train_text_df[['id','text', 'entities']]\n","train_dataset = data.loc[data['id'].isin(IDS[train_idx]),['text', 'entities']].reset_index(drop=True)\n","test_dataset = data.loc[data['id'].isin(IDS[valid_idx])].reset_index(drop=True)\n","\n","print(\"FULL Dataset: {}\".format(data.shape))\n","print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n","print(\"TEST Dataset: {}\".format(test_dataset.shape))\n","\n","tokenizer = AutoTokenizer.from_pretrained(Config.downloaded_model_path)\n","training_set = dataset(train_dataset, tokenizer, Config.max_length, False)\n","testing_set = dataset(test_dataset, tokenizer, Config.max_length, True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"znLMwNGuz8uq"},"outputs":[],"source":["train_params = {'batch_size': Config.train_batch_size,\n","                'shuffle': True,\n","                'num_workers': 2,\n","                'pin_memory': True}\n","\n","test_params = {'batch_size': Config.valid_batch_size,\n","               'shuffle': False,\n","               'num_workers': 2,\n","               'pin_memory': True}\n","\n","training_loader = DataLoader(training_set, **train_params)\n","testing_loader = DataLoader(testing_set, **test_params)\n","\n","# test dataset\n","test_texts_set = dataset(test_texts, tokenizer, Config.max_length, True)\n","test_texts_loader = DataLoader(test_texts_set, **test_params)"]},{"cell_type":"markdown","metadata":{"id":"_m5K8-iq2_YM"},"source":["# Train Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yODWpH5K3VdN"},"outputs":[],"source":["def train(epoch):\n","    tr_loss, tr_accuracy = 0, 0\n","    nb_tr_examples, nb_tr_steps = 0, 0\n","    #tr_preds, tr_labels = [], []\n","    \n","    # put model in training mode\n","    model.train()\n","    \n","    for idx, batch in enumerate(training_loader):\n","        \n","        ids = batch['input_ids'].to(Config.device, dtype = torch.long)\n","        mask = batch['attention_mask'].to(Config.device, dtype = torch.long)\n","        labels = batch['labels'].to(Config.device, dtype = torch.long)\n","\n","        loss, tr_logits = model(input_ids=ids, attention_mask=mask, labels=labels,\n","                               return_dict=False)\n","        tr_loss += loss.item()\n","\n","        nb_tr_steps += 1\n","        nb_tr_examples += labels.size(0)\n","        \n","        if idx % 200==0:\n","            loss_step = tr_loss/nb_tr_steps\n","            print(f\"Training loss after {idx:04d} training steps: {loss_step}\")\n","           \n","        # compute training accuracy\n","        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n","        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n","        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n","        \n","        # only compute accuracy at active labels\n","        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n","        #active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n","        \n","        labels = torch.masked_select(flattened_targets, active_accuracy)\n","        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n","        \n","        #tr_labels.extend(labels)\n","        #tr_preds.extend(predictions)\n","\n","        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n","        tr_accuracy += tmp_tr_accuracy\n","    \n","        # gradient clipping\n","        torch.nn.utils.clip_grad_norm_(\n","            parameters=model.parameters(), max_norm=Config.max_grad_norm\n","        )\n","        \n","        # backward pass\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    epoch_loss = tr_loss / nb_tr_steps\n","    tr_accuracy = tr_accuracy / nb_tr_steps\n","    print(f\"Training loss epoch: {epoch_loss}\")\n","    print(f\"Training accuracy epoch: {tr_accuracy}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1615,"status":"ok","timestamp":1643611968296,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"},"user_tz":-540},"id":"wmeJWeM47swF","outputId":"b223d240-2271-4dca-e848-bc771c462a03"},"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file model/config.json\n","Model config BigBirdConfig {\n","  \"_name_or_path\": \"model/config.json\",\n","  \"architectures\": [\n","    \"BigBirdForTokenClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"attention_type\": \"block_sparse\",\n","  \"block_size\": 64,\n","  \"bos_token_id\": 1,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu_new\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\",\n","    \"5\": \"LABEL_5\",\n","    \"6\": \"LABEL_6\",\n","    \"7\": \"LABEL_7\",\n","    \"8\": \"LABEL_8\",\n","    \"9\": \"LABEL_9\",\n","    \"10\": \"LABEL_10\",\n","    \"11\": \"LABEL_11\",\n","    \"12\": \"LABEL_12\",\n","    \"13\": \"LABEL_13\",\n","    \"14\": \"LABEL_14\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_10\": 10,\n","    \"LABEL_11\": 11,\n","    \"LABEL_12\": 12,\n","    \"LABEL_13\": 13,\n","    \"LABEL_14\": 14,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4,\n","    \"LABEL_5\": 5,\n","    \"LABEL_6\": 6,\n","    \"LABEL_7\": 7,\n","    \"LABEL_8\": 8,\n","    \"LABEL_9\": 9\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 4096,\n","  \"model_type\": \"big_bird\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_random_blocks\": 3,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"rescale_embeddings\": false,\n","  \"sep_token_id\": 66,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.16.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_bias\": true,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50358\n","}\n","\n","loading weights file model/pytorch_model.bin\n","All model checkpoint weights were used when initializing BigBirdForTokenClassification.\n","\n","All the weights of BigBirdForTokenClassification were initialized from the model checkpoint at model/pytorch_model.bin.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BigBirdForTokenClassification for predictions without further training.\n"]}],"source":["# create model\n","config_model = AutoConfig.from_pretrained(Config.downloaded_model_path+'/config.json')\n","model = AutoModelForTokenClassification.from_pretrained(\n","    Config.downloaded_model_path+'/pytorch_model.bin', config=config_model\n",")\n","model.to(Config.device)\n","optimizer = torch.optim.Adam(params=model.parameters(), lr=Config.learning_rates[0])"]},{"cell_type":"markdown","metadata":{"id":"RTWLw9e59DJW"},"source":["## Train Loop"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4whUzhyIDdYl"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7pZgDRzf8UNP","executionInfo":{"status":"ok","timestamp":1643611968984,"user_tz":-540,"elapsed":693,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"}},"outputId":"4ff82b15-d69c-4a16-f455-61b9303406ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model loaded.\n"]}],"source":["if not Config.load_model_from:\n","    for epoch in range(Config.epochs):\n","        \n","        print(f\"### Training epoch: {epoch + 1}\")\n","        for g in optimizer.param_groups: \n","            g['lr'] = Config.learning_rates[epoch]\n","        lr = optimizer.param_groups[0]['lr']\n","        print(f'### LR = {lr}\\n')\n","        \n","        train(epoch)\n","        torch.cuda.empty_cache()\n","        gc.collect()\n","        \n","    torch.save(model.state_dict(), f'bigbird_v{Config.ver}.pt')\n","else:\n","    model.load_state_dict(torch.load(f'{Config.load_model_from}/bigbird_v{Config.ver}.pt'))\n","    print('Model loaded.')"]},{"cell_type":"markdown","metadata":{"id":"7a9z7236IB8_"},"source":["# Inference"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cX0W1fpUM2cC"},"outputs":[],"source":["def inference(batch):\n","\n","    # move batch to gpu and infer\n","    ids = batch['input_ids'].to(Config.device)\n","    mask = batch['attention_mask'].to(Config.device)\n","    outputs = model(ids, attention_mask=mask, return_dict=False) # それぞれのidについて推論\n","    all_preds = torch.argmax(outputs[0], axis=-1).cpu().numpy() # 推論結果をまとめる\n","\n","    predictions = []\n","    for k, text_preds in enumerate(all_preds):\n","        token_preds = [ids_to_labels[i] for i in text_preds] # textからtokenを取得？\n","\n","        prediction = []\n","        word_ids = batch['wids'][k].numpy() # validation\n","        previous_word_idx = -1\n","        for idx, word_idx in enumerate(word_ids):\n","            if word_idx == -1:\n","                pass\n","            elif word_idx != previous_word_idx:\n","                prediction.append(token_preds[idx])\n","                previous_word_idx = word_idx\n","        predictions.append(prediction)\n","\n","    return predictions\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K76Ili_HQO-7"},"outputs":[],"source":["def get_predictions(df=test_dataset, loader=testing_loader):\n","    \n","    # put model in training mode\n","    model.eval()\n","    \n","    # GET WORD LABEL PREDICTIONS\n","    y_pred2 = []\n","    for batch in loader:\n","        labels = inference(batch)\n","        y_pred2.extend(labels)\n","\n","    final_preds2 = []\n","    for i in range(len(df)):\n","\n","        idx = df.id.values[i]\n","        #pred = [x.replace('B-','').replace('I-','') for x in y_pred2[i]]\n","        pred = y_pred2[i] # Leave \"B\" and \"I\"\n","        preds = []\n","        j = 0\n","        while j < len(pred):\n","            cls = pred[j]\n","            if cls == 'O': j += 1\n","            else: cls = cls.replace('B','I') # spans start with B\n","            end = j + 1\n","            while end < len(pred) and pred[end] == cls:\n","                end += 1\n","            \n","            if cls != 'O' and cls != '' and end - j > 7:\n","                final_preds2.append((idx, cls.replace('I-',''),\n","                                     ' '.join(map(str, list(range(j, end))))))\n","        \n","            j = end\n","        \n","    oof = pd.DataFrame(final_preds2)\n","    oof.columns = ['id','class','predictionstring']\n","\n","    return oof"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jl1M9KQPSIvW"},"outputs":[],"source":["def calc_overlap(row):\n","    \"\"\"\n","    Calculates the overlap between prediction and\n","    ground truth and overlap percentages used for determining\n","    true positives.\n","    \"\"\"\n","    set_pred = set(row.predictionstring_pred.split(' '))\n","    set_gt = set(row.predictionstring_gt.split(' '))\n","    # Length of each and intersection\n","    len_gt = len(set_gt)\n","    len_pred = len(set_pred)\n","    inter = len(set_gt.intersection(set_pred))\n","    overlap_1 = inter / len_gt\n","    overlap_2 = inter/ len_pred\n","    return [overlap_1, overlap_2]\n","\n","def score_feedback_comp(pred_df, gt_df):\n","    \"\"\"\n","    A function that scores for the kaggle\n","        Student Writing Competition\n","        \n","    Uses the steps in the evaluation page here:\n","        https://www.kaggle.com/c/feedback-prize-2021/overview/evaluation\n","    \"\"\"\n","    gt_df = gt_df[['id','discourse_type','predictionstring']] \\\n","        .reset_index(drop=True).copy()\n","    pred_df = pred_df[['id','class','predictionstring']] \\\n","        .reset_index(drop=True).copy()\n","    pred_df['pred_id'] = pred_df.index\n","    gt_df['gt_id'] = gt_df.index\n","    # Step 1. all ground truths and predictions for a given class are compared.\n","    joined = pred_df.merge(gt_df,\n","                           left_on=['id','class'],\n","                           right_on=['id','discourse_type'],\n","                           how='outer',\n","                           suffixes=('_pred','_gt')\n","                          )\n","    joined['predictionstring_gt'] = joined['predictionstring_gt'].fillna(' ')\n","    joined['predictionstring_pred'] = joined['predictionstring_pred'].fillna(' ')\n","\n","    joined['overlaps'] = joined.apply(calc_overlap, axis=1)\n","\n","    # 2. If the overlap between the ground truth and prediction is >= 0.5, \n","    # and the overlap between the prediction and the ground truth >= 0.5,\n","    # the prediction is a match and considered a true positive.\n","    # If multiple matches exist, the match with the highest pair of overlaps is taken.\n","    joined['overlap1'] = joined['overlaps'].apply(lambda x: eval(str(x))[0])\n","    joined['overlap2'] = joined['overlaps'].apply(lambda x: eval(str(x))[1])\n","\n","\n","    joined['potential_TP'] = (joined['overlap1'] >= 0.5) & (joined['overlap2'] >= 0.5)\n","    joined['max_overlap'] = joined[['overlap1','overlap2']].max(axis=1)\n","    tp_pred_ids = joined.query('potential_TP') \\\n","        .sort_values('max_overlap', ascending=False) \\\n","        .groupby(['id','predictionstring_gt']).first()['pred_id'].values\n","\n","    # 3. Any unmatched ground truths are false negatives\n","    # and any unmatched predictions are false positives.\n","    fp_pred_ids = [p for p in joined['pred_id'].unique() if p not in tp_pred_ids]\n","\n","    matched_gt_ids = joined.query('potential_TP')['gt_id'].unique()\n","    unmatched_gt_ids = [c for c in joined['gt_id'].unique() if c not in matched_gt_ids]\n","\n","    # Get numbers of each type\n","    TP = len(tp_pred_ids)\n","    FP = len(fp_pred_ids)\n","    FN = len(unmatched_gt_ids)\n","    #calc microf1\n","    my_f1_score = TP / (TP + 0.5*(FP+FN))\n","    return my_f1_score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HK_t8-8hSVRt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643612067792,"user_tz":-540,"elapsed":98810,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"}},"outputId":"27b29a29-3fa9-4567-9ea0-bfb1a98d53c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Lead 0.893923789907312\n","Claim 0.6138463210520596\n","Counterclaim 0.6828828828828829\n","Rebuttal 0.5990566037735849\n","Evidence 0.7387687188019967\n","Concluding Statement 0.872249822569198\n","Position 0.7605351170568562\n","\n","Overall 0.7373233222919843\n","\n"]}],"source":["if Config.compute_val_score: # note this doesn't run during submit\n","    # VALID TARGETS\n","    valid = train_df.loc[train_df['id'].isin(IDS[valid_idx])]\n","\n","    # OOF PREDICTIONS\n","    oof = get_predictions(test_dataset, testing_loader)\n","\n","    # COMPUTE F1 SCORE\n","    f1s = []\n","    CLASSES = oof['class'].unique()\n","    print()\n","    for c in CLASSES:\n","        pred_df = oof.loc[oof['class']==c].copy()\n","        gt_df = valid.loc[valid['discourse_type']==c].copy()\n","        f1 = score_feedback_comp(pred_df, gt_df)\n","        print(c,f1)\n","        f1s.append(f1)\n","    print()\n","    print('Overall',np.mean(f1s))\n","    print()"]},{"cell_type":"code","source":["sub = get_predictions(test_texts, test_texts_loader)\n","sub.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"tUaNRdmRzX09","executionInfo":{"status":"ok","timestamp":1643612068369,"user_tz":-540,"elapsed":594,"user":{"displayName":"武井柊悟","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00119739872577936431"}},"outputId":"aa94f60c-a91e-4a5c-8fad-c0e24016140e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-3c725cbc-275e-4fda-bc4a-88ab472ba1ac\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>class</th>\n","      <th>predictionstring</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>D46BCB48440A</td>\n","      <td>Lead</td>\n","      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>D46BCB48440A</td>\n","      <td>Position</td>\n","      <td>20 21 22 23 24 25 26 27</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>D46BCB48440A</td>\n","      <td>Evidence</td>\n","      <td>56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 7...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>D46BCB48440A</td>\n","      <td>Evidence</td>\n","      <td>150 151 152 153 154 155 156 157 158 159 160 16...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>D46BCB48440A</td>\n","      <td>Evidence</td>\n","      <td>224 225 226 227 228 229 230 231 232 233 234 23...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c725cbc-275e-4fda-bc4a-88ab472ba1ac')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3c725cbc-275e-4fda-bc4a-88ab472ba1ac button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3c725cbc-275e-4fda-bc4a-88ab472ba1ac');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["             id     class                                   predictionstring\n","0  D46BCB48440A      Lead  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n","1  D46BCB48440A  Position                            20 21 22 23 24 25 26 27\n","2  D46BCB48440A  Evidence  56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 7...\n","3  D46BCB48440A  Evidence  150 151 152 153 154 155 156 157 158 159 160 16...\n","4  D46BCB48440A  Evidence  224 225 226 227 228 229 230 231 232 233 234 23..."]},"metadata":{},"execution_count":128}]},{"cell_type":"code","source":["# sub.to_csv(\"submission.csv\", index=False)"],"metadata":{"id":"Uau40Xli0rUM"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","name":"nb004.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP0BzDd5qermW1S9wsDpSn3"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}